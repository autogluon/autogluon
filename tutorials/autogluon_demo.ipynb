{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AutoGluon aims to provide automatic machine learning (Auto ML) support for MXNet and Gluon. AutoGluon focuses on automatic deep learning (Auto DL). AutoGluon targets: \n",
    "\n",
    "* *Beginners *are* *70~80% of the customers who would be interested in AutoGluon. The basic Auto ML  scenario: customers have a traditional machine learning task by hand, provide own raw data, watch the search process, and finally obtain a good quality model. The beginners include but not limited to engineers and students, who are generally new to machine learning. \n",
    "* *Advanced users *aim to own full control and access to the Auto ML overall process as well as each important component, such as constructing own networks, metrics, losses, optimizers, searcher and trial scheduler. The advanced users could potentially have more specified constraints regarding to the automatic searching procedure. The advanced users include but not limited to experienced machine learning researchers and engineers.\n",
    "* *Contributors: *Contributors are Advanced users who will create strategies that are useful for beginners either extending to new datasets, new domains, new algorithms or bringing state of art results to save time and effort.\n",
    "\n",
    "The AutoGluon's design principles are:\n",
    "\n",
    "* *Easy to use: *Deep learning framework users could use AutoGluon almost right away. The only usage difference between AutoGluon and Gluon is that: rather than providing a fixed value to different deep learning components, we enable a searchable range to let Auto ML decides which are the best, whereas all the major APIs' usage stays the same.\n",
    "* *Easy to extend: *From user perspective, we organize the AutoGluon by tasks, users could easily use all the task specific components, such as data preprocessing, model zoo, metrics and losses, so that adding a new task could very straightforward. In this way, advanced ML tasks, such as GAN ,could be easily incorporated by providing a new task module. From system perspective, multiple back-ends could be used since the front-end are designed to be separate from the backends, this could be beneficial to extend to production-level Auto ML.\n",
    "\n",
    "The AutoGluon's overall system design is as below:\n",
    "\n",
    "<img src=\"./img/autogluon_overview.png\" width=\"400\" height=\"400\" />\n",
    "\n",
    "In the following*, we use Image Classification as a running example* to illustrate the usage of AutoGluon's main APIs.\n",
    "\n",
    "As follow-ups, to understand more about the `fit` backend workflow, please find the basic and distributed fit backend tutorials in [`[1]`](https://code.amazon.com/packages/AutoGluon/blobs/brazil/--/tutorials/autogluon_demo.ipynb) and [`[2]`](https://code.amazon.com/packages/AutoGluon/blobs/brazil/--/tutorials/autogluon_demo.ipynb) respectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "### Install AutoGluon\n",
    "\n",
    "```bash\n",
    "git clone ssh://git.amazon.com/pkg/AutoGluon\n",
    "cd AutoGluon\n",
    "python setup.py install\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Task\n",
    "\n",
    "We are using image classification as an example in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from autogluon import image_classification as task\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Quick Image Classification Example\n",
    "\n",
    "We first show the most basic usage by first creating a dataset and then fiting the dataset to generate the results with the image classification example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AutoGluon Dataset\n",
    "\n",
    "We use CIFAR10 for image classfication for demo purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.Dataset(name='cifar10') # case insentive \n",
    "\n",
    "print(dataset) # show a quick summary of the dataset, e.g. #example for train, #classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructed dataset contains the CIFAR10 training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.train[0] # access the first example\n",
    "dataset.val[-2:] # access the last 2 validation examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will use the default configuration of the image classification to generate:\n",
    "* Best result of the search in terms of accuracy\n",
    "* According best configuration regarding to the best result\n",
    "    \n",
    "To acheive this, we are using `fit` function to generate the above results based on the datasets.\n",
    "\n",
    "The default configruation is based on `max_trial_count=2` and `max_training_epochs=3`. \n",
    "If running on no GPU environment, please set `demo=True` in the `fit`. The process would approximately cost one and half minutes.\n",
    "If want to watch the `fit`, we default provide Tensorboad to visualize the process.\n",
    "Please type `tensorboard --logdir=./checkpoint/exp1/logs --host=127.0.0.1 --port=8888` in the command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = task.fit(dataset, demo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f acc' % (results.val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated best configuration is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time cost is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f s' % results.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Step-by-step Image Classification Example\n",
    "\n",
    "We first introduce the basic configuration `autogluon.space`, which is used to represent the search space of each task components, we will then go throught each components, including \n",
    "\n",
    "* `autogluon.Dataset`\n",
    "* `autogluon.Nets`\n",
    "* `autogluon.Optimizers`\n",
    "* `autogluon.Losses`\n",
    "* `autogluon.Metrics`\n",
    "\n",
    "and finally put all together to `fit` to generate best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import AutoGluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogluon as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AutoGluon Space\n",
    "\n",
    "\n",
    "`autogluon.space` is a search space containing a set of configuration candidates.\n",
    "We provide three basic space types.\n",
    "\n",
    "* Categorical Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_space = ag.space.List('listspace', ['0', '1', '2'])\n",
    "print(list_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Linear Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_space = ag.space.Linear('linspace', 0, 10)\n",
    "print(linear_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Log Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_space = ag.space.Log('logspace', 10**-10, 10**-1)\n",
    "print(log_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An Example of Random Sample from the Combined Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ag.space.sample_configuration([list_space, linear_space, log_space]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then will use `autogluon.Nets` and `autogluon.Optimizers` as examples to show the usage of auto objects. The remainining auto objects are using default value.\n",
    "\n",
    "### Create AutoGluon Nets\n",
    "\n",
    "`autogluon.Nets` is a list of auto networks, and allows search for the best net\n",
    "\n",
    "* from a list of provided (or default) networks\n",
    "* by choosing the best architecture regarding to each auto net."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type of net_list is ag.space.List\n",
    "\n",
    "# method 1 (complex but flexiable): specify the net_list using get_model\n",
    "# net_list = [task.model_zoo.get_model('cifar_resnet20_v1'), # TODO: pretrained and pretrained_dataset would be supported\n",
    "#             task.model_zoo.get_model('cifar_resnet56_v1'),\n",
    "#             task.model_zoo.get_model('cifar_resnet110_v1')]\n",
    "\n",
    "# method 2 (easy and less flexiable): specify the net_list using model name\n",
    "net_list = ['cifar_resnet20_v1',\n",
    "            'cifar_resnet56_v1',\n",
    "            'cifar_resnet110_v1']\n",
    "\n",
    "# default net list for image classification would be overwritten \n",
    "# if net_list is provided\n",
    "nets = ag.Nets(net_list)\n",
    "\n",
    "print(nets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AutoGluon Optimizers\n",
    "\n",
    "`autogluon.Optimizers` defines a list of optimization algorithms that allows search for the best optimization algorithm \n",
    "\n",
    "* from a list of provided (or default) optimizers\n",
    "* by choosing the best hyper-parameters regarding to each auto optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method 1 (complex but flexiable): specify the optim_list using get_optim\n",
    "# optimizers = ag.Optimizers([ag.optim.get_optim('sgd'),\n",
    "#                             ag.optim.get_optim('adam')])\n",
    "\n",
    "# method 2 (easy and less flexiable): specify the optim_list using get_model\n",
    "optimizers = ag.Optimizers(['sgd', 'adam'])\n",
    "\n",
    "print(optimizers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AutoGluon Fit - Put all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_criterion = {\n",
    "    'time_limits': 1*60*60,\n",
    "    'max_metric': 1.0,\n",
    "    'max_trial_count': 4\n",
    "}\n",
    "\n",
    "resources_per_trial = {\n",
    "    'max_num_gpus': 0, # set this to more than 1 if you have GPU machine to run more efficiently.\n",
    "    'max_num_cpus': 4,\n",
    "    'max_training_epochs': 2\n",
    "}\n",
    "\n",
    "results = task.fit(dataset,\n",
    "                   nets,\n",
    "                   optimizers,\n",
    "                   stop_criterion=stop_criterion,\n",
    "                   resources_per_trial=resources_per_trial,\n",
    "                   demo=True) # demo=True is recommened when running on no GPU machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f acc' % (results.val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best associated configuration is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total time cost is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f s' % results.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Search Algorithm\n",
    "\n",
    "`autogluon.searcher` will support both basic and SOTA searchers for both hyper-parameter optimization and architecture search. We now support random search. The default is using searcher is random searcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs is CS.ConfigurationSpace() where import ConfigSpace as CS, this is just example code;\n",
    "# in practice, this is in fit function, and cs should not be None\n",
    "cs = None\n",
    "searcher = ag.searcher.RandomSampling(cs)\n",
    "\n",
    "print(searcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply use string name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher = 'random'\n",
    "\n",
    "print(searcher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trial Scheduler\n",
    "\n",
    "`ag.scheduler` supports scheduling trials in serial order and with early stopping.\n",
    "\n",
    "We support basic FIFO scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just example code; in practice, this is in fit function\n",
    "savedir = 'checkpoint/demo.ag'\n",
    "\n",
    "trial_scheduler = ag.scheduler.FIFO_Scheduler(\n",
    "                task.pipeline.train_image_classification,\n",
    "                None,\n",
    "                {\n",
    "                    'num_cpus': 4,\n",
    "                    'num_gpus': 0,\n",
    "                },\n",
    "                searcher,\n",
    "                checkpoint=savedir)\n",
    "\n",
    "print(trial_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also support Hyperband which is an early stopping mechanism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is just example code; in practice, this is in fit function\n",
    "\n",
    "trial_scheduler = ag.scheduler.Hyperband_Scheduler(\n",
    "                task.pipeline.train_image_classification,\n",
    "                None,\n",
    "                {\n",
    "                    'num_cpus': 4,\n",
    "                    'num_gpus': 0,\n",
    "                },\n",
    "                searcher,\n",
    "                time_attr='epoch',\n",
    "                reward_attr='accuracy',\n",
    "                max_t=10,\n",
    "                grace_period=1,\n",
    "                checkpoint=savedir)\n",
    "\n",
    "print(trial_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume Fit and Checkpointer\n",
    "\n",
    "We use the resume and checkpoint dir in the scheduler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir = 'checkpoint/demo.ag'\n",
    "resume = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_scheduler = ag.scheduler.Hyperband_Scheduler(\n",
    "                task.pipeline.train_image_classification,\n",
    "                None,\n",
    "                {\n",
    "                    'num_cpus': 4,\n",
    "                    'num_gpus': 0,\n",
    "                },\n",
    "                searcher,\n",
    "                checkpoint=savedir,\n",
    "                resume=resume,\n",
    "                time_attr='epoch',\n",
    "                reward_attr='accuracy',\n",
    "                max_t=10,\n",
    "                grace_period=1)\n",
    "\n",
    "print(trial_scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or simply specify the trial scheduler with the string name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_scheduler = 'hyperband'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Using Tensor/MXBoard\n",
    "\n",
    "We could visualize the traing curve using Tensorboad or MXboard.\n",
    "To start the Tensorboard or MXboard, please use:\n",
    "\n",
    "`tensorboard --logdir=./checkpoint/demo/logs --host=127.0.0.1 --port=8889`\n",
    "\n",
    "An example is shown below.\n",
    "\n",
    "<img src=\"./img/cifar_accuracy_curves_2.svg\" width=\"400\" height=\"400\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Stop Criterion\n",
    "\n",
    "`autogluon` supports overall automatic constraints in `stop_criterion`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_criterion = {\n",
    "    'time_limits': 1*60*60,\n",
    "    'max_metric': 0.80, #if you know, otherwise use the default 1.0\n",
    "    'max_trial_count': 2\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Resources Per Trial\n",
    "\n",
    "`autogluon` supports constraints for each trial `in resource_per_trial`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resources_per_trial = {\n",
    "    'max_num_gpus': 0,\n",
    "    'max_num_cpus': 4,\n",
    "    'max_training_epochs': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create AutoGluon Fit with Full Capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = task.fit(dataset,\n",
    "                  nets,\n",
    "                  optimizers,\n",
    "                  searcher=searcher,\n",
    "                  trial_scheduler='fifo',\n",
    "                  resume=resume,\n",
    "                  savedir=savedir,\n",
    "                  stop_criterion=stop_criterion,\n",
    "                  resources_per_trial=resources_per_trial,\n",
    "                  demo=True) # only set demo=True when running on no GPU machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f acc' % (results.val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated best configuration is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total time cost is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f s' % results.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resume AutoGluon Fit\n",
    "\n",
    "We could resume the previous training for more epochs to achieve better results. Similarly, we could also increase `max_trial_count` for better results.\n",
    "\n",
    "Here we increase the `max_training_epochs` from 1 to 3, `max_trial_count` from 2 to 3, and set `resume = True` which will load the checking point in the savedir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_criterion = {\n",
    "    'time_limits': 1*60*60,\n",
    "    'max_metric': 0.80,\n",
    "    'max_trial_count': 3\n",
    "}\n",
    "\n",
    "resources_per_trial = {\n",
    "    'max_num_gpus': 0,\n",
    "    'max_num_cpus': 4,\n",
    "    'max_training_epochs': 3\n",
    "}\n",
    "\n",
    "resume = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = task.fit(dataset,\n",
    "                  nets,\n",
    "                  optimizers,\n",
    "                  searcher=searcher,\n",
    "                  trial_scheduler='fifo',\n",
    "                  resume=resume,\n",
    "                  savedir=savedir,\n",
    "                  stop_criterion=stop_criterion,\n",
    "                  resources_per_trial=resources_per_trial,\n",
    "                  demo=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best accuracy is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f acc' % (results.val_accuracy * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The associated best configuration is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(results.config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total time cost is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('%.2f s' % results.time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refereces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code: https://code.amazon.com/packages/AutoGluon/trees/heads/mainline \n",
    "\n",
    "[1] fit backend tutorial: https://code.amazon.com/packages/AutoGluon/blobs/brazil/--/tutorials/autogluon_demo.ipynb \n",
    "\n",
    "[2] fit backend distributed tutorial: https://code.amazon.com/packages/AutoGluon/blobs/brazil/--/tutorials/autogluon_demo.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
