{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGluon Fit Backend Tutorial (Distributed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisite\n",
    "Please read **AutoGluon Task Scheduler Tutorial** first, if not yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distributed Scheduler Tutorial\n",
    "![Distributed Resource Manager](img/distributed_resource_manager.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create Distributed Scheduler** for 8 servers, we launch the program from master node and provide the ip addresses for other nodes. Each node has 1 GPU (`p3.xlarge`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -       Start worker at:   tcp://172.31.8.238:44417\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -          Listening to:   tcp://172.31.8.238:44417\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -              bokeh at:         172.31.8.238:35770\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - Waiting to connect to:    tcp://172.31.8.238:8781\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -               Threads:                          8\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/git/AutoGluon/tutorials/worker-alug7osq\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:   tcp://172.31.8.238:8781\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-_2y9mz5d\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.8.238:44417\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.8.238:44417\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -         Registered to:    tcp://172.31.8.238:8781\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-27041c82-85aa-11e9-a32c-89ebe9f39263\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8782\n",
      "[ worker 172.31.1.97 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.1.97:8782 --no-nanny --host 172.31.1.97\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:39: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding.\n",
      "  m.add_string(self.Q_C.public_numbers().encode_point())\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:96: CryptographyDeprecationWarning: Support for unsafe construction of public numbers from encoded data will be removed in a future version. Please use EllipticCurvePublicKey.from_encoded_point\n",
      "  self.curve, Q_S_bytes\n",
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/paramiko/kex_ecdh_nist.py:111: CryptographyDeprecationWarning: encode_point has been deprecated on EllipticCurvePublicNumbers and will be removed in a future version. Please use EllipticCurvePublicKey.public_bytes to obtain both compressed and uncompressed point encoding.\n",
      "  hm.add_string(self.Q_C.public_numbers().encode_point())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:    tcp://172.31.1.97:8782\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-f2ckq9c4\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.1.97:35915\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.1.97:35915\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-2773fab6-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.1.97:8782\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.1.97 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.1.97 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.1.97 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.1.97 ] :   defaults = yaml.load(f)\n",
      "[ worker 172.31.1.97 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-kktn5wd5', purging\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -       Start worker at:    tcp://172.31.1.97:35915\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -          Listening to:    tcp://172.31.1.97:35915\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -              bokeh at:          172.31.1.97:33325\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO - Waiting to connect to:     tcp://172.31.1.97:8782\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-437xudjs\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO -         Registered to:     tcp://172.31.1.97:8782\n",
      "[ worker 172.31.1.97 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.97 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.3.224 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.3.224:8783 --no-nanny --host 172.31.3.224\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8783\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ worker 172.31.3.224 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.3.224 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.3.224 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.3.224 ] :   defaults = yaml.load(f)\n",
      "[ worker 172.31.6.120 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.6.120:8784 --no-nanny --host 172.31.6.120\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8784\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:   tcp://172.31.3.224:8783\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-mfp5ql0g\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-2838486c-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.3.224:45665\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.3.224:45665\n",
      "[ \u001b[1mscheduler 172.31.3.224:8783\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.3.224 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-77stpwrg', purging\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -       Start worker at:   tcp://172.31.3.224:45665\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -          Listening to:   tcp://172.31.3.224:45665\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -              bokeh at:         172.31.3.224:38483\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO - Waiting to connect to:    tcp://172.31.3.224:8783\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-mmv4cxao\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO -         Registered to:    tcp://172.31.3.224:8783\n",
      "[ worker 172.31.3.224 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.3.224 ] : distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ worker 172.31.6.120 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.6.120 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.6.120 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.6.120 ] :   defaults = yaml.load(f)\n",
      "[ worker 172.31.6.120 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-fwcabrfe', purging\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -       Start worker at:   tcp://172.31.6.120:35558\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -          Listening to:   tcp://172.31.6.120:35558\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -              bokeh at:         172.31.6.120:40539\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO - Waiting to connect to:    tcp://172.31.6.120:8784\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-t18prpg3\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.216 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.1.216:8785 --no-nanny --host 172.31.1.216\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8785\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:   tcp://172.31.6.120:8784\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-7uyad3jf\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.6.120:35558\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.6.120:35558\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-2925e188-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.6.120:8784\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO -         Registered to:    tcp://172.31.6.120:8784\n",
      "[ worker 172.31.6.120 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.6.120 ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ worker 172.31.1.216 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.1.216 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.1.216 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.1.216 ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:   tcp://172.31.1.216:8785\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-hwxpakj3\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.1.216:43040\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.1.216:43040\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-29df3e74-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.1.216:8785\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.1.216 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-3q0026lt', purging\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -       Start worker at:   tcp://172.31.1.216:43040\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -          Listening to:   tcp://172.31.1.216:43040\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -              bokeh at:         172.31.1.216:42050\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO - Waiting to connect to:    tcp://172.31.1.216:8785\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-l903or_j\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO -         Registered to:    tcp://172.31.1.216:8785\n",
      "[ worker 172.31.1.216 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.1.216 ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8786\n",
      "[ worker 172.31.14.8 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.14.8:8786 --no-nanny --host 172.31.14.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ worker 172.31.14.8 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.14.8 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.14.8 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.14.8 ] :   defaults = yaml.load(f)\n",
      "[ worker 172.31.14.8 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-9nb1kzsv', purging\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -       Start worker at:    tcp://172.31.14.8:40561\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -          Listening to:    tcp://172.31.14.8:40561\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -              bokeh at:          172.31.14.8:36373\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO - Waiting to connect to:     tcp://172.31.14.8:8786\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-z3_3rtb8\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8787\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:    tcp://172.31.14.8:8786\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-lhi9qpzw\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.14.8:40561\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.14.8:40561\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-2a9ef892-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.14.8:8786\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO -         Registered to:     tcp://172.31.14.8:8786\n",
      "[ worker 172.31.14.8 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.14.8 ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.14.237 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.14.237:8787 --no-nanny --host 172.31.14.237\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] :   data = yaml.load(f.read()) or {}\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] :   defaults = yaml.load(f)\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/bokeh/core.py:57: UserWarning:\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : Port 8787 is already in use.\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : Perhaps you already have a cluster running?\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : Hosting the diagnostics dashboard on a random port instead.\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] :   warnings.warn('\\n' + msg)\n",
      "[ worker 172.31.14.237 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.14.237 ] :   data = yaml.load(f.read()) or {}\n",
      "[ worker 172.31.14.237 ] : /home/ubuntu/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "[ worker 172.31.14.237 ] :   defaults = yaml.load(f)\n",
      "[ worker 172.31.14.237 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-cktyc7hy', purging\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -       Start worker at:  tcp://172.31.14.237:37322\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -          Listening to:  tcp://172.31.14.237:37322\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -              bokeh at:        172.31.14.237:45154\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO - Waiting to connect to:   tcp://172.31.14.237:8787\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-1erh6zqd\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:  tcp://172.31.14.237:8787\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                    :39555\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-dkvg2zvf\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.14.237:37322\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.14.237:37322\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-2b5d31cc-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.14.237:8787\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO -         Registered to:   tcp://172.31.14.237:8787\n",
      "[ worker 172.31.14.237 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.14.237 ] : distributed.core - INFO - Starting established connection\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ worker 172.31.3.95 ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_worker 172.31.3.95:8788 --no-nanny --host 172.31.3.95\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : /home/ubuntu/anaconda3/bin/python -m distributed.cli.dask_scheduler --port 8788\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ worker 172.31.3.95 ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/worker-rzpq3lsd', purging\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -       Start worker at:    tcp://172.31.3.95:34227\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -          Listening to:    tcp://172.31.3.95:34227\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -              bokeh at:          172.31.3.95:34041\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO - Waiting to connect to:     tcp://172.31.3.95:8788\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -               Threads:                          8\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -                Memory:                   64.39 GB\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/worker-l_s2xti0\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:    tcp://172.31.3.95:8788\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO -       bokeh at:                     :8787\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-mdgewwga\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.3.95:34227\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.3.95:34227\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-31ef9b70-85aa-11e9-a32c-89ebe9f39263\n",
      "[ \u001b[1mscheduler 172.31.3.95:8788\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO -         Registered to:     tcp://172.31.3.95:8788\n",
      "[ worker 172.31.3.95 ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[ worker 172.31.3.95 ] : distributed.core - INFO - Starting established connection\n"
     ]
    }
   ],
   "source": [
    "import autogluon as ag\n",
    "\n",
    "# Make sure the master node can access the other nodes through ssh.\n",
    "# Make sure AutoGluon Package is installed on the machines.\n",
    "extra_node_ips = ['172.31.1.97',\n",
    "                  '172.31.3.224',\n",
    "                  '172.31.6.120',\n",
    "                  '172.31.1.216',\n",
    "                  '172.31.14.8',\n",
    "                  '172.31.14.237']\n",
    "\n",
    "# Create a distributed scheduler. If no ipaddresses are provided, \n",
    "# scheduler will only use the local resources\n",
    "scheduler = ag.distributed.DistributedTaskScheduler(extra_node_ips)\n",
    "\n",
    "# Add additional node after intialize or at anytime.\n",
    "scheduler.add_remote('172.31.3.95')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DistributedTaskScheduler(\n",
      "DistributedResourceManager{\n",
      "(Remote: Remote REMOTE_ID: 0, \n",
      "\t<Remote: scheduler='tcp://172.31.8.238:8781' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 1, \n",
      "\t<Remote: scheduler='tcp://172.31.1.97:8782' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 2, \n",
      "\t<Remote: scheduler='tcp://172.31.3.224:8783' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 3, \n",
      "\t<Remote: scheduler='tcp://172.31.6.120:8784' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 4, \n",
      "\t<Remote: scheduler='tcp://172.31.1.216:8785' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 5, \n",
      "\t<Remote: scheduler='tcp://172.31.14.8:8786' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 6, \n",
      "\t<Remote: scheduler='tcp://172.31.14.237:8787' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "(Remote: Remote REMOTE_ID: 7, \n",
      "\t<Remote: scheduler='tcp://172.31.3.95:8788' processes=1 cores=8>, Resource: NodeResourceManager(8 CPUs, 1 GPUs))\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(scheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Construct a fake training function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import socket\n",
    "from autogluon.resource import DistributedResource\n",
    "\n",
    "@ag.autogluon_method\n",
    "def train_fn(args):\n",
    "    print('task_id: {}, lr: {}'.format(args.task_id, args.lr))\n",
    "    # wait for 1 sec\n",
    "    time.sleep(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Launch 16 Tasks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ worker 172.31.3.224 ] : task_id: 2, lr is 0.001782649715138694\n",
      "[ worker 172.31.1.97 ] : task_id: 1, lr is 0.001782649715138694\n",
      "[ worker 172.31.6.120 ] : task_id: 3, lr is 0.001782649715138694\n",
      "[ worker 172.31.1.216 ] : task_id: 4, lr is 0.001782649715138694\n",
      "[ worker 172.31.14.237 ] : task_id: 6, lr is 0.001782649715138694\n",
      "[ worker 172.31.14.8 ] : task_id: 5, lr is 0.001782649715138694\n",
      "[ worker 172.31.3.95 ] : task_id: 7, lr is 0.001782649715138694\n",
      "[ worker 172.31.3.95 ] : task_id: 15, lr is 0.00203228544324115\n",
      "[ worker 172.31.3.224 ] : task_id: 11, lr is 0.00203228544324115\n",
      "[ worker 172.31.1.97 ] : task_id: 9, lr is 0.00203228544324115\n",
      "[ worker 172.31.6.120 ] : task_id: 10, lr is 0.00203228544324115\n",
      "[ worker 172.31.1.216 ] : task_id: 13, lr is 0.00203228544324115\n",
      "[ worker 172.31.14.237 ] : task_id: 14, lr is 0.00203228544324115\n",
      "[ worker 172.31.14.8 ] : task_id: 12, lr is 0.00203228544324115\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "from autogluon.scheduler import Task\n",
    "\n",
    "args = argparse.ArgumentParser()\n",
    "config = {'lr': ag.searcher.sample_from(\n",
    "            lambda: np.power(10.0, np.random.uniform(-4, -1)))}\n",
    "\n",
    "for i in range(16):\n",
    "    resource = DistributedResource(num_cpus=2, num_gpus=1)\n",
    "    task = Task(train_fn, {'args': args, 'config': config}, resource)\n",
    "    scheduler.add_task(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
