{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a benchmark for Autogluon Forecasting task.  \n",
    "Assume that we have two COV19 dataset, train_data.csv and test_data.csv in the following format:  \n",
    "\n",
    "|Date|ConfirmedCases|name|\n",
    "| ------ | ------ | ------ |\n",
    "|2020-01-22|0.0|Afghanistan_|\n",
    "|2020-01-23|0.0|Afghanistan_|\n",
    "|2020-01-24|0.0|Afghanistan_|\n",
    "|2020-01-25|0.0|Afghanistan_|\n",
    "|2020-01-26|0.0|Afghanistan_|\n",
    "\n",
    "The comfirmedcases here is the cummulative comfirmed cases up to that date in a certain country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yixiaxia/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/yixiaxia/.pyenv/versions/3.7.7/lib/python3.7/site-packages/pandas/compat/__init__.py:85: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n",
      "/Users/yixiaxia/.pyenv/versions/3.7.7/lib/python3.7/site-packages/gluonts/evaluation/_base.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
      "  from collections import Sized\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "from autogluon.forecasting.task.forecasting.forecasting import Forecasting as task\n",
    "\n",
    "train_data = task.Dataset(file_path=\"https://autogluon.s3-us-west-2.amazonaws.com/datasets/CovidTimeSeries/train.csv\")\n",
    "test_data = task.Dataset(file_path=\"https://autogluon.s3-us-west-2.amazonaws.com/datasets/CovidTimeSeries/test.csv\")\n",
    "prediction_length = 19\n",
    "eval_metric = \"mean_wQuantileLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yixiaxia/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ConfirmedCases</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Afghanistan_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Afghanistan_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Afghanistan_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Afghanistan_</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Afghanistan_</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  ConfirmedCases          name\n",
       "0  2020-01-22             0.0  Afghanistan_\n",
       "1  2020-01-23             0.0  Afghanistan_\n",
       "2  2020-01-24             0.0  Afghanistan_\n",
       "3  2020-01-25             0.0  Afghanistan_\n",
       "4  2020-01-26             0.0  Afghanistan_"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly using GluonTS to do forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def rebuild_tabular(X, time_column, target_column, index_column=None):\n",
    "    \"\"\"\n",
    "    X: dataframe to rebuild, should have the form of:\n",
    "    >>> X\n",
    "      index_column time_column  target_column\n",
    "    0            A  2020-01-22              1\n",
    "    1            A  2020-01-23              2\n",
    "    2            A  2020-01-24              3\n",
    "    3            B  2020-01-22              1\n",
    "    4            B  2020-01-23              2\n",
    "    5            B  2020-01-24              3\n",
    "    6            C  2020-01-22              1\n",
    "    7            C  2020-01-23              2\n",
    "    8            C  2020-01-24              3\n",
    "\n",
    "    index_column: time series index, in the above example, there are three ts: A, B, C,\n",
    "                  if index_column is None, we will assume that the dataset contains only one time series\n",
    "\n",
    "    time_column: time of a data, in the form \"YYYY-MM-DD HH:MM:SS\", we are assuming that each time series contains the same time sequence,\n",
    "                 and the freq in each time series does not change.\n",
    "\n",
    "    target_column: values used for prediction, integers.\n",
    "\n",
    "    output:\n",
    "    a new dataframe in the form that each line contains a time series\n",
    "    transformed example would be:\n",
    "    >>> X\n",
    "          index_column  2020-01-22  2020-01-23  2020-01-24\n",
    "    0            A           1           2           3\n",
    "    1            C           1           2           3\n",
    "    2            B           1           2           3\n",
    "\n",
    "    \"\"\"\n",
    "    if index_column is None:\n",
    "        X = X[[time_column, target_column]]\n",
    "        X[\"index_column\"] = [\"time_series\" for i in range(X.shape[0])]\n",
    "        index_column = \"index_column\"\n",
    "    time_list = sorted(list(set(X[time_column])))\n",
    "    freq = pd.infer_freq(time_list)\n",
    "    if freq is None:\n",
    "        raise ValueError(\"Freq cannot be inferred. Check your dataset.\")\n",
    "\n",
    "    def reshape_dataframe(df):\n",
    "        \"\"\"\n",
    "        for each time occurs in the dataset, we select the target value corresponding to\n",
    "        each time series, and use dataframe.pivot() to convert it to one column, where the column name is the\n",
    "        time, each row is the corresponding target value for each time series.\n",
    "        \"\"\"\n",
    "        df = df.sort_values(by=index_column)\n",
    "        data_dic = {index_column: sorted(list(set(df[index_column])))}\n",
    "\n",
    "        for time in time_list:\n",
    "            tmp = df[df[time_column] == time][[index_column, time_column, target_column]]\n",
    "            tmp = tmp.pivot(index=index_column, columns=time_column, values=target_column)\n",
    "            tmp_values = tmp[time].values\n",
    "            data_dic[time] = tmp_values\n",
    "        return pd.DataFrame(data_dic)\n",
    "\n",
    "    X = reshape_dataframe(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt_train = rebuild_tabular(train_data, time_column=\"Date\", target_column=\"ConfirmedCases\", index_column=\"name\")\n",
    "rebuilt_test = rebuild_tabular(test_data, time_column=\"Date\", target_column=\"ConfirmedCases\", index_column=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>2020-01-22</th>\n",
       "      <th>2020-01-23</th>\n",
       "      <th>2020-01-24</th>\n",
       "      <th>2020-01-25</th>\n",
       "      <th>2020-01-26</th>\n",
       "      <th>2020-01-27</th>\n",
       "      <th>2020-01-28</th>\n",
       "      <th>2020-01-29</th>\n",
       "      <th>2020-01-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-03-24</th>\n",
       "      <th>2020-03-25</th>\n",
       "      <th>2020-03-26</th>\n",
       "      <th>2020-03-27</th>\n",
       "      <th>2020-03-28</th>\n",
       "      <th>2020-03-29</th>\n",
       "      <th>2020-03-30</th>\n",
       "      <th>2020-03-31</th>\n",
       "      <th>2020-04-01</th>\n",
       "      <th>2020-04-02</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>123.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>197.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>264.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>454.0</td>\n",
       "      <td>511.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>847.0</td>\n",
       "      <td>986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>308.0</td>\n",
       "      <td>334.0</td>\n",
       "      <td>370.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>390.0</td>\n",
       "      <td>428.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 73 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  2020-01-22  2020-01-23  2020-01-24  2020-01-25  2020-01-26  \\\n",
       "0  Afghanistan_         0.0         0.0         0.0         0.0         0.0   \n",
       "1      Albania_         0.0         0.0         0.0         0.0         0.0   \n",
       "2      Algeria_         0.0         0.0         0.0         0.0         0.0   \n",
       "3      Andorra_         0.0         0.0         0.0         0.0         0.0   \n",
       "4       Angola_         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2020-01-27  2020-01-28  2020-01-29  2020-01-30  ...  2020-03-24  \\\n",
       "0         0.0         0.0         0.0         0.0  ...        74.0   \n",
       "1         0.0         0.0         0.0         0.0  ...       123.0   \n",
       "2         0.0         0.0         0.0         0.0  ...       264.0   \n",
       "3         0.0         0.0         0.0         0.0  ...       164.0   \n",
       "4         0.0         0.0         0.0         0.0  ...         3.0   \n",
       "\n",
       "   2020-03-25  2020-03-26  2020-03-27  2020-03-28  2020-03-29  2020-03-30  \\\n",
       "0        84.0        94.0       110.0       110.0       120.0       170.0   \n",
       "1       146.0       174.0       186.0       197.0       212.0       223.0   \n",
       "2       302.0       367.0       409.0       454.0       511.0       584.0   \n",
       "3       188.0       224.0       267.0       308.0       334.0       370.0   \n",
       "4         3.0         4.0         4.0         5.0         7.0         7.0   \n",
       "\n",
       "   2020-03-31  2020-04-01  2020-04-02  \n",
       "0       174.0       237.0       273.0  \n",
       "1       243.0       259.0       277.0  \n",
       "2       716.0       847.0       986.0  \n",
       "3       376.0       390.0       428.0  \n",
       "4         7.0         8.0         8.0  \n",
       "\n",
       "[5 rows x 73 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>2020-01-22</th>\n",
       "      <th>2020-01-23</th>\n",
       "      <th>2020-01-24</th>\n",
       "      <th>2020-01-25</th>\n",
       "      <th>2020-01-26</th>\n",
       "      <th>2020-01-27</th>\n",
       "      <th>2020-01-28</th>\n",
       "      <th>2020-01-29</th>\n",
       "      <th>2020-01-30</th>\n",
       "      <th>...</th>\n",
       "      <th>2020-04-12</th>\n",
       "      <th>2020-04-13</th>\n",
       "      <th>2020-04-14</th>\n",
       "      <th>2020-04-15</th>\n",
       "      <th>2020-04-16</th>\n",
       "      <th>2020-04-17</th>\n",
       "      <th>2020-04-18</th>\n",
       "      <th>2020-04-19</th>\n",
       "      <th>2020-04-20</th>\n",
       "      <th>2020-04-21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>607.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>840.0</td>\n",
       "      <td>906.0</td>\n",
       "      <td>933.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>446.0</td>\n",
       "      <td>467.0</td>\n",
       "      <td>475.0</td>\n",
       "      <td>494.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>539.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>609.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1914.0</td>\n",
       "      <td>1983.0</td>\n",
       "      <td>2070.0</td>\n",
       "      <td>2160.0</td>\n",
       "      <td>2268.0</td>\n",
       "      <td>2418.0</td>\n",
       "      <td>2534.0</td>\n",
       "      <td>2629.0</td>\n",
       "      <td>2718.0</td>\n",
       "      <td>2811.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Andorra_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>638.0</td>\n",
       "      <td>646.0</td>\n",
       "      <td>659.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>696.0</td>\n",
       "      <td>704.0</td>\n",
       "      <td>713.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Angola_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           name  2020-01-22  2020-01-23  2020-01-24  2020-01-25  2020-01-26  \\\n",
       "0  Afghanistan_         0.0         0.0         0.0         0.0         0.0   \n",
       "1      Albania_         0.0         0.0         0.0         0.0         0.0   \n",
       "2      Algeria_         0.0         0.0         0.0         0.0         0.0   \n",
       "3      Andorra_         0.0         0.0         0.0         0.0         0.0   \n",
       "4       Angola_         0.0         0.0         0.0         0.0         0.0   \n",
       "\n",
       "   2020-01-27  2020-01-28  2020-01-29  2020-01-30  ...  2020-04-12  \\\n",
       "0         0.0         0.0         0.0         0.0  ...       607.0   \n",
       "1         0.0         0.0         0.0         0.0  ...       446.0   \n",
       "2         0.0         0.0         0.0         0.0  ...      1914.0   \n",
       "3         0.0         0.0         0.0         0.0  ...       638.0   \n",
       "4         0.0         0.0         0.0         0.0  ...        19.0   \n",
       "\n",
       "   2020-04-13  2020-04-14  2020-04-15  2020-04-16  2020-04-17  2020-04-18  \\\n",
       "0       665.0       714.0       784.0       840.0       906.0       933.0   \n",
       "1       467.0       475.0       494.0       518.0       539.0       548.0   \n",
       "2      1983.0      2070.0      2160.0      2268.0      2418.0      2534.0   \n",
       "3       646.0       659.0       673.0       673.0       696.0       704.0   \n",
       "4        19.0        19.0        19.0        19.0        19.0        24.0   \n",
       "\n",
       "   2020-04-19  2020-04-20  2020-04-21  \n",
       "0       996.0      1026.0      1092.0  \n",
       "1       562.0       584.0       609.0  \n",
       "2      2629.0      2718.0      2811.0  \n",
       "3       713.0       717.0       717.0  \n",
       "4        24.0        24.0        24.0  \n",
       "\n",
       "[5 rows x 92 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rebuilt_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt_val = rebuilt_train.copy()\n",
    "rebuilt_train = rebuilt_train.iloc[:, :-prediction_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then transform the rebuilt tabular into GluonTS Listdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "def create_gluonts_data(df, index_column):\n",
    "    index = df[index_column]\n",
    "    target = df.drop(index_column, axis=1)\n",
    "    target_values = target.values\n",
    "    date_list = target.columns\n",
    "    freq = pd.infer_freq(date_list)\n",
    "    data = [\n",
    "        {\n",
    "            FieldName.TARGET: target,\n",
    "            FieldName.START: pd.Timestamp(date_list[0], freq=freq),\n",
    "            FieldName.ITEM_ID: item_id\n",
    "        }\n",
    "        for (target, item_id) in zip(target_values, index)\n",
    "    ]\n",
    "    return ListDataset(data, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gluonts_train_data = create_gluonts_data(rebuilt_train, \"name\")\n",
    "gluonts_val_data = create_gluonts_data(rebuilt_val, \"name\")\n",
    "gluonts_test_data = create_gluonts_data(rebuilt_test, \"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 32.04it/s, epoch=1/100, avg_epoch_loss=85.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.32it/s, epoch=2/100, avg_epoch_loss=83]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.43it/s, epoch=3/100, avg_epoch_loss=80.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.29it/s, epoch=4/100, avg_epoch_loss=76.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.52it/s, epoch=5/100, avg_epoch_loss=70.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.86it/s, epoch=6/100, avg_epoch_loss=59.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.17it/s, epoch=7/100, avg_epoch_loss=49.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.52it/s, epoch=8/100, avg_epoch_loss=43.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.38it/s, epoch=9/100, avg_epoch_loss=38.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.79it/s, epoch=10/100, avg_epoch_loss=56.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.15it/s, epoch=11/100, avg_epoch_loss=31.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.16it/s, epoch=12/100, avg_epoch_loss=29.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.54it/s, epoch=13/100, avg_epoch_loss=27.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.53it/s, epoch=14/100, avg_epoch_loss=25.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.84it/s, epoch=15/100, avg_epoch_loss=24.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.45it/s, epoch=16/100, avg_epoch_loss=22.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.98it/s, epoch=17/100, avg_epoch_loss=22]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.73it/s, epoch=18/100, avg_epoch_loss=20.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.97it/s, epoch=19/100, avg_epoch_loss=21.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.29it/s, epoch=20/100, avg_epoch_loss=19.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.85it/s, epoch=21/100, avg_epoch_loss=23.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.17it/s, epoch=22/100, avg_epoch_loss=20.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.51it/s, epoch=23/100, avg_epoch_loss=18.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.93it/s, epoch=24/100, avg_epoch_loss=19.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.46it/s, epoch=25/100, avg_epoch_loss=18.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.90it/s, epoch=26/100, avg_epoch_loss=17.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.29it/s, epoch=27/100, avg_epoch_loss=17.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.22it/s, epoch=28/100, avg_epoch_loss=17.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.56it/s, epoch=29/100, avg_epoch_loss=17.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.50it/s, epoch=30/100, avg_epoch_loss=16.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.35it/s, epoch=31/100, avg_epoch_loss=16.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.27it/s, epoch=32/100, avg_epoch_loss=16.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.32it/s, epoch=33/100, avg_epoch_loss=17.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.40it/s, epoch=34/100, avg_epoch_loss=15.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.37it/s, epoch=35/100, avg_epoch_loss=16.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.81it/s, epoch=36/100, avg_epoch_loss=15.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.47it/s, epoch=37/100, avg_epoch_loss=15.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.08it/s, epoch=38/100, avg_epoch_loss=16.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.94it/s, epoch=39/100, avg_epoch_loss=15.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.94it/s, epoch=40/100, avg_epoch_loss=15.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.70it/s, epoch=41/100, avg_epoch_loss=15.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.24it/s, epoch=42/100, avg_epoch_loss=15.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.64it/s, epoch=43/100, avg_epoch_loss=15]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.45it/s, epoch=44/100, avg_epoch_loss=15.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.96it/s, epoch=45/100, avg_epoch_loss=14.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.51it/s, epoch=46/100, avg_epoch_loss=14.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.40it/s, epoch=47/100, avg_epoch_loss=15.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.12it/s, epoch=48/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.23it/s, epoch=49/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.54it/s, epoch=50/100, avg_epoch_loss=14]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.74it/s, epoch=51/100, avg_epoch_loss=14.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.39it/s, epoch=52/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.70it/s, epoch=53/100, avg_epoch_loss=14.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.72it/s, epoch=54/100, avg_epoch_loss=14.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.78it/s, epoch=55/100, avg_epoch_loss=20.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.87it/s, epoch=56/100, avg_epoch_loss=14.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.75it/s, epoch=57/100, avg_epoch_loss=14.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.36it/s, epoch=58/100, avg_epoch_loss=13.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.89it/s, epoch=59/100, avg_epoch_loss=14.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.74it/s, epoch=60/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.94it/s, epoch=61/100, avg_epoch_loss=14]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.66it/s, epoch=62/100, avg_epoch_loss=13.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.50it/s, epoch=63/100, avg_epoch_loss=14.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.28it/s, epoch=64/100, avg_epoch_loss=13.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.78it/s, epoch=65/100, avg_epoch_loss=13.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.71it/s, epoch=66/100, avg_epoch_loss=17]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.23it/s, epoch=67/100, avg_epoch_loss=15.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.78it/s, epoch=68/100, avg_epoch_loss=13.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.76it/s, epoch=69/100, avg_epoch_loss=14.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.44it/s, epoch=70/100, avg_epoch_loss=13.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.83it/s, epoch=71/100, avg_epoch_loss=13.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.53it/s, epoch=72/100, avg_epoch_loss=13.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.91it/s, epoch=73/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.47it/s, epoch=74/100, avg_epoch_loss=13.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.10it/s, epoch=75/100, avg_epoch_loss=14]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.61it/s, epoch=76/100, avg_epoch_loss=12.9]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.82it/s, epoch=77/100, avg_epoch_loss=13.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.43it/s, epoch=78/100, avg_epoch_loss=14.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.63it/s, epoch=79/100, avg_epoch_loss=12.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.01it/s, epoch=80/100, avg_epoch_loss=13.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.00it/s, epoch=81/100, avg_epoch_loss=13.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.97it/s, epoch=82/100, avg_epoch_loss=14.1]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.80it/s, epoch=83/100, avg_epoch_loss=13.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.49it/s, epoch=84/100, avg_epoch_loss=13.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.12it/s, epoch=85/100, avg_epoch_loss=13.4]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.23it/s, epoch=86/100, avg_epoch_loss=13.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.55it/s, epoch=87/100, avg_epoch_loss=14.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.23it/s, epoch=88/100, avg_epoch_loss=13.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.23it/s, epoch=89/100, avg_epoch_loss=13.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.97it/s, epoch=90/100, avg_epoch_loss=12.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 32.53it/s, epoch=91/100, avg_epoch_loss=12.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 31.94it/s, epoch=92/100, avg_epoch_loss=12.3]\n",
      "100%|██████████| 10/10 [00:00<00:00, 33.01it/s, epoch=93/100, avg_epoch_loss=12.6]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.18it/s, epoch=94/100, avg_epoch_loss=12.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 34.61it/s, epoch=95/100, avg_epoch_loss=12.5]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.49it/s, epoch=96/100, avg_epoch_loss=12.2]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.25it/s, epoch=97/100, avg_epoch_loss=12.7]\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.10it/s, epoch=98/100, avg_epoch_loss=12.6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 35.11it/s, epoch=99/100, avg_epoch_loss=12.8]\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.40it/s, epoch=100/100, avg_epoch_loss=16.5]\n"
     ]
    }
   ],
   "source": [
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "params = {\n",
    "    \"prediction_length\": 19,\n",
    "    \"freq\": \"D\",\n",
    "    \"num_batches_per_epoch\": 10,\n",
    "    \"epochs\": 100,\n",
    "    \"quantiles\": [0.1, 0.5, 0.9]\n",
    "}\n",
    "model = MQCNNEstimator.from_hyperparameters(**params)\n",
    "\n",
    "predictor = model.train(gluonts_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yixiaxia/.pyenv/versions/3.7.7/lib/python3.7/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Running evaluation: 100%|██████████| 313/313 [00:00<00:00, 8443.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11829968436159917\n"
     ]
    }
   ],
   "source": [
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=gluonts_test_data,\n",
    "                                                 predictor=predictor,\n",
    "                                                 num_samples=100)\n",
    "forecasts, tss = list(forecast_it), list(ts_it)\n",
    "# forecasts, tss = list(tqdm(forecast_it, total=len(gluonts_val_data))), list(tqdm(ts_it, total=len(gluonts_val_data)))\n",
    "# print(forecasts[0], tss[0])\n",
    "evaluator = Evaluator()\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(tss))\n",
    "print(agg_metrics[eval_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction results for 20 days after the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0.5\n",
      "2020-04-22  1019.208862\n",
      "2020-04-23   982.361755\n",
      "2020-04-24   992.114441\n",
      "2020-04-25   989.922974\n",
      "2020-04-26  1028.132568\n",
      "2020-04-27  1018.237427\n",
      "2020-04-28  1023.813538\n",
      "2020-04-29  1018.235596\n",
      "2020-04-30  1042.546631\n",
      "2020-05-01  1052.428711\n",
      "2020-05-02  1030.224365\n",
      "2020-05-03  1052.249512\n",
      "2020-05-04   998.043213\n",
      "2020-05-05  1051.093262\n",
      "2020-05-06  1059.899902\n",
      "2020-05-07  1032.044312\n",
      "2020-05-08  1049.196777\n",
      "2020-05-09  1030.370483\n",
      "2020-05-10  1037.513794\n"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "predicted_targets = list(predictor.predict(gluonts_test_data))\n",
    "index = sorted(list(set(train_data[\"name\"])))\n",
    "\n",
    "quantiles = [0.5]\n",
    "for i in range(len(index)):\n",
    "    tmp_dict = {}\n",
    "    for quantile in quantiles:\n",
    "        tmp_dict[quantile] = predicted_targets[i].quantile(str(quantile))\n",
    "    df = pd.DataFrame(tmp_dict)\n",
    "    df.index = pd.date_range(start=predicted_targets[i].start_date,\n",
    "                             periods=prediction_length,\n",
    "                             freq=\"D\")\n",
    "    result_dict[index[i]] = df\n",
    "    \n",
    "print(result_dict[\"Afghanistan_\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AutoGluon To do this forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82a2ffa5359d41a6aa9fb2119fb7b688",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.26it/s, epoch=1/100, avg_epoch_loss=263]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 37.17it/s, epoch=2/100, avg_epoch_loss=257]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.72it/s, epoch=3/100, avg_epoch_loss=249]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 36.34it/s, epoch=1/100, avg_epoch_loss=269]\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 33.98it/s, epoch=4/100, avg_epoch_loss=237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning rate from ``lr_scheduler`` has been overwritten by ``learning_rate`` in optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 35.06it/s, epoch=2/100, avg_epoch_loss=262]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 27.84it/s, epoch=5/100, avg_epoch_loss=214]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 31.65it/s, epoch=3/100, avg_epoch_loss=255]\n",
      "\n",
      "100%|██████████| 10/10 [00:00<00:00, 23.28it/s, epoch=1/100, avg_epoch_loss=254]\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "from autogluon.forecasting.task.forecasting.forecasting import Forecasting as task\n",
    "\n",
    "import autogluon.core as ag\n",
    "\n",
    "# change this to specify search strategy, can try bayesopt, random, or skopt\n",
    "searcher_type = \"random\"\n",
    "# change this to specify eval metric, one of [\"MASE\", \"MAPE\", \"sMAPE\", \"mean_wQuantileLoss\"]\n",
    "eval_metric = \"mean_wQuantileLoss\"\n",
    "\n",
    "predictor = task.fit(train_data=train_data,\n",
    "                     prediction_length=19,\n",
    "                     index_column=\"name\",\n",
    "                     target_column=\"ConfirmedCases\",\n",
    "                     time_column=\"Date\",\n",
    "                     hyperparameter_tune=True,\n",
    "                     hyperparameters={\"MQCNN\": {'context_length': ag.Int(10, 20),\n",
    "                                                'epochs': 100,\n",
    "                                                \"num_batches_per_epoch\": 10}},\n",
    "                     search_strategy=searcher_type,\n",
    "                     eval_metric=eval_metric,\n",
    "                     num_trials=3)\n",
    "\n",
    "print(predictor.leaderboard())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 2323.72it/s]\n",
      "100%|██████████| 313/313 [00:00<00:00, 2729.03it/s]\n",
      "Running evaluation: 100%|██████████| 313/313 [00:00<00:00, 6015.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33742358997324406\n"
     ]
    }
   ],
   "source": [
    "print(predictor.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction results for 20 days after the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    0.1          0.5          0.9\n",
      "2020-04-22   927.118286  1074.994629  1180.039185\n",
      "2020-04-23   973.479370  1103.497070  1194.868652\n",
      "2020-04-24   889.371399  1129.917725  1198.302734\n",
      "2020-04-25   925.780457  1123.990601  1192.414551\n",
      "2020-04-26   999.970154  1137.439575  1308.415527\n",
      "2020-04-27   941.977539  1131.409058  1304.347168\n",
      "2020-04-28   861.965149  1146.861694  1289.805908\n",
      "2020-04-29  1027.356079  1148.889038  1272.243164\n",
      "2020-04-30  1034.995483  1176.468262  1376.541992\n",
      "2020-05-01   914.351135  1165.311646  1336.263428\n",
      "2020-05-02   971.587769  1192.618164  1476.304688\n",
      "2020-05-03   935.683350  1172.089600  1326.004395\n",
      "2020-05-04   995.432861  1160.596069  1347.831787\n",
      "2020-05-05   957.176208  1172.679565  1318.155029\n",
      "2020-05-06  1005.680969  1179.221680  1343.417725\n",
      "2020-05-07   954.338379  1170.545898  1309.378540\n",
      "2020-05-08   883.415100  1183.472290  1419.175415\n",
      "2020-05-09   960.499695  1205.509155  1483.166138\n",
      "2020-05-10   994.224792  1190.478394  1407.080322\n"
     ]
    }
   ],
   "source": [
    "predictions = predictor.predict(test_data, quantiles=[0.1, 0.5, 0.9])\n",
    "print(predictions['Afghanistan_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
