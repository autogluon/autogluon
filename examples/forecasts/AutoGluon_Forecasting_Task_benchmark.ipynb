{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a benchmark for Autogluon Forecasting task.  \n",
    "Assume that we have two COV19 dataset, train_data.csv and test_data.csv in the following format:  \n",
    "\n",
    "|Date|ConfirmedCases|name|\n",
    "| ------ | ------ | ------ |\n",
    "|2020-01-22|0.0|Afghanistan_|\n",
    "|2020-01-23|0.0|Afghanistan_|\n",
    "|2020-01-24|0.0|Afghanistan_|\n",
    "|2020-01-25|0.0|Afghanistan_|\n",
    "|2020-01-26|0.0|Afghanistan_|\n",
    "\n",
    "The comfirmedcases here is the cummulative comfirmed cases up to that date in a certain country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "from autogluon.forecasting.task.forecasting.forecasting import Forecasting as task\n",
    "\n",
    "train_data = task.Dataset(\"https://autogluon.s3-us-west-2.amazonaws.com/datasets/CovidTimeSeries/train.csv\")\n",
    "test_data = task.Dataset(\"https://autogluon.s3-us-west-2.amazonaws.com/datasets/CovidTimeSeries/test.csv\")\n",
    "prediction_length = 19\n",
    "eval_metric = \"mean_wQuantileLoss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Directly using GluonTS to do forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def rebuild_tabular(X, time_column, target_column, index_column=None):\n",
    "    if index_column is None:\n",
    "        X = X[[time_column, target_column]]\n",
    "        X[\"index_column\"] = [\"time_series\" for i in range(X.shape[0])]\n",
    "        index_column = \"index_column\"\n",
    "    time_list = sorted(list(set(X[time_column])))\n",
    "    freq = pd.infer_freq(time_list)\n",
    "    if freq is None:\n",
    "        raise ValueError(\"Freq cannot be inferred. Check your dataset.\")\n",
    "\n",
    "    def reshape_dataframe(df):\n",
    "        df = df.sort_values(by=index_column)\n",
    "        data_dic = {index_column: sorted(list(set(df[index_column])))}\n",
    "\n",
    "        for time in time_list:\n",
    "            tmp = df[df[time_column] == time][[index_column, time_column, target_column]]\n",
    "            tmp = tmp.pivot(index=index_column, columns=time_column, values=target_column)\n",
    "            tmp_values = tmp[time].values\n",
    "            data_dic[time] = tmp_values\n",
    "        return pd.DataFrame(data_dic)\n",
    "\n",
    "    X = reshape_dataframe(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt_train = rebuild_tabular(train_data, time_column=\"Date\", target_column=\"ConfirmedCases\", index_column=\"name\")\n",
    "rebuilt_test = rebuild_tabular(test_data, time_column=\"Date\", target_column=\"ConfirmedCases\", index_column=\"name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rebuilt_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rebuilt_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train-Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rebuilt_val = rebuilt_train.copy()\n",
    "rebuilt_train = rebuilt_train.iloc[:, :-prediction_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then transform the rebuilt tabular into GluonTS Listdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.dataset.common import ListDataset\n",
    "\n",
    "def create_gluonts_data(df, index_column):\n",
    "    index = df[index_column]\n",
    "    target = df.drop(index_column, axis=1)\n",
    "    target_values = target.values\n",
    "    date_list = target.columns\n",
    "    freq = pd.infer_freq(date_list)\n",
    "    data = [\n",
    "        {\n",
    "            FieldName.TARGET: target,\n",
    "            FieldName.START: pd.Timestamp(date_list[0], freq=freq),\n",
    "            FieldName.ITEM_ID: item_id\n",
    "        }\n",
    "        for (target, item_id) in zip(target_values, index)\n",
    "    ]\n",
    "    return ListDataset(data, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gluonts_train_data = create_gluonts_data(rebuilt_train, \"name\")\n",
    "gluonts_val_data = create_gluonts_data(rebuilt_val, \"name\")\n",
    "gluonts_test_data = create_gluonts_data(rebuilt_test, \"name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.model.seq2seq import MQCNNEstimator\n",
    "from gluonts.trainer import Trainer\n",
    "\n",
    "params = {\n",
    "    \"prediction_length\": 19,\n",
    "    \"freq\": \"D\",\n",
    "    \"num_batches_per_epoch\": 10,\n",
    "    \"epochs\": 50,\n",
    "    \"quantiles\": [0.1, 0.5, 0.9]\n",
    "}\n",
    "model = MQCNNEstimator.from_hyperparameters(**params)\n",
    "\n",
    "predictor = model.train(gluonts_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gluonts.evaluation import Evaluator\n",
    "from gluonts.evaluation.backtest import make_evaluation_predictions\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=gluonts_test_data,\n",
    "                                                 predictor=predictor,\n",
    "                                                 num_samples=100)\n",
    "forecasts, tss = list(forecast_it), list(ts_it)\n",
    "# forecasts, tss = list(tqdm(forecast_it, total=len(gluonts_val_data))), list(tqdm(ts_it, total=len(gluonts_val_data)))\n",
    "# print(forecasts[0], tss[0])\n",
    "evaluator = Evaluator(quantiles=[0.1, 0.5, 0.9])\n",
    "agg_metrics, item_metrics = evaluator(iter(tss), iter(forecasts), num_series=len(tss))\n",
    "print(agg_metrics[eval_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction results for 20 days after the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {}\n",
    "predicted_targets = list(predictor.predict(gluonts_test_data))\n",
    "index = sorted(list(set(train_data[\"name\"])))\n",
    "\n",
    "quantiles = [0.1, 0.5, 0.9]\n",
    "for i in range(len(index)):\n",
    "    tmp_dict = {}\n",
    "    for quantile in quantiles:\n",
    "        tmp_dict[quantile] = predicted_targets[i].quantile(str(quantile))\n",
    "    df = pd.DataFrame(tmp_dict)\n",
    "    df.index = pd.date_range(start=predicted_targets[i].start_date,\n",
    "                             periods=prediction_length,\n",
    "                             freq=\"D\")\n",
    "    result_dict[index[i]] = df\n",
    "    \n",
    "print(result_dict[\"Afghanistan_\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using AutoGluon To do this forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from autogluon.forecasting.task.forecasting.forecasting import Forecasting as task\n",
    "\n",
    "import autogluon.core as ag\n",
    "\n",
    "# change this to specify search strategy, can try bayesopt, random, or skopt\n",
    "searcher_type = \"random\"\n",
    "# change this to specify eval metric, one of [\"MASE\", \"MAPE\", \"sMAPE\", \"mean_wQuantileLoss\"]\n",
    "eval_metric = \"mean_wQuantileLoss\"\n",
    "\n",
    "predictor = task.fit(train_data=train_data,\n",
    "                     prediction_length=19,\n",
    "                     index_column=\"name\",\n",
    "                     target_column=\"ConfirmedCases\",\n",
    "                     time_column=\"Date\",\n",
    "                     hyperparameter_tune=True,\n",
    "                     hyperparameters={\"MQCNN\": {'context_length': ag.Int(10, 20),\n",
    "                                                'epochs': 50,\n",
    "                                                \"num_batches_per_epoch\": 10}},\n",
    "                     search_strategy=searcher_type,\n",
    "                     eval_metric=eval_metric,\n",
    "                     quantiles=[0.1, 0.5, 0.9],\n",
    "                     num_trials=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predictor.evaluate(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get prediction results for 20 days after the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(test_data, quantiles=[0.1, 0.5, 0.9])\n",
    "print(predictions['Afghanistan_'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
