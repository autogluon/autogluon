{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# AutoGluon Example on Custom Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Import the basic packages, such as numpy, mxnet and gluoncv.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, init\n",
    "from gluoncv.model_zoo import get_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Define a function to load the given network parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_network(num_classes, ctx):\n",
    "    finetune_net = get_model('densenet169', pretrained=False)\n",
    "    finetune_net.collect_params().load('densenet169-0000.params')\n",
    "    # change the last fully connected layer to match the number of classes\n",
    "    with finetune_net.name_scope():\n",
    "        finetune_net.output = gluon.nn.Dense(num_classes)\n",
    "    # initialize and context\n",
    "    finetune_net.output.initialize(init.Xavier(), ctx=ctx)\n",
    "    finetune_net.collect_params().reset_ctx(ctx)\n",
    "    finetune_net.hybridize()\n",
    "    return finetune_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Define a function for dataset meta data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset_meta(dataset, basedir='./datasets'):\n",
    "    if dataset.lower() == 'apparel':\n",
    "        num_classes = 18\n",
    "        rec_train = os.path.join(basedir, 'Apparel_train.rec')\n",
    "        rec_train_idx = os.path.join(basedir, 'Apparel_train.idx')\n",
    "        rec_val = os.path.join(basedir, 'Apparel_test.rec')\n",
    "        rec_val_idx = os.path.join(basedir, 'Apparel_test.idx')\n",
    "    else:\n",
    "        raise NotImplemented\n",
    "    return num_classes, rec_train, rec_train_idx, rec_val, rec_val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Define the test/evaluation function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def test(net, val_data, ctx, batch_fn):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    val_data.reset()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data, label = batch_fn(batch, ctx)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Define the training loop**\n",
    "This is a 40-line normal finetuning script, with only basic components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def train_loop(args, reporter):\n",
    "    lr_steps = [int(args.epochs*0.75), np.inf]\n",
    "    ctx = [mx.gpu(i) for i in range(args.num_gpus)] if args.num_gpus > 0 else [mx.cpu()]\n",
    "\n",
    "    num_classes, rec_train, rec_train_idx, rec_val, rec_val_idx = get_dataset_meta(args.dataset)\n",
    "    finetune_net = get_network(num_classes, ctx)\n",
    "\n",
    "    train_data, val_data, batch_fn = get_data_rec(\n",
    "            args.input_size, args.crop_ratio, rec_train, rec_train_idx,\n",
    "            rec_val, rec_val_idx, args.batch_size, args.num_workers,\n",
    "            args.jitter_param, args.max_rotate_angle)\n",
    "\n",
    "    trainer = gluon.Trainer(finetune_net.collect_params(), 'sgd', {\n",
    "                            'learning_rate': args.lr, 'momentum': args.momentum, 'wd': args.wd})\n",
    "    metric = mx.metric.Accuracy()\n",
    "    L = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "    lr_counter = 0\n",
    "    for epoch in range(args.epochs):\n",
    "        if epoch == lr_steps[lr_counter]:\n",
    "            print('Decreasing LR to ', trainer.learning_rate*args.lr_factor)\n",
    "            trainer.set_learning_rate(trainer.learning_rate*args.lr_factor)\n",
    "            lr_counter += 1\n",
    "\n",
    "        train_data.reset()\n",
    "        metric.reset()\n",
    "        for i, batch in enumerate(train_data):\n",
    "            data, label = batch_fn(batch, ctx)\n",
    "            with mx.autograd.record():\n",
    "                outputs = [finetune_net(X) for X in data]\n",
    "                loss = [L(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "            for l in loss:\n",
    "                l.backward()\n",
    "\n",
    "            trainer.step(args.batch_size)\n",
    "            metric.update(label, outputs)\n",
    "\n",
    "        _, train_acc = metric.get()\n",
    "        _, val_acc = test(finetune_net, val_data, ctx, batch_fn)\n",
    "\n",
    "        if reporter is not None:\n",
    "            # reporter enables communicatons with autogluon\n",
    "            reporter(epoch=epoch, accuracy=val_acc)\n",
    "        else:\n",
    "            print('[Epoch %d] Train-acc: %.3f | Val-acc: %.3f' %\n",
    "                  (epoch, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### How to convert any training function to enable autogluon HPO?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import autogluon as ag\n",
    "from autogluon import autogluon_register_args\n",
    "from autogluon.utils.mxutils import get_data_rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "@autogluon_register_args(\n",
    "    dataset='apparel',\n",
    "    resume=False,\n",
    "    epochs=ag.ListSpace(80, 40, 120),\n",
    "    lr=ag.LogLinearSpace(1e-4, 1e-2),\n",
    "    lr_factor=ag.LogLinearSpace(0.1, 1),\n",
    "    batch_size=256,\n",
    "    momentum=0.9,\n",
    "    wd=ag.LogLinearSpace(1e-5, 1e-3),\n",
    "    num_gpus=8,\n",
    "    num_workers=30,\n",
    "    input_size=ag.ListSpace(224, 256),\n",
    "    crop_ratio=0.875,\n",
    "    jitter_param=ag.LinearSpace(0.1, 0.4),\n",
    "    max_rotate_angle=ag.IntSpace(0, 10),\n",
    "    remote_file='remote_ips.txt',\n",
    ")\n",
    "def train_finetune(args, reporter):\n",
    "    return train_loop(args, reporter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Create the searcher and scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/git/AutoGluon/examples/worker-jz7vl_u4', purging\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.diskutils - INFO - Found stale lock file and directory '/home/ubuntu/git/AutoGluon/examples/worker-2aa6hc12', purging\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Clear task state\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.dashboard.proxy - INFO - To route to workers diagnostics web server please install jupyter-server-proxy: pip install jupyter-server-proxy\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO -   Scheduler at:  tcp://172.31.23.121:8781\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO -   dashboard at:                     :8787\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Local Directory:    /tmp/scheduler-xw1uzstc\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - -----------------------------------------------\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Remote-1ca9355c-b85d-11e9-bd76-477b68619086\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -       Start worker at:  tcp://172.31.23.121:35737\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -          Listening to:  tcp://172.31.23.121:35737\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -          dashboard at:        172.31.23.121:37324\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - Waiting to connect to:   tcp://172.31.23.121:8781\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -               Threads:                         64\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -                Memory:                  515.70 GB\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -       Local Directory: /home/ubuntu/git/AutoGluon/examples/worker-34avfzeg\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Register tcp://172.31.23.121:35737\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Starting worker compute stream, tcp://172.31.23.121:35737\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO -         Registered to:   tcp://172.31.23.121:8781\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.worker - INFO - -------------------------------------------------\n",
      "[\u001b[1m worker local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "DistributedHyperbandScheduler(\n",
      "DistributedResourceManager{\n",
      "(Remote: Remote REMOTE_ID: 0, \n",
      "\t<Remote: scheduler='tcp://172.31.23.121:8781' processes=0 cores=0>, Resource: NodeResourceManager(64 CPUs, 8 GPUs))\n",
      "})\n",
      "\n"
     ]
    }
   ],
   "source": [
    "searcher = ag.searcher.RandomSampling(train_finetune.cs)\n",
    "args =  train_finetune.args\n",
    "myscheduler = ag.distributed.DistributedHyperbandScheduler(train_finetune,args,\n",
    "                                                           resource={'num_cpus': 16, 'num_gpus': args.num_gpus},\n",
    "                                                           searcher=searcher,\n",
    "                                                           checkpoint='./{}/checkerpoint.ag'.format(args.dataset),\n",
    "                                                           num_trials=300,\n",
    "                                                           resume=args.resume,\n",
    "                                                           time_attr='epoch',\n",
    "                                                           reward_attr=\"accuracy\",\n",
    "                                                           max_t=args.epochs,\n",
    "                                                           grace_period=args.epochs//4)\n",
    "print(myscheduler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Run the experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.scheduler - INFO - Receive client connection: Client-worker-1e20212e-b85d-11e9-bdc6-d16320409407\n",
      "[\u001b[1m scheduler local\u001b[0m ] : distributed.core - INFO - Starting established connection\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:39] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_train.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:39] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_test.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:744: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: .vvvv...\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: v.vv.v..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: vv.v..v.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: vvv....v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: v....vvv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: .v..v.vv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: ..v.vv.v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:41] src/kvstore/././comm.h:753: ...vvvv.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:47] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:16:56] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[ worker local] : rec_train ./datasets/Apparel_train.rec\n",
      "[ worker local] : rec_train_idx ./datasets/Apparel_train.idx\n",
      "[ worker local] : Decreasing LR to  1.636688649144277e-05\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:07] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_train.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:07] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_test.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:744: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: .vvvv...\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: v.vv.v..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: vv.v..v.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: vvv....v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: v....vvv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: .v..v.vv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: ..v.vv.v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:09] src/kvstore/././comm.h:753: ...vvvv.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:22] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:25:40] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[ worker local] : rec_train ./datasets/Apparel_train.rec\n",
      "[ worker local] : rec_train_idx ./datasets/Apparel_train.idx\n",
      "[ worker local] : Decreasing LR to  6.329815405912475e-05\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:04] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_train.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:04] src/io/iter_image_recordio_2.cc:172: ImageRecordIOParser2: ./datasets/Apparel_test.rec, use 30 threads for decoding..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:744: only 32 out of 56 GPU pairs are enabled direct access. It may affect the performance. You can set MXNET_ENABLE_GPU_P2P=0 to turn it off\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: .vvvv...\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: v.vv.v..\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: vv.v..v.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: vvv....v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: v....vvv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: .v..v.vv\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: ..v.vv.v\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:06] src/kvstore/././comm.h:753: ...vvvv.\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:19] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n",
      "[\u001b[1m worker local\u001b[0m ] : [15:34:37] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (set the environment variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\n"
     ]
    }
   ],
   "source": [
    "myscheduler.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Join the tasks and gather the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "myscheduler.join_tasks()\n",
    "myscheduler.get_training_curves(plot=True,use_legend=False)\n",
    "print('The Best Configuration and Accuracy are: {}, {}'.format(myscheduler.get_best_config(),\n",
    "                                                               myscheduler.get_best_reward()))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
