{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Multi-Objective Multi-Fidelity Hyperparameter Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides an example for AutoGluon's multi-objective HPO capabilities. Using the MNIST toy problem we show how to use the MOHyperbandScheduler to search for neural network hyperparameters which lead to networks with accurate and fast predictions.\n",
    "\n",
    "The overall handling is very similar to the standard HyperbandScheduler. The constructor signature differs in two attributes:\n",
    "\n",
    "1. **objectives**: This attribute is used to specify the objectives of interests. It expects a dictionary. The dictionary values  are used to indicate if a particular objective is meant to be maximized (\"MAX\") or minimized (\"MIN\"). \n",
    "2. **scalarization_options**: An additional dictionary can be provided to specify a scalarization technique and its parameters. By default \"Random Weights\" with 100 weight vectors is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict \n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import autogluon.core as ag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X = X / 255.\n",
    "X_train, X_test = X[:60000], X[60000:]\n",
    "y_train, y_test = y[:60000], y[60000:]\n",
    "classes = np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a training function that returns multiple objectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Specify search space for MLPs\n",
    "@ag.args(\n",
    "    n_layers=ag.space.Int(1, 4),\n",
    "    layer_1=ag.space.Int(2, 32),\n",
    "    layer_2=ag.space.Int(2, 32),\n",
    "    layer_3=ag.space.Int(2, 32),\n",
    "    layer_4=ag.space.Int(2, 32),\n",
    "    alpha=ag.space.Real(1e-6, 1e-1, log=True),\n",
    "    learning_rate_init=ag.space.Real(1e-6, 1e-2, log=True),\n",
    "    beta_1=ag.space.Real(0.001, 0.99, log=True),\n",
    "    beta_2=ag.space.Real(0.001, 0.99, log=True),\n",
    "    tol=ag.space.Real(1e-5, 1e-2, log=True),\n",
    "    epochs=20)\n",
    "def train_fn(args, reporter):\n",
    "    \n",
    "    # Initialize model with args\n",
    "    hidden = [args.layer_1, args.layer_2, args.layer_3, args.layer_4][:args.n_layers]\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=hidden,\n",
    "                        alpha=args.alpha,\n",
    "                        learning_rate_init=args.learning_rate_init,\n",
    "                        beta_1=args.beta_1,\n",
    "                        beta_2=args.beta_2,\n",
    "                        tol=args.tol,\n",
    "                        verbose=False)\n",
    "\n",
    "    # Train model iteratively\n",
    "    for e in range(args.epochs):\n",
    "        mlp.partial_fit(X_train, y_train, classes)\n",
    "        train_score = mlp.score(X_train, y_train)\n",
    "        test_score = mlp.score(X_test, y_test)\n",
    "        start = time.time()\n",
    "        mlp.predict(X_train)\n",
    "        prediction_time = time.time() - start\n",
    "        \n",
    "        # Ensure to return all quantities of interest\n",
    "        reporter(epoch=e+1, train_score=train_score, test_score=test_score, prediction_time=prediction_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Objectives are specified as dictionary with indication if they should be \n",
    "# maximized or minimized\n",
    "objectives = {\n",
    "    \"test_score\": \"MAX\",\n",
    "    \"prediction_time\": \"MIN\"\n",
    "}\n",
    "\n",
    "# The scalarization technqiue to be used and its parameters\n",
    "# are provided as a dictionary. There are two different\n",
    "# scalarization methods available\n",
    "random_weights_options = {\n",
    "    \"algorithm\": \"random_weights\",\n",
    "    \"num_weights\": 100\n",
    "}\n",
    "\n",
    "parego_options = {\n",
    "    \"algorithm\": \"parego\",\n",
    "    \"num_weights\": 100,\n",
    "    \"rho\": 0.05,\n",
    "    \"lambda\": 3\n",
    "}\n",
    "\n",
    "scheduler = ag.scheduler.MOHyperbandScheduler(\n",
    "    train_fn,\n",
    "    resource={'num_cpus': 4, 'num_gpus': 0},\n",
    "    num_trials=10,\n",
    "    objectives=objectives,\n",
    "    scalarization_options=random_weights_options,\n",
    "    time_attr='epoch',\n",
    "    grace_period=1,\n",
    "    reduction_factor=3,\n",
    "    type='stopping'\n",
    ")\n",
    "scheduler.run()\n",
    "scheduler.join_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve history for every objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories = defaultdict(list)\n",
    "for task_id, task_res in scheduler.training_history.items():\n",
    "    for res_dict in task_res:\n",
    "        for o in objectives:\n",
    "            histories[o].append(res_dict[o])\n",
    "         \n",
    "    plt.ylabel(list(objectives.keys())[0])\n",
    "    plt.xlabel(list(objectives.keys())[1])\n",
    "    plt.title(\"MO Result\")\n",
    "    plt.scatter(histories[\"test_score\"], histories[\"prediction_time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vmbo",
   "language": "python",
   "name": "vmbo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
