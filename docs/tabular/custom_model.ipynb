{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e6d0f3e",
   "metadata": {},
   "source": [
    "# Custom Models\n",
    "\n",
    "In this tutorial, we will show how to add a custom model to AutoGluon. A custom model can be a new model AutoGluon doesn't have yet, or a model fits your data well. Although you can train your model directly, integrating into AutoGluon allows you to leverage its feature engineering, model selection and combination. \n",
    "\n",
    "AutoGluon's class for a ML model is {class}`autogluon.core.models.AbstractModel`. You need to define your model as its subclass. To do so, you need to implement two methods: \n",
    "\n",
    "- `_process`: transforms the input data to the internal representation usable by the model.\n",
    "- `_fit`: fit your model on the input data\n",
    "\n",
    "In the following example, we wrap scikit-learn's random forest into an AutoGluon model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f8aed78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T20:58:49.476799Z",
     "start_time": "2022-07-13T20:58:49.466745Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from autogluon.core.models import AbstractModel\n",
    "from autogluon.features.generators import LabelEncoderFeatureGenerator\n",
    "\n",
    "class CustomRandomForestModel(AbstractModel):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self._feature_generator = None\n",
    "\n",
    "    # `_preprocess` is called by `preprocess` \n",
    "    def _preprocess(self, X: pd.DataFrame, is_train=False, **kwargs) -> np.ndarray:\n",
    "        X = super()._preprocess(X, **kwargs)\n",
    "        # TODO, explain what's _feature_generator\n",
    "        if is_train:  # called during model fit\n",
    "            self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n",
    "            self._feature_generator.fit(X=X)\n",
    "        if self._feature_generator.features_in:\n",
    "            # This converts categorical features to numeric via stateful label encoding.\n",
    "            X = X.copy()\n",
    "            X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n",
    "        # Handle missing values\n",
    "        return X.fillna(0).to_numpy(dtype=np.float32)\n",
    "\n",
    "    # Note that we ignored some common arguments such as X_val, y_val, time_limit\n",
    "    def _fit(self, X: pd.DataFrame, y: pd.Series, **kwargs):\n",
    "        # Import the required dependencies for the model. \n",
    "        # Importing here rather than outside makes AutoGluon more robust for \n",
    "        # the case the libraries are not available. AutoGluon will still train \n",
    "        # other models.\n",
    "        from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "        # problem_type can be binary, multiclass, regression, quantile, softclass\n",
    "        if self.problem_type in ['regression', 'softclass']:\n",
    "            model_cls = RandomForestRegressor\n",
    "        else:\n",
    "            model_cls = RandomForestClassifier\n",
    "\n",
    "        # Call preprocess instead of _preprocess\n",
    "        X = self.preprocess(X, is_train=True)\n",
    "        # Fetches the user-specified (and default) hyperparameters.\n",
    "        params = self._get_model_params()\n",
    "        self.model = model_cls(**params)\n",
    "        self.model.fit(X, y)\n",
    "    \n",
    "    # Defines the default hyperparameters. We can override them later.\n",
    "    def _set_default_params(self):\n",
    "        default_params = {\n",
    "            'n_estimators': 300,\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 0,\n",
    "        }\n",
    "        for param, val in default_params.items():\n",
    "            self._set_default_param_value(param, val)\n",
    "\n",
    "    # Defines model-agnostic hyperparameters. \n",
    "    # In most cases, you only need to specify the valid/invalid dtypes.\n",
    "    def _get_default_auxiliary_params(self) -> dict:\n",
    "        default_auxiliary_params = super()._get_default_auxiliary_params()\n",
    "        # all raw dtypes are: ['int', 'float', 'category', 'object', 'datetime']\n",
    "        # objects can be raw texts and image paths.\n",
    "        default_auxiliary_params.update(\n",
    "            {'valid_raw_types': ['int', 'float', 'category']})\n",
    "        return default_auxiliary_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076c5afd",
   "metadata": {},
   "source": [
    "```{seealso}\n",
    "You can check the source code for {class}`autogluon.tabular.models.RFModel` for the official AutoGluon random forest implementation.\n",
    "```\n",
    "\n",
    "Now let's train ... \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "148ff847",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T20:47:58.983008Z",
     "start_time": "2022-07-13T20:47:57.570416Z"
    }
   },
   "outputs": [],
   "source": [
    "#@title Load the knot theory data\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/mli/ag-docs/main/knot_theory/'\n",
    "train_data = TabularDataset(url+'train.csv')\n",
    "test_data = TabularDataset(url+'test.csv')\n",
    "label = 'signature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76de9235",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T21:00:25.908111Z",
     "start_time": "2022-07-13T20:59:24.196264Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220713_205924/\"\n",
      "Warning: hyperparameter tuning is currently experimental and may cause the process to hang.\n",
      "Beginning AutoGluon training ... Time limit = 60s\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220713_205924/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    10000\n",
      "Train Data Columns: 18\n",
      "Label Column: signature\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 13) unique label values:  [-2, 0, 2, -8, 4, -4, -6, 8, 6, 10]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 9 out of 13 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9984\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    240190.4 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.44 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Symmetry_D8']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])   :  3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])       : 3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\t\t('int', ['bool']) : 5 | ['Symmetry_0', 'Symmetry_D3', 'Symmetry_D4', 'Symmetry_D6', 'Symmetry_Z/2 + Z/2']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 7987, Val Rows: 1997\n",
      "Custom Model Type Detected: <class '__main__.CustomRandomForestModel'>\n",
      "Fitting 1 L1 models ...\n",
      "Hyperparameter tuning model: CustomRandomForestModel ... Tuning model for up to 53.93s of the 59.92s of remaining time.\n",
      "\tStopping HPO to satisfy time limit...\n",
      "Fitted model: CustomRandomForestModel/T1 ...\n",
      "\t0.696\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T2 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.11s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T3 ...\n",
      "\t0.9339\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T4 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.2s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T5 ...\n",
      "\t0.9234\t = Validation score   (accuracy)\n",
      "\t1.01s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T6 ...\n",
      "\t0.8803\t = Validation score   (accuracy)\n",
      "\t0.92s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T7 ...\n",
      "\t0.9504\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T8 ...\n",
      "\t0.9424\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T9 ...\n",
      "\t0.9419\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T10 ...\n",
      "\t0.9479\t = Validation score   (accuracy)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T11 ...\n",
      "\t0.8568\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T12 ...\n",
      "\t0.9464\t = Validation score   (accuracy)\n",
      "\t1.05s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T13 ...\n",
      "\t0.9464\t = Validation score   (accuracy)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T14 ...\n",
      "\t0.8332\t = Validation score   (accuracy)\n",
      "\t0.83s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T15 ...\n",
      "\t0.8538\t = Validation score   (accuracy)\n",
      "\t0.98s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T16 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T17 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T18 ...\n",
      "\t0.696\t = Validation score   (accuracy)\n",
      "\t0.79s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T19 ...\n",
      "\t0.9469\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T20 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.27s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T21 ...\n",
      "\t0.9484\t = Validation score   (accuracy)\n",
      "\t1.19s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T22 ...\n",
      "\t0.8758\t = Validation score   (accuracy)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T23 ...\n",
      "\t0.9509\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T24 ...\n",
      "\t0.9484\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T25 ...\n",
      "\t0.8423\t = Validation score   (accuracy)\n",
      "\t0.91s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T26 ...\n",
      "\t0.9494\t = Validation score   (accuracy)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T27 ...\n",
      "\t0.9464\t = Validation score   (accuracy)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T28 ...\n",
      "\t0.9464\t = Validation score   (accuracy)\n",
      "\t1.0s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T29 ...\n",
      "\t0.9514\t = Validation score   (accuracy)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T30 ...\n",
      "\t0.9474\t = Validation score   (accuracy)\n",
      "\t1.06s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T31 ...\n",
      "\t0.9514\t = Validation score   (accuracy)\n",
      "\t1.13s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fitted model: CustomRandomForestModel/T32 ...\n",
      "\t0.9514\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T33 ...\n",
      "\t0.9494\t = Validation score   (accuracy)\n",
      "\t1.68s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T34 ...\n",
      "\t0.8668\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T35 ...\n",
      "\t0.9529\t = Validation score   (accuracy)\n",
      "\t1.43s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T36 ...\n",
      "\t0.9124\t = Validation score   (accuracy)\n",
      "\t0.95s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T37 ...\n",
      "\t0.9504\t = Validation score   (accuracy)\n",
      "\t1.37s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T38 ...\n",
      "\t0.8518\t = Validation score   (accuracy)\n",
      "\t0.94s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T39 ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.3s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitted model: CustomRandomForestModel/T40 ...\n",
      "\t0.9169\t = Validation score   (accuracy)\n",
      "\t1.46s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 59.92s of the -1.18s of remaining time.\n",
      "\t0.9534\t = Validation score   (accuracy)\n",
      "\t0.48s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 61.7s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220713_205924/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.core.space import Categorical, Int, Real\n",
    "\n",
    "# TODO: these hps were not set before, need to explain.\n",
    "custom_hyperparameters_hpo = {CustomRandomForestModel: {\n",
    "    'max_depth': Int(lower=5, upper=30),\n",
    "    'max_features': Real(lower=0.1, upper=1.0),\n",
    "    'criterion': Categorical('gini', 'entropy'),\n",
    "}}\n",
    "\n",
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data, hyperparameters=custom_hyperparameters_hpo,\n",
    "    hyperparameter_tune_kwargs='auto', \n",
    "    time_limit=60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f3fe444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T21:05:25.034337Z",
     "start_time": "2022-07-13T21:05:17.170498Z"
    }
   },
   "outputs": [],
   "source": [
    "best_model = predictor.leaderboard(silent=True).iloc[1]['model']\n",
    "best_config = predictor.info()['model_info'][best_model]['hyperparameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "345ce9cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T21:06:03.347656Z",
     "start_time": "2022-07-13T21:06:03.344190Z"
    }
   },
   "outputs": [],
   "source": [
    "from autogluon.tabular.configs.hyperparameter_configs import get_hyperparameter_config\n",
    "\n",
    "custom_hyperparameters = get_hyperparameter_config('default')\n",
    "custom_hyperparameters[CustomRandomForestModel] = best_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d553d4",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "935f1926",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T21:08:32.833572Z",
     "start_time": "2022-07-13T21:06:51.565720Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20220713_210651/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20220713_210651/\"\n",
      "AutoGluon Version:  0.5.0\n",
      "Python Version:     3.9.12\n",
      "Operating System:   Linux\n",
      "Train Data Rows:    10000\n",
      "Train Data Columns: 18\n",
      "Label Column: signature\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == int, but few unique label-values observed).\n",
      "\tFirst 10 (of 13) unique label values:  [-2, 0, 2, -8, 4, -4, -6, 8, 6, 10]\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 9 out of 13 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9984\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    240085.72 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.44 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 5 features to boolean dtype as they only contain 2 unique values.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUseless Original Features (Count: 1): ['Symmetry_D8']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 14 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])   :  3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', [])     : 9 | ['chern_simons', 'cusp_volume', 'injectivity_radius', 'longitudinal_translation', 'meridinal_translation_imag', ...]\n",
      "\t\t('int', [])       : 3 | ['Unnamed: 0', 'hyperbolic_adjoint_torsion_degree', 'hyperbolic_torsion_degree']\n",
      "\t\t('int', ['bool']) : 5 | ['Symmetry_0', 'Symmetry_D3', 'Symmetry_D4', 'Symmetry_D6', 'Symmetry_Z/2 + Z/2']\n",
      "\t0.1s = Fit runtime\n",
      "\t17 features in original data used to generate 17 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.01 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.08s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Automatically generating train/validation split with holdout_frac=0.1, Train Rows: 8985, Val Rows: 999\n",
      "Custom Model Type Detected: <class '__main__.CustomRandomForestModel'>\n",
      "Fitting 14 L1 models ...\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.2232\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.2132\t = Validation score   (accuracy)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "\t0.9439\t = Validation score   (accuracy)\n",
      "\t9.55s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.9459\t = Validation score   (accuracy)\n",
      "\t5.36s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.956\t = Validation score   (accuracy)\n",
      "\t3.9s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.9429\t = Validation score   (accuracy)\n",
      "\t1.17s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t1.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "/home/ubuntu/miniconda3/envs/ag/lib/python3.9/site-packages/xgboost/compat.py:31: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "\t0.956\t = Validation score   (accuracy)\n",
      "\t18.07s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.9469\t = Validation score   (accuracy)\n",
      "\t1.12s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.9399\t = Validation score   (accuracy)\n",
      "\t0.93s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n",
      "\t0.957\t = Validation score   (accuracy)\n",
      "\t6.11s\t = Training   runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetTorch ...\n",
      "\t0.9389\t = Validation score   (accuracy)\n",
      "\t38.41s\t = Training   runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.9499\t = Validation score   (accuracy)\n",
      "\t9.68s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: CustomRandomForestModel ...\n",
      "\t0.9459\t = Validation score   (accuracy)\n",
      "\t1.6s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.966\t = Validation score   (accuracy)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 101.25s ... Best model: \"WeightedEnsemble_L2\"\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20220713_210651/\")\n"
     ]
    }
   ],
   "source": [
    "predictor = TabularPredictor(label=label).fit(\n",
    "    train_data, hyperparameters=custom_hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "890ffb90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-13T21:14:44.700902Z",
     "start_time": "2022-07-13T21:14:42.729033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_test</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_test</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_test_marginal</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.965966</td>\n",
       "      <td>0.453382</td>\n",
       "      <td>0.165812</td>\n",
       "      <td>17.925526</td>\n",
       "      <td>0.006438</td>\n",
       "      <td>0.000571</td>\n",
       "      <td>0.670520</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>0.955956</td>\n",
       "      <td>0.068570</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>3.902843</td>\n",
       "      <td>0.068570</td>\n",
       "      <td>0.027067</td>\n",
       "      <td>3.902843</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.9448</td>\n",
       "      <td>0.956957</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>6.111501</td>\n",
       "      <td>0.062688</td>\n",
       "      <td>0.019377</td>\n",
       "      <td>6.111501</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.9444</td>\n",
       "      <td>0.949950</td>\n",
       "      <td>0.155716</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>9.678791</td>\n",
       "      <td>0.155716</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>9.678791</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>0.955956</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>18.071039</td>\n",
       "      <td>0.019610</td>\n",
       "      <td>0.008976</td>\n",
       "      <td>18.071039</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CustomRandomForestModel</td>\n",
       "      <td>0.9424</td>\n",
       "      <td>0.945946</td>\n",
       "      <td>0.165466</td>\n",
       "      <td>0.119914</td>\n",
       "      <td>1.596552</td>\n",
       "      <td>0.165466</td>\n",
       "      <td>0.119914</td>\n",
       "      <td>1.596552</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.949950</td>\n",
       "      <td>0.175203</td>\n",
       "      <td>0.119092</td>\n",
       "      <td>1.092610</td>\n",
       "      <td>0.175203</td>\n",
       "      <td>0.119092</td>\n",
       "      <td>1.092610</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.9380</td>\n",
       "      <td>0.943944</td>\n",
       "      <td>0.218790</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>9.546953</td>\n",
       "      <td>0.218790</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>9.546953</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     model  score_test  score_val  pred_time_test  \\\n",
       "0      WeightedEnsemble_L2      0.9498   0.965966        0.453382   \n",
       "1                 LightGBM      0.9456   0.955956        0.068570   \n",
       "2                  XGBoost      0.9448   0.956957        0.062688   \n",
       "3            LightGBMLarge      0.9444   0.949950        0.155716   \n",
       "4                 CatBoost      0.9432   0.955956        0.019610   \n",
       "5  CustomRandomForestModel      0.9424   0.945946        0.165466   \n",
       "6         RandomForestEntr      0.9388   0.949950        0.175203   \n",
       "7          NeuralNetFastAI      0.9380   0.943944        0.218790   \n",
       "\n",
       "   pred_time_val   fit_time  pred_time_test_marginal  pred_time_val_marginal  \\\n",
       "0       0.165812  17.925526                 0.006438                0.000571   \n",
       "1       0.027067   3.902843                 0.068570                0.027067   \n",
       "2       0.019377   6.111501                 0.062688                0.019377   \n",
       "3       0.035261   9.678791                 0.155716                0.035261   \n",
       "4       0.008976  18.071039                 0.019610                0.008976   \n",
       "5       0.119914   1.596552                 0.165466                0.119914   \n",
       "6       0.119092   1.092610                 0.175203                0.119092   \n",
       "7       0.025950   9.546953                 0.218790                0.025950   \n",
       "\n",
       "   fit_time_marginal  stack_level  can_infer  fit_order  \n",
       "0           0.670520            2       True         15  \n",
       "1           3.902843            1       True          5  \n",
       "2           6.111501            1       True         11  \n",
       "3           9.678791            1       True         13  \n",
       "4          18.071039            1       True          8  \n",
       "5           1.596552            1       True         14  \n",
       "6           1.092610            1       True          7  \n",
       "7           9.546953            1       True          3  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(test_data, silent=True).head(n=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b0dc1c",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
