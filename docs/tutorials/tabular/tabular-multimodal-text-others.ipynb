{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bef65a7",
   "metadata": {},
   "source": [
    "# Multimodal Data Tables: Combining BERT/Transformers and Classical Tabular Models\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/new/docs/tutorials/tabular/tabular-multimodal-text-others.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/new/docs/tutorials/tabular/tabular-multimodal-text-others.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Tip**: If your data contains images, consider also checking out [Multimodal Data Tables: Tabular, Text, and Image](http://auto.gluon.ai/new/tutorials/tabular/tabular-multimodal.ipynb#multimodal-data-tables:-tabular,-text,-and-image) which handles images in addition to text and tabular features.\n",
    "\n",
    "Here we introduce how to use AutoGluon Tabular to deal with multimodal tabular data that contains text, numeric, and categorical columns. In AutoGluon, **raw text data** is considered as a first-class citizen of data tables. AutoGluon Tabular can help you train and combine a diverse set of models including classical tabular models like LightGBM/RF/CatBoost as well as our pretrained NLP model based multimodal network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770bd4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import random\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "np.random.seed(123)\n",
    "random.seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbf38a1",
   "metadata": {},
   "source": [
    "## Product Sentiment Analysis Dataset\n",
    "\n",
    "We consider the product sentiment analysis dataset from a [MachineHack hackathon](https://www.machinehack.com/hackathons/product_sentiment_classification_weekend_hackathon_19/leaderboard). The goal is to predict a user's sentiment towards a product given their review (raw text) and a categorical feature indicating the product's type (e.g., Tablet, Mobile, etc.). We have already split the original dataset to be 90% for training and 10% for development/testing (if submitting your models to the hackathon, we recommend training them on 100% of the dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c96f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p product_sentiment_machine_hack\n",
    "!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/train.csv -O product_sentiment_machine_hack/train.csv\n",
    "!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/dev.csv -O product_sentiment_machine_hack/dev.csv\n",
    "!wget https://autogluon-text-data.s3.amazonaws.com/multimodal_text/machine_hack_product_sentiment/test.csv -O product_sentiment_machine_hack/test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2114ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_size = 2000  # for quick demo, try setting to larger values\n",
    "feature_columns = ['Product_Description', 'Product_Type']\n",
    "label = 'Sentiment'\n",
    "\n",
    "train_df = pd.read_csv('product_sentiment_machine_hack/train.csv', index_col=0).sample(2000, random_state=123)\n",
    "dev_df = pd.read_csv('product_sentiment_machine_hack/dev.csv', index_col=0)\n",
    "test_df = pd.read_csv('product_sentiment_machine_hack/test.csv', index_col=0)\n",
    "\n",
    "train_df = train_df[feature_columns + [label]]\n",
    "dev_df = dev_df[feature_columns + [label]]\n",
    "test_df = test_df[feature_columns]\n",
    "print('Number of training samples:', len(train_df))\n",
    "print('Number of dev samples:', len(dev_df))\n",
    "print('Number of test samples:', len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359881df",
   "metadata": {},
   "source": [
    "There are two features in the dataset: the users' review of the product and the product's type, and four possible classes to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6089e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ec510",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8713001c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e812ce",
   "metadata": {},
   "source": [
    "## AutoGluon Tabular with Multimodal Support\n",
    "\n",
    "To utilize the `TextPredictor` model inside of `TabularPredictor`, we must specify the `hyperparameters = 'multimodal'` in AutoGluon Tabular. Internally, this will train multiple tabular models as well as the TextPredictor model, and then combine them via either a weighted ensemble or stack ensemble, as  explained in [AutoGluon Tabular Paper](https://arxiv.org/pdf/2003.06505.pdf). If you do not specify `hyperparameters = 'multimodal'`, then AutoGluon Tabular will simply featurize text fields using N-grams and train only tabular models (which may work better if your text is mostly uncommon strings/vocabulary)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "predictor = TabularPredictor(label='Sentiment', path='ag_tabular_product_sentiment_multimodal')\n",
    "predictor.fit(train_df, hyperparameters='multimodal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1864dfd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(dev_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beba9b5c",
   "metadata": {},
   "source": [
    "## Improve the Performance with Stack Ensemble\n",
    "\n",
    "You can improve predictive performance by using stack ensembling. One way to turn it on is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89bb570",
   "metadata": {},
   "source": [
    "```\n",
    "predictor.fit(train_df, hyperparameters='multimodal', num_bag_folds=5, num_stack_levels=1)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62672d4b",
   "metadata": {},
   "source": [
    "or using:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c6c85e",
   "metadata": {},
   "source": [
    "```\n",
    "predictor.fit(train_df, hyperparameters='multimodal', presets='best_quality')\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ec9ff7",
   "metadata": {},
   "source": [
    "which will automatically select values for `num_stack_levels` (how many stacking layers) and `num_bag_folds` (how many folds to split data into during bagging).\n",
    "Stack ensembling can take much longer, so we won't run with this configuration here. You may explore more examples in https://github.com/autogluon/autogluon/tree/master/examples/text_prediction, which demonstrate how you can achieve top performance in competitions with a stack ensembling based solution."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}