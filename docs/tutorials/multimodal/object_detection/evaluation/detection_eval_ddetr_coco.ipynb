{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b66e08c",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Evaluate Pretrained Deformable DETR on COCO Format Dataset\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/object_detection/evaluation/detection_eval_ddetr_coco.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/object_detection/evaluation/detection_eval_ddetr_coco.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "In this section, our goal is to evaluate Deformable DETR model on COCO17 dataset in COCO format. \n",
    "Previously we introduced two classic models: [AutoMM Detection - Evaluate Pretrained YOLOv3 on COCO Format Dataset](detection_eval_yolov3_coco.ipynb) and [AutoMM Detection - Evaluate Pretrained Faster R-CNN on COCO Format Dataset](detection_eval_fasterrcnn_coco.ipynb).\n",
    "Recent years Transformer models become more and more popular in Computer Vision, and Deformable DEtection TRansformer (Deformable DETR) reached the SOTA performance in detection task.\n",
    "In terms of speed, it's slower than YOLOv3 and Faster-RCNN, but it also has higher performance.\n",
    "\n",
    "To start, let's import MultiModalPredictor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3695d",
   "metadata": {},
   "source": [
    "```python\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b3f7d9",
   "metadata": {},
   "source": [
    "We select the two-stage Deformable DETR with ResNet50 as backbone with bounding box finetune,\n",
    "this model has **15.7 frames per second (FPS)** on single A10e GPU with `batch_size=1`.\n",
    "And we use all the GPUs (if any):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7b569",
   "metadata": {},
   "source": [
    "```python\n",
    "checkpoint_name = \"deformable_detr_twostage_refine_r50_16x2_50e_coco\"\n",
    "num_gpus = -1  # use all GPUs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb56366a",
   "metadata": {},
   "source": [
    "We create the MultiModalPredictor with selected checkpoint name and number of GPUs.\n",
    "We also need to specify the problem_type to `\"object_detection\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a492fd",
   "metadata": {},
   "source": [
    "```python\n",
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8589265",
   "metadata": {},
   "source": [
    "Here we use COCO17 for testing. \n",
    "See other tutorials for [AutoMM Detection - Prepare COCO2017 Dataset](../data_preparation/prepare_coco17.ipynb).\n",
    "While using COCO dataset, the input is the json annotation file of the dataset split.\n",
    "In this example, `instances_val2017.json` is the annotation file of validation split of COCO17 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33be86",
   "metadata": {},
   "source": [
    "```python\n",
    "test_path = \"coco17/annotations/instances_val2017.json\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25a88f0",
   "metadata": {},
   "source": [
    "To evaluate the pretrained Deformable DETR model we loaded, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246c350a",
   "metadata": {},
   "source": [
    "```python\n",
    "predictor.evaluate(test_path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d03b8fe",
   "metadata": {},
   "source": [
    "And the evaluation results are shown in command line output. The first value `0.463` is mAP in COCO standard, and the second one `0.659` is mAP in VOC standard (or mAP50). For more details about these metrics, see [COCO's evaluation guideline](https://cocodataset.org/#detection-eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26198fe2",
   "metadata": {},
   "source": [
    "```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.463\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.659\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.500\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.298\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.493\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.607\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.358\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.603\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.652\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.451\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.692\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.830\n",
    "time usage: 389.92\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b63dbb",
   "metadata": {},
   "source": [
    "Deformable DETR has best performance but takes more time and (GPU memory) space. \n",
    "If there is a restriction in time or space, \n",
    "see [AutoMM Detection - Evaluate Pretrained Faster R-CNN on COCO Format Dataset](detection_eval_fasterrcnn_coco.ipynb) or [AutoMM Detection - Evaluate Pretrained YOLOv3 on COCO Format Dataset](detection_eval_yolov3_coco.ipynb).\n",
    "You can also see other tutorials for [AutoMM Detection - High Performance Finetune on COCO Format Dataset](../finetune/detection_high_performance_finetune_coco.ipynb) or [AutoMM Detection - High Performance Finetune on COCO Format Dataset](../finetune/detection_high_performance_finetune_coco.ipynb).\n",
    "\n",
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/autogluon/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to [Customize AutoMM](../../advanced_topics/customization.ipynb).\n",
    "\n",
    "## Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab81970",
   "metadata": {},
   "source": [
    "```\n",
    "@inproceedings{\n",
    "zhu2021deformable,\n",
    "title={Deformable DETR: Deformable Transformers for End-to-End Object Detection},\n",
    "author={Xizhou Zhu and Weijie Su and Lewei Lu and Bin Li and Xiaogang Wang and Jifeng Dai},\n",
    "booktitle={International Conference on Learning Representations},\n",
    "year={2021},\n",
    "url={https://openreview.net/forum?id=gZ9hCDWe6ke}\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}