{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2124a2b",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Evaluate Pretrained YOLOv3 on COCO Format Dataset\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/new/docs/tutorials/multimodal/object_detection/evaluation/detection_eval_yolov3_coco.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/new/docs/tutorials/multimodal/object_detection/evaluation/detection_eval_yolov3_coco.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "In this section, our goal is to evaluate YOLOv3 model on COCO17 dataset in COCO format. We start with yolov3 because it's extremely fast and accurate, and is a good choice to deploy with strict time and computational restrictions.\n",
    "\n",
    "To start, let's import MultiModalPredictor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c045399d",
   "metadata": {},
   "source": [
    "```python\n",
    "from autogluon.multimodal import MultiModalPredictor\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0654ca",
   "metadata": {},
   "source": [
    "We select the YOLOv3 with MobileNetV2 as backbone, \n",
    "this model reached **85.0 Frames Per Second (FPS)** on single A10e GPU with `batch_size=1`.\n",
    "And we use all the GPUs (if any):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718540aa",
   "metadata": {},
   "source": [
    "```python\n",
    "checkpoint_name = \"yolov3_mobilenetv2_320_300e_coco\"\n",
    "num_gpus = -1  # use all GPUs\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3c0e88",
   "metadata": {},
   "source": [
    "We create the MultiModalPredictor with selected checkpoint name and number of GPUs.\n",
    "We also need to specify the problem_type to `\"object_detection\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d74a009",
   "metadata": {},
   "source": [
    "```python\n",
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    ")\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd288f8a",
   "metadata": {},
   "source": [
    "Here we use COCO17 for testing. \n",
    "See other tutorials for [AutoMM Detection - Prepare COCO2017 Dataset](http://auto.gluon.ai/new/tutorials/multimodal/object_detection/data_preparation/prepare_coco17.ipynb#automm-detection---prepare-coco2017-dataset).\n",
    "While using COCO dataset, the input is the json annotation file of the dataset split.\n",
    "In this example, `instances_val2017.json` is the annotation file of validation split of COCO17 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92bc725",
   "metadata": {},
   "source": [
    "```python\n",
    "test_path = \"coco17/annotations/instances_val2017.json\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25325330",
   "metadata": {},
   "source": [
    "To evaluate the pretrained YOLOv3 model we loaded, run:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af673365",
   "metadata": {},
   "source": [
    "```python\n",
    "predictor.evaluate(test_path)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeed659",
   "metadata": {},
   "source": [
    "And the evaluation results are shown in command line output. The first value `0.223` is mAP in COCO standard, and the second one `0.420` is mAP in VOC standard (or mAP50). For more details about these metrics, see [COCO's evaluation guideline](https://cocodataset.org/#detection-eval)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee99278",
   "metadata": {},
   "source": [
    "```\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.223\n",
    " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.420\n",
    " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.215\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.060\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.237\n",
    " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.358\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.215\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.333\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.352\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.137\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.385\n",
    " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.529\n",
    "time usage: 81.76\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ee0d2d",
   "metadata": {},
   "source": [
    "YOLOv3 is small and fast. For larger model with higher performance, see [AutoMM Detection - Evaluate Pretrained Faster R-CNN on COCO Format Dataset](http://auto.gluon.ai/new/tutorials/multimodal/object_detection/evaluation/detection_eval_fasterrcnn_coco.ipynb#automm-detection---evaluate-pretrained-faster-r-cnn-on-coco-format-dataset) or [AutoMM Detection - Evaluate Pretrained Deformable DETR on COCO Format Dataset](http://auto.gluon.ai/new/tutorials/multimodal/object_detection/evaluation/detection_eval_ddetr_coco.ipynb#automm-detection---evaluate-pretrained-deformable-detr-on-coco-format-dataset).\n",
    "You can also see other tutorials for [AutoMM Detection - Fast Finetune on COCO Format Dataset](http://auto.gluon.ai/new/tutorials/multimodal/object_detection/finetune/detection_fast_finetune_coco.ipynb#automm-detection---fast-finetune-on-coco-format-dataset) or [AutoMM Detection - High Performance Finetune on COCO Format Dataset](http://auto.gluon.ai/new/tutorials/multimodal/object_detection/finetune/detection_high_performance_finetune_coco.ipynb#automm-detection---high-performance-finetune-on-coco-format-dataset).\n",
    "\n",
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/autogluon/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to [Customize AutoMM](http://auto.gluon.ai/new/tutorials/multimodal/advanced_topics/customization.ipynb#customize-automm).\n",
    "\n",
    "## Citation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92d55c1",
   "metadata": {},
   "source": [
    "```\n",
    "@misc{redmon2018yolov3,\n",
    "    title={YOLOv3: An Incremental Improvement},\n",
    "    author={Joseph Redmon and Ali Farhadi},\n",
    "    year={2018},\n",
    "    eprint={1804.02767},\n",
    "    archivePrefix={arXiv},\n",
    "    primaryClass={cs.CV}\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}