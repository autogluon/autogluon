{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea81dd8a",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Prepare Pascal VOC Dataset\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/object_detection/data_preparation/prepare_voc.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/object_detection/data_preparation/prepare_voc.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "[Pascal VOC](http://host.robots.ox.ac.uk/pascal/VOC/) is a collection of datasets for object detection. \n",
    "The most commonly combination for benchmarking is using VOC2007 trainval and VOC2012 trainval for training and VOC2007 test for validation.\n",
    "Both VOC2007 and VOC2012 have the same 20 classes, and they have 16551 training images in total.\n",
    "This tutorial will walk through the steps of preparing both VOC2007 and VOC2012 for Autogluon MultiModalPredictor.\n",
    "\n",
    "You need 8.4 GB disk space to download and extract this dataset. SSD is preferred over HDD because of its better performance.\n",
    "The total time to prepare the dataset depends on your Internet speed and disk performance. For example, it often takes 10 min on AWS EC2 with EBS.\n",
    "\n",
    "VOC has an [official webpage](http://host.robots.ox.ac.uk/pascal/VOC/) to download the data, \n",
    "but it's always easier to perform a one-step setup.\n",
    "We prepared a script to download both VOC2007 and VOC2012 in our examples: \n",
    "[download_voc0712.sh](https://raw.githubusercontent.com/autogluon/autogluon/master/examples/automm/object_detection/download_voc0712.sh).\n",
    "You can also download them separately:\n",
    "[download_voc07.sh](https://raw.githubusercontent.com/autogluon/autogluon/master/examples/automm/object_detection/download_voc07.sh),\n",
    "[download_voc12.sh](https://raw.githubusercontent.com/autogluon/autogluon/master/examples/automm/object_detection/download_voc12.sh).\n",
    "Or you can also use our cli tool `prepare_detection_dataset` that can download all datasets mentioned in our tutorials.\n",
    "This python script is in our code: \n",
    "[prepare_detection_dataset.py](https://raw.githubusercontent.com/autogluon/autogluon/master/multimodal/src/autogluon/multimodal/cli/prepare_detection_dataset.py),\n",
    "and you can also run it as a cli: `python3 -m autogluon.multimodal.cli.prepare_detection_dataset`.\n",
    "\n",
    "## Download with Python Script\n",
    "\n",
    "The python script does not show progress bar, but is promised to work on all major platforms.\n",
    "If you are working on a Unix system and needs a progress bar, try the bash script!\n",
    "\n",
    "You could either extract it under current directory by running:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0531ce4",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name voc0712\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7939e2",
   "metadata": {},
   "source": [
    "or extract it under a provided output path:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b8cb0",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name voc0712 --output_path ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e191c23",
   "metadata": {},
   "source": [
    "or make it shorter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e345e7",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset -d voc -o ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ce32e",
   "metadata": {},
   "source": [
    "or download them separately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12965978",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset -d voc07 -o ~/data\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset -d voc12 -o ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c8814e",
   "metadata": {},
   "source": [
    "## Download with Bash Script\n",
    "\n",
    "You could either extract it under current directory by running:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3766a060",
   "metadata": {},
   "source": [
    "```\n",
    "bash download_voc0712.sh\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9082a174",
   "metadata": {},
   "source": [
    "or extract it under a provided output path:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905c1fe5",
   "metadata": {},
   "source": [
    "```\n",
    "bash download_voc0712.sh ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad980a7",
   "metadata": {},
   "source": [
    "The command line output will show the progress bar:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db444bd",
   "metadata": {},
   "source": [
    "```\n",
    "extract data in current directory\n",
    "Downloading VOC2007 trainval ...\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "100  438M  100  438M    0     0  92.3M      0  0:00:04  0:00:04 --:--:-- 95.5M\n",
    "Downloading VOC2007 test data ...\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    "100  430M  100  430M    0     0  96.5M      0  0:00:04  0:00:04 --:--:-- 99.1M\n",
    "Downloading VOC2012 trainval ...\n",
    "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
    "                                 Dload  Upload   Total   Spent    Left  Speed\n",
    " 73 1907M   73 1401M    0     0   108M      0  0:00:17  0:00:12  0:00:05  118M\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd92290",
   "metadata": {},
   "source": [
    "And after it finished, VOC datasets are extracted in folder `VOCdevkit`, it contains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11fd356a",
   "metadata": {},
   "source": [
    "```\n",
    "VOC2007  VOC2012\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d263b3",
   "metadata": {},
   "source": [
    "And both of them contains:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2932be",
   "metadata": {},
   "source": [
    "```\n",
    "Annotations  ImageSets  JPEGImages  SegmentationClass  SegmentationObject\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a58b659",
   "metadata": {},
   "source": [
    "## The VOC Format\n",
    "VOC also refers to the specific format (in `.xml` file) the VOC dataset is using.\n",
    "\n",
    "**In Autogluon MultiModalPredictor, we strongly recommend using COCO as your data format instead.\n",
    "Check [AutoMM Detection - Prepare COCO2017 Dataset](prepare_coco17.ipynb) and [Convert Data to COCO Format](convert_data_to_coco_format.ipynb) for more information\n",
    "about COCO dataset and how to convert a VOC dataset to COCO.**\n",
    "\n",
    "However, for fast proof testing we also have limit support for VOC format.\n",
    "While using VOC format dataset, the input is the root path of the dataset, and contains at least:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8eafbeb",
   "metadata": {},
   "source": [
    "```\n",
    "Annotations  ImageSets  JPEGImages\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c238bbf7",
   "metadata": {},
   "source": [
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/autogluon/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to [Customize AutoMM](../../advanced_topics/customization.ipynb).\n",
    "\n",
    "## Citation\n",
    "```\n",
    "@Article{Everingham10,\n",
    "   author = \"Everingham, M. and Van~Gool, L. and Williams, C. K. I. and Winn, J. and Zisserman, A.\",\n",
    "   title = \"The Pascal Visual Object Classes (VOC) Challenge\",\n",
    "   journal = \"International Journal of Computer Vision\",\n",
    "   volume = \"88\",\n",
    "   year = \"2010\",\n",
    "   number = \"2\",\n",
    "   month = jun,\n",
    "   pages = \"303--338\",\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}