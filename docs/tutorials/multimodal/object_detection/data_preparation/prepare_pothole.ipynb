{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "628eb02f",
   "metadata": {},
   "source": [
    "# AutoMM Detection - Prepare Pothole Dataset\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/stable/docs/tutorials/multimodal/object_detection/data_preparation/prepare_pothole.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/stable/docs/tutorials/multimodal/object_detection/data_preparation/prepare_pothole.ipynb)\n",
    "\n",
    "\n",
    "\n",
    "[Pothole](https://www.kaggle.com/datasets/andrewmvd/pothole-detection) is a small object detection dataset with 665 images,\n",
    "and has a specific domain, i.e. potholes on the road. This dataset will be used to show how to [AutoMM Detection - Fast Finetune on COCO Format Dataset](../finetune/detection_fast_finetune_coco.ipynb) and [AutoMM Detection - High Performance Finetune on COCO Format Dataset](../finetune/detection_high_performance_finetune_coco.ipynb).\n",
    "\n",
    "You need 1 GB disk space to download and extract this dataset. SSD is preferred over HDD because of its better performance.\n",
    "The total time to prepare the dataset depends on your Internet speed and disk performance. For example, it often takes 3 min on AWS EC2 with EBS.\n",
    "\n",
    "You can download the dataset from its [kaggle page](https://www.kaggle.com/datasets/andrewmvd/pothole-detection).\n",
    "Or you can also use our cli tool `prepare_detection_dataset` that can download all datasets mentioned in our tutorials.\n",
    "This python script is in our code: \n",
    "[prepare_detection_dataset.py](https://raw.githubusercontent.com/autogluon/autogluon/master/multimodal/src/autogluon/multimodal/cli/prepare_detection_dataset.py),\n",
    "and you can also run it as a cli: `python3 -m autogluon.multimodal.cli.prepare_detection_dataset`.\n",
    "\n",
    "## Download with Python Script\n",
    "\n",
    "You could either extract it in pothole folder under current directory by running:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b21fef4",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name pothole\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac579297",
   "metadata": {},
   "source": [
    "or extract it in pothole folder under a provided output path:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd58f9a",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset --dataset_name pothole --output_path ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0823af3c",
   "metadata": {},
   "source": [
    "or make it shorter:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4298ed07",
   "metadata": {},
   "source": [
    "```\n",
    "python3 -m autogluon.multimodal.cli.prepare_detection_dataset -d pothole -o ~/data\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e006cb",
   "metadata": {},
   "source": [
    "The dataset downloaded with the provided tool is in COCO format and split to train/validation/test set with ratio 3:1:1.\n",
    "And the annotation files are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f56c4b",
   "metadata": {},
   "source": [
    "```\n",
    "pothole/Annotations/usersplit_train_cocoformat.json\n",
    "pothole/Annotations/usersplit_val_cocoformat.json\n",
    "pothole/Annotations/usersplit_test_cocoformat.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd368d",
   "metadata": {},
   "source": [
    "## If You Download From Kaggle\n",
    "\n",
    "Original Pothole dataset is in VOC format and is not split. **In Autogluon MultiModalPredictor, we strongly recommend using COCO as your data format instead.\n",
    "Check [AutoMM Detection - Prepare COCO2017 Dataset](prepare_coco17.ipynb) and [Convert Data to COCO Format](convert_data_to_coco_format.ipynb) for more information\n",
    "about COCO dataset and how to split and convert a VOC dataset to COCO.**\n",
    "\n",
    "\n",
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/autogluon/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to [Customize AutoMM](../../advanced_topics/customization.ipynb).\n",
    "\n",
    "## Citation\n",
    "```\n",
    "@inproceedings{inoue_2018_cvpr,\n",
    "    author = {Inoue, Naoto and Furuta, Ryosuke and Yamasaki, Toshihiko and Aizawa, Kiyoharu},\n",
    "    title = {Cross-Domain Weakly-Supervised Object Detection Through Progressive Domain Adaptation},\n",
    "    booktitle = {The IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},\n",
    "    month = {June},\n",
    "    year = {2018}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}