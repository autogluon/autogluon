{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4292c3b",
   "metadata": {},
   "source": [
    "# AutoMM for Semantic Segmentation - Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/image_segmentation/beginner_semantic_seg.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/multimodal/image_prediction/beginner_semantic_seg.ipynb)\n",
    "\n",
    "\n",
    "Semantic Segmentation is a computer vision task in which the goal is to produce a dense pixel-wise segmentation map of an image, where each pixel is assigned to a specific class or object. It is used to recognize a collection of pixels that form distinct categories. For example, an autonomous vehicle needs to identify vehicles, pedestrians, traffic signs, pavement, and other road features.\n",
    "\n",
    "Segment Anything Model (SAM) is a foundation model that was pretrained on large-scale segmentation data with 1B masks and 11M images. Despite its excellent zero-shot performance on generic scenes, it faces challenges to generalize to specialized domain, such as remote sensing, medical imagery, agriculture, and manufacturing, due to the domain shift issue. Fortunately, AutoMM can help bridge the domain gap by finetuning SAM on domain-specific data.\n",
    "\n",
    "In this quick start, we'll show how to use AutoMM to finetune SAM. Once the data is prepared in [Pandas DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) format, a single call to `MultiModalPredictor.fit()` will take care of the model training for you.\n",
    "\n",
    "\n",
    "## Prepare Data\n",
    "\n",
    "For demonstration purposes, we use a subset of the [Shopee-IET dataset](https://www.kaggle.com/c/shopee-iet-machine-learning-competition/data) from Kaggle.\n",
    "Each image in this data depicts a clothing item and the corresponding label specifies its clothing category.\n",
    "Our subset of the data contains the following possible labels: `BabyPants`, `BabyShirt`, `womencasualshoes`, `womenchiffontop`.\n",
    "\n",
    "We can load a dataset by downloading a url data automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install autogluon.multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ca4f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from autogluon.core.utils.loaders import load_zip\n",
    "\n",
    "def file2id(folder_path, file_path, split_str=\"_\"):\n",
    "    image_id = os.path.normpath(os.path.relpath(file_path, start=folder_path))\n",
    "    if split_str in image_id:\n",
    "        image_id = os.path.splitext(image_id)[0].split(split_str)[0]\n",
    "    else:\n",
    "        image_id = os.path.splitext(image_id)[0]\n",
    "    return image_id\n",
    "\n",
    "def get_file_paths(directory, split_str=\"_\"):\n",
    "    file_paths = sorted(os.listdir(directory), key=lambda file_path: file2id(directory, file_path, split_str))\n",
    "    return [os.path.join(directory, file_path) for file_path in file_paths]\n",
    "\n",
    "zip_file = \"https://automl-mm-bench.s3.amazonaws.com/unit-tests/tiny_isic2017.zip\"\n",
    "download_dir = \"./automm_tutorial_semantic_seg\"\n",
    "load_zip.unzip(zip_file, unzip_dir=download_dir)\n",
    "data_dir = os.path.join(download_dir, \"tiny_isic2017\")\n",
    "train_img_files = get_file_paths(os.path.join(data_dir, \"train/ISIC-2017_Train\"))\n",
    "train_gt_files = get_file_paths(os.path.join(data_dir, \"train/ISIC-2017_Training_Part1_GroundTruth\"))\n",
    "val_img_files = get_file_paths(os.path.join(data_dir, \"val/ISIC-2017_Val\"))\n",
    "val_gt_files = get_file_paths(os.path.join(data_dir, \"val/ISIC-2017_Validation_Part1_GroundTruth\"))\n",
    "test_img_files = get_file_paths(os.path.join(data_dir, \"test/ISIC-2017_Test\"))\n",
    "test_gt_files = get_file_paths(os.path.join(data_dir, \"test/ISIC-2017_Test_v2_Part1_GroundTruth\"))\n",
    "\n",
    "train_data = pd.DataFrame({\"image\": train_img_files, \"label\": train_gt_files})\n",
    "val_data = pd.DataFrame({\"image\": val_img_files, \"label\": val_gt_files})\n",
    "test_data = pd.DataFrame({\"image\": test_img_files, \"label\": test_gt_files})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77034c07",
   "metadata": {},
   "source": [
    "We can see there are 800 rows and 2 columns in this training dataframe. The 2 columns are **image** and **label**, and the **image** column contains the absolute paths of the images. Each row represents a different training sample.\n",
    "\n",
    "In addition to image paths, `MultiModalPredictor` also supports image bytearrays during training and inference. We can load the dataset with bytearrays with the option `is_bytearray` set to `True`:"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Initialize AutoMM"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import uuid\n",
    "save_path = f\"./tmp/{uuid.uuid4().hex}-automm_semantic_seg\"\n",
    "predictor = MultiModalPredictor(label=\"label\", path=save_path)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Zero Shot Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scores = predictor.evaluate(test_data, metrics=[\"iou\"])\n",
    "print(scores)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "id": "b6640353",
   "metadata": {},
   "source": [
    "## Train Model (Finetune SAM)\n",
    "\n",
    "Now, we fit a classifier using AutoMM as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e31052",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.fit(\n",
    "    train_data=train_data,\n",
    "    time_limit=30, # seconds\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199ced03",
   "metadata": {},
   "source": [
    "**label** is the name of the column that contains the target variable to predict, e.g., it is \"label\" in our example. **path** indicates the directory where models and intermediate outputs should be saved. We set the training time limit to 30 seconds for demonstration purpose, but you can control the training time by setting configurations. To customize AutoMM, please refer to [Customize AutoMM](../advanced_topics/customization.ipynb).\n",
    "\n",
    "\n",
    "## Evaluate on Test Data\n",
    "\n",
    "You can evaluate the classifier on the test dataset to see how it performs, the test top-1 accuracy is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4078bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = predictor.evaluate(test_data, metrics=[\"iou\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c60aa65",
   "metadata": {},
   "source": [
    "## Predict on a New Image\n",
    "\n",
    "Given an example image, let's visualize it first,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08caa07",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_data.iloc[0]['image']\n",
    "from IPython.display import Image, display\n",
    "pil_img = Image(filename=image_path)\n",
    "display(pil_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddc4aa7",
   "metadata": {},
   "source": [
    "We can easily use the final model to `predict` the label,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21c9030",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict({'image': [image_path]})\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee61517",
   "metadata": {},
   "source": [
    "If probabilities of all categories are needed, you can call `predict_proba`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67728302",
   "metadata": {},
   "source": [
    "## Save and Load\n",
    "\n",
    "The trained predictor is automatically saved at the end of `fit()`, and you can easily reload it.\n",
    "\n",
    "```{warning}\n",
    "\n",
    "`MultiModalPredictor.load()` uses `pickle` module implicitly, which is known to be insecure. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling. Never load data that could have come from an untrusted source, or that could have been tampered with. **Only load data you trust.**\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df38a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_predictor = MultiModalPredictor.load(model_path)\n",
    "load_proba = loaded_predictor.predict_proba({'image': [image_path]})\n",
    "print(load_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f650eda5",
   "metadata": {},
   "source": [
    "We can see the predicted class probabilities are still the same as above, which means same model!\n",
    "\n",
    "## Other Examples\n",
    "\n",
    "You may go to [AutoMM Examples](https://github.com/autogluon/autogluon/tree/master/examples/automm) to explore other examples about AutoMM.\n",
    "\n",
    "## Customization\n",
    "To learn how to customize AutoMM, please refer to [Customize AutoMM](../advanced_topics/customization.ipynb)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
