{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b0f6df2b",
   "metadata": {},
   "source": [
    "# AutoGluon Time Series - Forecasting Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/timeseries/forecasting-quick-start.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/timeseries/forecasting-quick-start.ipynb)\n",
    "\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can train and tune\n",
    "\n",
    "- simple forecasting models (e.g., ARIMA, ETS, Theta),\n",
    "- powerful deep learning models (e.g., DeepAR, Temporal Fusion Transformer),\n",
    "- tree-based models (e.g., LightGBM),\n",
    "- an ensemble that combines predictions of other models\n",
    "\n",
    "to produce multi-step ahead _probabilistic_ forecasts for univariate time series data.\n",
    "\n",
    "This tutorial demonstrates how to quickly start using AutoGluon to generate hourly forecasts for the [M4 forecasting competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128) dataset.\n",
    "\n",
    "## Loading time series data as a `TimeSeriesDataFrame`\n",
    "\n",
    "First, we import some required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install autogluon.timeseries\n",
    "!pip uninstall torchaudio -y  # fix incompatible torchaudio version on Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843dc3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "519d689a",
   "metadata": {},
   "source": [
    "To use `autogluon.timeseries`, we will only need the following two classes:\n",
    "\n",
    "- `TimeSeriesDataFrame` stores a dataset consisting of multiple time series.\n",
    "- `TimeSeriesPredictor` takes care of fitting, tuning and selecting the best forecasting models, as well as generating new forecasts.\n",
    "\n",
    "We load a subset of the M4 hourly dataset as a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd73a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/m4_hourly_subset/train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a64ddd43",
   "metadata": {},
   "source": [
    "AutoGluon expects time series data in [long format](https://doc.dataiku.com/dss/latest/time-series/data-formatting.html#long-format).\n",
    "Each row of the data frame contains a single observation (timestep) of a single time series represented by\n",
    "\n",
    "- unique ID of the time series (`\"item_id\"`) as int or str\n",
    "- timestamp of the observation (`\"timestamp\"`) as a `pandas.Timestamp` or compatible format\n",
    "- numeric value of the time series (`\"target\"`)\n",
    "\n",
    "The raw dataset should always follow this format with at least three columns for unique ID, timestamp, and target value, but the names of these columns can be arbitrary.\n",
    "It is important, however, that we provide the names of the columns when constructing a `TimeSeriesDataFrame` that is used by AutoGluon.\n",
    "AutoGluon will raise an exception if the data doesn't match the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73ddcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"item_id\",\n",
    "    timestamp_column=\"timestamp\"\n",
    ")\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfee8b9b",
   "metadata": {},
   "source": [
    "We refer to each individual time series stored in a `TimeSeriesDataFrame` as an _item_.\n",
    "For example, items might correspond to different products in demand forecasting, or to different stocks in financial datasets.\n",
    "This setting is also referred to as a _panel_ of time series.\n",
    "Note that this is *not* the same as multivariate forecasting — AutoGluon generates forecasts for each time series individually, without modeling interactions between different items (time series).\n",
    "\n",
    "`TimeSeriesDataFrame` inherits from [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), so all attributes and methods of `pandas.DataFrame` are available in a `TimeSeriesDataFrame`.\n",
    "It also provides other utility functions, such as loaders for different data formats (see [TimeSeriesDataFrame](../../api/autogluon.timeseries.TimeSeriesDataFrame) for details).\n",
    "\n",
    "## Training time series models with `TimeSeriesPredictor.fit`\n",
    "To forecast future values of the time series, we need to create a `TimeSeriesPredictor` object.\n",
    "\n",
    "Models in `autogluon.timeseries` forecast time series _multiple steps_ into the future.\n",
    "We choose the number of these steps — the _prediction length_ (also known as the _forecast horizon_) —  depending on our task.\n",
    "For example, our dataset contains time series measured at hourly _frequency_, so we set `prediction_length = 48` to train models that forecast up to 48 hours into the future.\n",
    "\n",
    "We instruct AutoGluon to save trained models in the folder `./autogluon-m4-hourly`.\n",
    "We also specify that AutoGluon should rank models according to [mean absolute scaled error (MASE)](https://en.wikipedia.org/wiki/Mean_absolute_scaled_error), and that data that we want to forecast is stored in the column `\"target\"` of the `TimeSeriesDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ef668c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    prediction_length=48,\n",
    "    path=\"autogluon-m4-hourly\",\n",
    "    target=\"target\",\n",
    "    eval_metric=\"MASE\",\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=600,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91b3ddd4",
   "metadata": {},
   "source": [
    "Here we used the `\"medium_quality\"` presets and limited the training time to 10 minutes (600 seconds).\n",
    "The presets define which models AutoGluon will try to fit.\n",
    "For `medium_quality` presets, these are\n",
    "simple baselines (`Naive`, `SeasonalNaive`),\n",
    "statistical models (`AutoETS`, `Theta`),\n",
    "tree-based model LightGBM wrapped by `RecursiveTabular`,\n",
    "a deep learning model `DeepAR`,\n",
    "and a weighted ensemble combining these.\n",
    "Other available presets for `TimeSeriesPredictor` are `\"fast_training\"`, `\"high_quality\"` and `\"best_quality\"`.\n",
    "Higher quality presets will usually produce more accurate forecasts but take longer to train.\n",
    "\n",
    "Inside `fit()`, AutoGluon will train as many models as possible within the given time limit.\n",
    "Trained models are then ranked based on their performance on an internal validation set.\n",
    "By default, this validation set is constructed by holding out the last `prediction_length` timesteps of each time series in `train_data`.\n",
    "\n",
    "\n",
    "## Generating forecasts with `TimeSeriesPredictor.predict`\n",
    "\n",
    "We can now use the fitted `TimeSeriesPredictor` to forecast the future time series values.\n",
    "By default, AutoGluon will make forecasts using the model that had the best score on the internal validation set.\n",
    "The forecast always includes predictions for the next `prediction_length` timesteps, starting from the end of each time series in `train_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a238183",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(train_data)\n",
    "predictions.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bfbca161",
   "metadata": {},
   "source": [
    "AutoGluon produces a _probabilistic_ forecast: in addition to predicting the mean (expected value) of the time series in the future, models also provide the quantiles of the forecast distribution.\n",
    "The quantile forecasts give us an idea about the range of possible outcomes.\n",
    "For example, if the `\"0.1\"` quantile is equal to `500.0`, it means that the model predicts a 10% chance that the target value will be below `500.0`.\n",
    "\n",
    "We will now visualize the forecast and the actually observed values for one of the time series in the dataset.\n",
    "We plot the mean forecast, as well as the 10% and 90% quantiles to show the range of potential outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2455126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# TimeSeriesDataFrame can also be loaded directly from a file\n",
    "test_data = TimeSeriesDataFrame.from_path(\"https://autogluon.s3.amazonaws.com/datasets/timeseries/m4_hourly_subset/test.csv\")\n",
    "\n",
    "plt.figure(figsize=(20, 3))\n",
    "\n",
    "item_id = \"H1\"\n",
    "y_past = train_data.loc[item_id][\"target\"]\n",
    "y_pred = predictions.loc[item_id]\n",
    "y_test = test_data.loc[item_id][\"target\"][-48:]\n",
    "\n",
    "plt.plot(y_past[-200:], label=\"Past time series values\")\n",
    "plt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\n",
    "plt.plot(y_test, label=\"Future time series values\")\n",
    "\n",
    "plt.fill_between(\n",
    "    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n",
    ")\n",
    "plt.legend();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc2d08f7",
   "metadata": {},
   "source": [
    "## Evaluating the performance of different models\n",
    "\n",
    "We can view the performance of each model AutoGluon has trained via the `leaderboard()` method.\n",
    "We provide the test data set to the leaderboard function to see how well our fitted models are doing on the unseen test data.\n",
    "The leaderboard also includes the validation scores computed on the internal validation dataset.\n",
    "\n",
    "In AutoGluon leaderboards, higher scores always correspond to better predictive performance.\n",
    "Therefore our MASE scores are multiplied by `-1`, such that higher \"negative MASE\"s correspond to more accurate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4f8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The test score is computed using the last\n",
    "# prediction_length=48 timesteps of each time series in test_data\n",
    "predictor.leaderboard(test_data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd2fdfac",
   "metadata": {},
   "source": [
    "## Summary\n",
    "We used `autogluon.timeseries` to make probabilistic multi-step forecasts on the M4 Hourly dataset.\n",
    "Check out [Forecasting Time Series - In Depth](forecasting-indepth.ipynb) to learn about the advanced capabilities of AutoGluon for time series forecasting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
