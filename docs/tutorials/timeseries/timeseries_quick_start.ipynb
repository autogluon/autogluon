{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zcGYEaIQKiql"
   },
   "source": [
    "# Time Series Quick Start\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/new/docs/tutorials/timeseries/timeseries_quick_start.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/new/docs/tutorials/timeseries/timeseries_quick_start.ipynb)\n",
    "\n",
    "Via a simple `fit()` call, AutoGluon can train and tune\n",
    "\n",
    "- simple forecasting models (e.g., ARIMA, ETS, Theta),\n",
    "- powerful deep learning models (e.g., DeepAR, Temporal Fusion Transformer),\n",
    "- tree-based models (e.g., XGBoost, CatBoost, LightGBM),\n",
    "- an ensemble that combines predictions of other models\n",
    "\n",
    "to produce multi-step ahead _probabilistic_ forecasts for univariate time series data.\n",
    "\n",
    "This tutorial demonstrates how to get started using AutoGluon to generate hourly forecasts for the [M4 forecasting competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "Begin by making sure AutoGluon is installed, and then import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "ppnLJmzsKYu5",
    "outputId": "34540c95-cc34-4f59-a888-b19e870fb6ca",
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install autogluon\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T04:47:05.526762Z",
     "start_time": "2022-07-09T04:47:04.436407Z"
    },
    "id": "Mv1_TnxKLtYn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from autogluon.timeseries import TimeSeriesDataFrame, TimeSeriesPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use `autogluon.timeseries`, we will only need the following two classes:\n",
    "\n",
    "- `TimeSeriesDataFrame` stores a dataset consisting of multiple time series.\n",
    "- `TimeSeriesPredictor` takes care of fitting, tuning and selecting the best forecasting models, as well as generating new forecasts.\n",
    "\n",
    "We start by downloading the M4 Hourly dataset from the official website (click on the arrow to show the preprocessing code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 8)  # Save space when printing\n",
    "\n",
    "m4_info_url = \"https://github.com/Mcompetitions/M4-methods/raw/master/Dataset/M4-info.csv\"\n",
    "m4_hourly_url = \"https://github.com/Mcompetitions/M4-methods/raw/master/Dataset/Train/Hourly-train.csv\"\n",
    "\n",
    "def download_m4_hourly_dataset(save_path):\n",
    "    metadata = pd.read_csv(m4_info_url)\n",
    "    metadata = metadata[metadata[\"SP\"] == \"Hourly\"].set_index(\"M4id\")\n",
    "    data = pd.read_csv(m4_hourly_url, index_col=\"V1\")\n",
    "    results = []\n",
    "    for item_id in metadata.index:\n",
    "        time_series = data.loc[item_id].dropna().values\n",
    "        start_time = pd.Timestamp(metadata.loc[item_id][\"StartingDate\"])\n",
    "        timestamps = pd.date_range(start_time, freq=\"H\", periods=len(time_series))\n",
    "        results.append(pd.DataFrame({\"M4id\": [item_id] * len(time_series), \"Date\": timestamps, \"Value\": time_series}))\n",
    "    result = pd.concat(results, ignore_index=True)\n",
    "    result.to_csv(save_path, index=False)\n",
    "\n",
    "download_m4_hourly_dataset(\"m4_hourly.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The M4 dataset contains time series from various domains like finance, demography and economics.\n",
    "Our goal is to forecast the future values of each time series in the dataset given the past observations.\n",
    "\n",
    "We load the dataset as a `pandas.DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"m4_hourly.csv\",\n",
    "    parse_dates=[\"Date\"],  # make sure that pandas parses the dates\n",
    ")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each row of the data frame contains a single observation (timestep) of a single time series represented by\n",
    "\n",
    "- unique ID of the time series (`\"M4id\"`)\n",
    "- timestamp of the observation (`\"Date\"`) as a `pandas.Timestamp`\n",
    "- numeric value of the time series (`\"Value\"`)\n",
    "\n",
    "The raw dataset should always follow this format with at least three columns for unique ID, timestamp, and target value, but the names of these columns can be arbitrary.\n",
    "It is important, however, that we provide the names of the columns when constructing a `TimeSeriesDataFrame` that is used by AutoGluon.\n",
    "AutoGluon will raise an exception if the data doesn't match the expected format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataframe = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"M4id\",  # column that contains unique ID of each time series\n",
    "    timestamp_column=\"Date\",  # column that contains timestamps of each observation\n",
    ")\n",
    "ts_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We refer to each individual time series stored in a `TimeSeriesDataFrame` as an _item_.\n",
    "For example, items might correspond to different products in demand forecasting, or to different stocks in financial datasets.\n",
    "This setting is also referred to as a _panel_ of time series.\n",
    "Note that this is *not* the same as multivariate forecasting â€” AutoGluon generates forecasts for each time series individually, without modeling interactions between different items (time series).\n",
    "\n",
    "`TimeSeriesDataFrame` inherits from [pandas.DataFrame](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html), so all attributes and methods of `pandas.DataFrame` are also available in a `TimeSeriesDataFrame`.\n",
    "Note how `TimeSeriesDataFrame` organizes the data with a `pandas.MultiIndex`: the first _level_ of the index corresponds to the item ID and the second level contains the timestamp when each observation was made.\n",
    "For example, we can use the `loc` accessor to access each individual time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts_dataframe.loc[\"H2\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot some of the time series in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.5), dpi=100)\n",
    "for item_id in [\"H1\", \"H2\"]:\n",
    "    plt.plot(ts_dataframe.loc[item_id], label=item_id)\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting problem formulation\n",
    "Models in `autogluon.timeseries` provide _probabilistic_ forecasts of time series _multiple steps_ into the future.\n",
    "We choose the number of these steps---the _prediction length_ (also known as the _forecast horizon_) depending on our task.\n",
    "For example, our dataset contains time series measured at hourly _frequency_, so we set `prediction_length = 48` to train models that forecast 48 hours into the future.\n",
    "Moreover, forecasts are probabilistic: in addition to predicting the _mean_ (expected value) of the time series in the future, models also provide the _quantiles_ of the forecast distribution.\n",
    "\n",
    "In order to report realistic results for how AutoGluon will perform on unseen data; we will split our dataset into a training set, used to train & tune models, and a test set used to evaluate the final performance.\n",
    "In forecasting, this is usually done by hiding the last `prediction_length` steps of each time series during training, and only using these last steps to evaluate the forecast quality (also known as \"out of time validation\").\n",
    "We perform this split using the `slice_by_timestep` method of `TimeSeriesDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 48\n",
    "test_data = ts_dataframe  # the full data set\n",
    "\n",
    "# last prediction_length timesteps of each time series are excluded, akin to `x[:-48]`\n",
    "train_data = ts_dataframe.slice_by_timestep(None, -prediction_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we plot the training and test parts of the time series for a single country, and mark the test forecast horizon.\n",
    "We will compute the test scores by measuring how well the forecast generated by a model matches the actually observed values in the forecast horizon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "item_id = \"H1\"\n",
    "plt.figure(figsize=(10, 2.5), dpi=100)\n",
    "train_series = train_data.loc[item_id][\"Value\"]\n",
    "test_series = test_data.loc[item_id][\"Value\"]\n",
    "plt.plot(test_series, label=\"Test\")\n",
    "plt.plot(train_series, label=\"Train\")\n",
    "\n",
    "plt.fill_betweenx(\n",
    "    y=(test_series.min(), test_series.max()),\n",
    "    x1=train_series.index[-1],\n",
    "    x2=test_series.index[-1],\n",
    "    alpha=0.2,\n",
    "    label=\"Test forecast horizon\",\n",
    ")\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training time series models with `TimeSeriesPredictor.fit`\n",
    "\n",
    "Below we instantiate a `TimeSeriesPredictor` object and instruct AutoGluon to fit models that can forecast up to\n",
    "48 timesteps into the future (`prediction_length`) and save them in the folder `./autogluon-m4-hourly`.\n",
    "We also specify that AutoGluon should rank models according to mean absolute percentage error (MAPE), and that data that we want to forecast is stored in the column `\"Value\"` of the `TimeSeriesDataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "predictor = TimeSeriesPredictor(\n",
    "    path=\"autogluon-m4-hourly\",\n",
    "    target=\"Value\",\n",
    "    prediction_length=prediction_length,\n",
    "    eval_metric=\"MAPE\",\n",
    ")\n",
    "\n",
    "predictor.fit(\n",
    "    train_data,\n",
    "    presets=\"medium_quality\",\n",
    "    time_limit=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used the `\"medium_quality\"` presets and limited the training time to 10 minutes (600 seconds).\n",
    "The presets define which models AutoGluon will try to fit.\n",
    "For `medium_quality` presets, these are \n",
    "simple baselines (`Naive`, `SeasonalNaive`), \n",
    "statistical models (`ARIMA`, `ETS`, `Theta`), \n",
    "tree-based models XGBoost, LightGBM and CatBoost wrapped by `AutoGluonTabular`,\n",
    "a deep learning model `DeepAR`,\n",
    "and a weighted ensemble combining these.\n",
    "Other available presets for `TimeSeriesPredictor` are `\"fast_training\"` `\"high_quality\"` and `\"best_quality\"`.\n",
    "Higher quality presets will usually produce more accurate forecasts but take longer to train and may produce less computationally efficient models.\n",
    "\n",
    "Inside `fit()`, AutoGluon will train as many models as possible within the given time limit.\n",
    "Trained models are then ranked based on their performance on an internal validation set.\n",
    "By default, this validation set is constructed by holding out the last `prediction_length` timesteps of each time series in `train_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of different models\n",
    "\n",
    "We can view the test performance of each model AutoGluon has trained via the `leaderboard()` method.\n",
    "We provide the test data set to the leaderboard function to see how well our fitted models are doing on the held out test data.\n",
    "The leaderboard also includes the validation scores computed on the internal validation dataset.\n",
    "\n",
    "In AutoGluon leaderboards, higher scores always correspond to better predictive performance.\n",
    "Therefore our MAPE scores are multiplied by `-1`, such that higher \"negative MAPE\"s correspond to more accurate forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.leaderboard(test_data, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating forecasts with `TimeSeriesPredictor.predict`\n",
    "\n",
    "We can now use the fitted `TimeSeriesPredictor` to make predictions.\n",
    "By default, AutoGluon will make forecasts using the model that had the best validation score (as shown in the leaderboard).\n",
    "Let's use the predictor to generate forecasts starting from the end of the time series in `train_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictor.predict(train_data)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions are also stored as a `TimeSeriesDataFrame`. However, now the columns contain the mean and quantile predictions of each model.\n",
    "The quantile forecasts give us an idea about the range of possible outcomes.\n",
    "For example, if the `\"0.1\"` quantile is equal to `501.3`, it means that the model predicts a 10% chance that the target value will be below `501.3`.\n",
    "\n",
    "We will now visualize the forecast and the actually observed values for one of the time series in the dataset.\n",
    "We plot the mean forecast, as well as the 10% and 90% quantiles to show the range of potential outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 2.5), dpi=100)\n",
    "\n",
    "item_id = \"H3\"\n",
    "y_past = train_data.loc[item_id][\"Value\"]\n",
    "y_pred = predictions.loc[item_id]\n",
    "y_true = test_data.loc[item_id][\"Value\"][-prediction_length:]\n",
    "\n",
    "# prepend the last value of true range to predicted range for plotting continuity\n",
    "y_pred.loc[y_past.index[-1]] = [y_past[-1]] * 10\n",
    "y_pred = y_pred.sort_index()\n",
    "\n",
    "plt.plot(y_past[-200:], label=\"Training data\")\n",
    "plt.plot(y_pred[\"mean\"], label=\"Mean forecast\")\n",
    "plt.plot(y_true, label=\"Observed\")\n",
    "\n",
    "plt.fill_between(\n",
    "    y_pred.index, y_pred[\"0.1\"], y_pred[\"0.9\"], color=\"red\", alpha=0.1, label=f\"10%-90% confidence interval\"\n",
    ")\n",
    "plt.title(\"Forecasted time series values vs. the real observations\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used `autogluon.timeseries` to make probabilistic multi-step forecasts on the M4 Hourly dataset.\n",
    "Here is a short summary of the main steps for applying AutoGluon to make forecasts for the entire dataset using a few lines of code.\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\n",
    "    \"m4_hourly.csv\",\n",
    "    parse_dates=[\"Date\"],\n",
    ")\n",
    "ts_dataframe = TimeSeriesDataFrame.from_data_frame(\n",
    "    df,\n",
    "    id_column=\"M4id\",  # name of the column with unique ID of each time series\n",
    "    timestamp_column=\"Date\",  # name of the column with timestamps of observations\n",
    ")\n",
    "\n",
    "# Create & fit the predictor\n",
    "predictor = TimeSeriesPredictor(\n",
    "    path=\"autogluon-m4-hourly\",  # models will be saved in this folder\n",
    "    target=\"Value\",  # name of the column with time series values\n",
    "    prediction_length=48,  # number of steps into the future to predict\n",
    "    eval_metric=\"MAPE\",  # other options: \"MASE\", \"sMAPE\", \"mean_wQuantileLoss\", \"MSE\", \"RMSE\"\n",
    ").fit(\n",
    "    train_data=ts_dataframe,\n",
    "    presets=\"medium_quality\",  # other options: \"fast_training\", \"high_quality\", \"best_quality\"\n",
    "    time_limit=600,  # training time in seconds\n",
    ")\n",
    "\n",
    "predictions = predictor.predict(ts_dataframe)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "timeseries_quick_start.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "f7bc0839522284c9a892b98610e89887142f14aaecf82d540f4079f05f0bb734"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
