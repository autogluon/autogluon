{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b7d7a5e-cffa-4571-b7fa-3cb048689538",
   "metadata": {},
   "source": [
    "# Automated Quick Model Fit\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/autogluon/autogluon/blob/master/docs/tutorials/eda/eda-auto-quick-fit.ipynb)\n",
    "[![Open In SageMaker Studio Lab](https://studiolab.sagemaker.aws/studiolab.svg)](https://studiolab.sagemaker.aws/import/github/autogluon/autogluon/blob/master/docs/tutorials/eda/eda-auto-quick-fit.ipynb)\n",
    "\n",
    "The purpose of this feature is to provide a quick and easy way to obtain a preliminary understanding of the\n",
    "relationships between the target variable and the independent variables in a dataset.\n",
    "\n",
    "This functionality automatically splits the training data, fits a simple regression or classification model to the\n",
    "data and generates insights: model performance metrics, feature importance and prediction result insights.\n",
    "\n",
    "To inspect the prediction quality, a confusion matrix is displayed for classification problems and scatter plot for\n",
    "regression problems. Both representation allow the user to see the difference between actual and predicted values.\n",
    "\n",
    "The insights highlight two subsets of the model predictions:\n",
    "\n",
    "- Predictions with the largest classification error. Rows listed in this section are candidates for inspecting why the\n",
    "  model made the mistakes\n",
    "- Predictions with the least distance from the other class. Rows in this category are most 'undecided'. They are useful\n",
    "  as examples of data which is close to a decision boundary between the classes. The model would benefit from having\n",
    "  more data for similar cases.\n",
    "\n",
    "## Classification Example\n",
    "\n",
    "We will start with getting the titanic dataset and performing a quick one-line overview to get the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa00faab-252f-44c9-b8f7-57131aa8251c",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "!pip install autogluon.eda\n",
    "!pip install autogluon.tabular[lightgbm]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f818ee7d-e400-4ce3-8159-0b5b5cc0403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import autogluon.eda.auto as auto\n",
    "\n",
    "df_train = pd.read_csv('https://autogluon.s3.amazonaws.com/datasets/titanic/train.csv')\n",
    "df_test = pd.read_csv('https://autogluon.s3.amazonaws.com/datasets/titanic/test.csv')\n",
    "target_col = 'Survived'\n",
    "\n",
    "state = auto.quick_fit(\n",
    "    df_train, \n",
    "    target_col, \n",
    "    return_state=True,\n",
    "    show_feature_importance_barplots=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "486d331a",
   "metadata": {},
   "source": [
    "### Explain rows\n",
    "Let's take a look what were the contibuting factors in the row with the highest error. `auto.explain_rows` can perform SHAP analysis for the specified rows and render it either using `force` or `waterfall` layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.explain_rows(\n",
    "    train_data=df_train,\n",
    "    model=state.model,\n",
    "    display_rows=True,\n",
    "    rows=state.model_evaluation.highest_error[:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1806eca7",
   "metadata": {},
   "source": [
    "Next we are going to inspect the most undecided rows that were misclassified. This time we will use `waterfall` layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto.explain_rows(\n",
    "    train_data=df_train,\n",
    "    model=state.model,\n",
    "    display_rows=True,\n",
    "    plot=\"waterfall\",\n",
    "    rows=state.model_evaluation.undecided[:1],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d826aca4-e5ee-41b2-8583-3f56866700e1",
   "metadata": {},
   "source": [
    "## Regression Example\n",
    "\n",
    "In the previous section we tried a classification example. Let's try a regression. It has a few differences.\n",
    "We are also going to return the state to retrieve the fitted model and use it to predict test values later.\n",
    "\n",
    "It is a large dataset, so we'll keep only a few columns for this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f1c828-5b66-4847-9e97-b9ab58e8a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('https://autogluon.s3.amazonaws.com/datasets/AmesHousingPriceRegression/train_data.csv')\n",
    "df_test = pd.read_csv('https://autogluon.s3.amazonaws.com/datasets/AmesHousingPriceRegression/test_data.csv')\n",
    "target_col = 'SalePrice'\n",
    "\n",
    "keep_cols = [\n",
    "  'Overall.Qual', 'Gr.Liv.Area', 'Neighborhood', 'Total.Bsmt.SF', 'BsmtFin.SF.1',\n",
    "  'X1st.Flr.SF', 'Bsmt.Qual', 'Garage.Cars', 'Half.Bath', 'Year.Remod.Add', target_col\n",
    "]\n",
    "\n",
    "df_train = df_train[[c for c in df_train.columns if c in keep_cols]][:500]\n",
    "df_test = df_test[[c for c in df_test.columns if c in keep_cols]][:500]\n",
    "\n",
    "\n",
    "state = auto.quick_fit(df_train, target_col, fit_bagging_folds=3, return_state=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108e60ee-317b-4f9f-b07f-277a99914614",
   "metadata": {},
   "source": [
    "## Using a fitted model\n",
    "\n",
    "Now let's get the `model` from `state`, perform the prediction on `df_test` and quickly visualize the results using \n",
    "`auto.analyze_interaction()` tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991fb214-11d6-44c5-a0a2-0b5e40b671c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = state.model\n",
    "y_pred = model.predict(df_test)\n",
    "auto.analyze_interaction(\n",
    "    train_data=pd.DataFrame({'SalePrice_Pred': y_pred}), \n",
    "    x='SalePrice_Pred', \n",
    "    fit_distributions=['johnsonsu', 'norm', 'exponnorm']\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
