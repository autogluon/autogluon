# Version 0.6.0

We're happy to announce the AutoGluon 0.6 release. 0.6 contains major enhancements to Tabular Text and Time Series
modules, along with many quality of life improvements and fixes.

As always, only load previously trained models using the same version of AutoGluon that they were originally trained on.
Loading models trained in different versions of AutoGluon is not supported.

This release contains [**230** commits from **25** contributors](https://github.com/awslabs/autogluon/graphs/contributors?from=2022-07-18&to=2022-11-15&type=c)!

See the full commit change-log here: https://github.com/awslabs/autogluon/compare/v0.5.2...v0.6.0

Special thanks to @cheungdaven, @suzhoum, @BingzhaoZhu, @liangfu, @Harry-zzh, @gidler, @yongxinw, @martinschaef,
@giswqs, @Jalagarto, @geoalgo, @lujiaying and @leloykun who were first time contributors to AutoGluon this release!

Full Contributor List (ordered by # of commits):

- @shchur, @yinweisu, @zhiqiangdon, @Innixma, @canerturkmen, @gradientsky, @sxjscience, @FANGAreNotGnu, @cheungdaven,
  @suzhoum, @bryanyzhu, @BingzhaoZhu, @liangfu, @Harry-zzh, @Raldir, @gidler, @yongxinw, @martinschaef, @giswqs,
  @Jalagarto, @geoalgo, @lujiaying, @leloykun, @yiqings

This version supports Python versions 3.7 to 3.9. This is the last version that supports python 3.7.

# Changes

## AutoMM

### New features

### More tutorials and examples

## Tabular

### New features

### More tutorials and examples

## Time Series

### New features

- `TimeSeriesPredictor` now supports **static features** (a.k.a. time series metadata, static covariates) and **
  time-varying covariates** (a.k.a. dynamic features or related time series). @shchur @canerturkmen (#1986, #2238,
  #2276, #2287)
- AutoGluon-TimeSeries now uses **PyTorch** by default (for `DeepAR` and `SimpleFeedForward`), removing the dependency
  on MXNet. @canerturkmen (#2074, #2205, #2279)
- New models! `AutoGluonTabular` relies on XGBoost, LightGBM and CatBoost under the hood via the `autogluon.tabular`
  module. `Naive` and `SeasonalNaive` forecasters are simple methods that provide strong baselines with no increase in
  training time. `TemporalFusionTransformerMXNet` brings the TFT transformer architecture to AutoGluon. @shchur (#2106,
  #2188, #2258, #2266)
- Up to 20x faster parallel and memory-efficient training for statistical (local) forecasting models like `ETS`, `ARIMA`
  and `Theta`, as well as `WeightedEnsemble`. @shchur @canerturkmen (#2001, #2033, #2040, #2067, #2072, #2073, #2180,
  #2293, #2305)
- Up to 3x faster training for GluonTS models with data caching. GPU training enabled by default on PyTorch models.
  @shchur (#2323)
- More accurate validation for time series models with multi-window backtesting. @shchur (#2013, #2038)
- `TimeSeriesPredictor` now handles irregularly sampled time series with `ignore_index`. @canerturkmen, @shchur (#1993,
  #2322)
- Improved and extended presets for more accurate forecasting. @shchur (#2304)
- 15x faster and more robust forecast evaluation with updates to `TimeSeriesEvaluator` @shchur (#2147, #2150)
- Enabled Ray Tune backend for hyperparameter optimization of time series models. @shchur (#2167, #2203)

### More tutorials and examples

Improved documentation and new tutorials:

- Updated [Quickstart tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-quickstart.html)
- New! [In-depth tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-indepth.html)
-
New! [Overview of available models and hyperparameters](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-model-zoo.html)
- Updated [API documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#module-5)

@shchur (#2120, #2127, #2146, #2174, #2187, #2354)

## Fixes and enhancements in v0.6

