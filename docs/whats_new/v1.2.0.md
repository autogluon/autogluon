# Version 1.2.0

We're happy to announce the AutoGluon 1.2.0 release.

AutoGluon 1.2 contains massive improvements to both Tabular and TimeSeries modules, each achieving a 70% win-rate vs AutoGluon 1.1. This release additionally adds support for Python 3.12 and drops support for Python 3.8.

This release contains [186 commits from 26 contributors](https://github.com/autogluon/autogluon/compare/v1.1.1...v1.2.0)!

We are also excited to announce [AutoGluon-Assistant](https://github.com/autogluon/autogluon-assistant/) (AG-A), our first venture into the realm of Automated Data Science!

WIP: The 1.2.0 release notes are still being updated. Come back in a few hours for the complete release notes. The below is a draft.

For Tabular, we encompass the primary enhancements of the new [TabPFNMix tabular foundation model](https://huggingface.co/autogluon/tabpfn-mix-1.0-classifier) and parallel fit strategy into the new `"experimental_quality"` preset to ensure a smooth transition period for those who wish to try the new cutting edge features. We will be using this release to gather feedback prior to incorporating these features into the other presets. We also introduce a new stack layer model pruning technique that results in a 3x inference speedup on small datasets with zero performance loss and greatly improved post-hoc calibration across the board, particularly on small datasets.

For TimeSeries, we introduce [Chronos-Bolt](https://huggingface.co/autogluon/chronos-bolt-base), our latest foundation model integrated into AutoGluon, with massive improvements to both accuracy and inference speed compared to Chronos, along with fine-tuning capabilities. We also added covariate regressor support!

See more details in the Spotlights below!

## Spotlight

### AutoGluon Becomes the Golden Standard for Competition ML in 2024

Before diving into the new features of 1.2, we would like to start by highlighting the [wide-spread adoption](https://www.kaggle.com/search?q=autogluon+sortBy%3Adate) AutoGluon has received on competition ML sites like Kaggle in 2024. Across all of 2024, AutoGluon was used to achieve a top 3 finish in 15 out of 18 tabular Kaggle competitions, including 7 first place finishes, and was never outside the top 1% of private leaderboard placements, with an average of over 1000 competing human teams in each competition. In the $75,000 prize money [2024 Kaggle AutoML Grand Prix](https://www.kaggle.com/automl-grand-prix), AutoGluon was used by the 1st, 2nd, and 3rd place teams, with the 2nd place team led by two AutoGluon developers: [Lennart Purucker](https://github.com/LennartPurucker) and [Nick Erickson](https://github.com/Innixma)! For comparison, in 2023 AutoGluon achieved only 1 first place and 1 second place solution. We attribute the bulk of this increase to the improvements seen in AutoGluon 1.0 and beyond.

<center>
<img src="https://autogluon.s3.amazonaws.com/images/autogluon_kaggle_results_2024.png" width="75%"/>
</center>

We'd like to emphasize that these results are achieved via human expert interaction with AutoGluon and other tools, and often includes manual feature engineering and hyperparameter tuning to get the most out of AutoGluon. To see a live tracking of all AutoGluon solution placements on Kaggle, refer to our [AWESOME.md ML competition section](https://github.com/autogluon/autogluon/blob/master/AWESOME.md#kaggle) where we provide links to all solution write-ups.

### AutoGluon-Assistant: Automating Data Science with AutoGluon and LLMs

We are excited to share the release of a new [AutoGluon-Assistant module](https://github.com/autogluon/autogluon-assistant/) (AG-A), powered by LLMs from AWS Bedrock or OpenAI. AutoGluon-Assistant empowers users to solve tabular machine learning problems using only natural language descriptions, in zero lines of code with our simple user interface. Fully autonomous AG-A outperforms 74% of human ML practitioners in Kaggle competitions and secured a live top 10 finish in the $75,000 prize money [2024 Kaggle AutoML Grand Prix](https://www.kaggle.com/automl-grand-prix) competition as Team AGA ðŸ¤–!

### TabularPredictor presets="experimental_quality"

TabularPredictor has a new `"experimental_quality"` preset that offers even better predictive quality than `"best_quality"`. On [the AutoMLBenchmark](https://github.com/openml/automlbenchmark), we observe a 70% winrate vs `best_quality` when running for 4 hours on a 64 CPU machine. This preset is a testing ground for cutting edge features and models which we hope to incorporate into `best_quality` for future releases. We recommend to use a machine with at least 16 CPU cores, 64 GB of memory, and a 4 hour+ `time_limit` to get the most benefit out of `experimental_quality`. Please let us know via a GitHub issue if you run into any problems running the `experimental_quality` preset.

#### TabPFNMix: A Foundation Model for Tabular Data

[TabPFNMix]((https://huggingface.co/autogluon/tabpfn-mix-1.0-classifier)) is the first tabular foundation model created by the AutoGluon team, and was pre-trained exclusively on synthetic data.
The model builds upon the prior work of [TabPFN](https://arxiv.org/abs/2207.01848) and [TabForestPFN](https://arxiv.org/abs/2405.13396). TabPFNMix to the best of our knowledge achieves a new state-of-the-art for individual open source model performance on datasets between 1000 and 10000 samples, and also supports regression tasks! Across the 109 classification datasets with less than or equal to 10000 training samples in [TabRepo](https://github.com/autogluon/tabrepo), fine-tuned TabPFNMix outperforms all prior models, with a 64% win-rate vs the strongest tree model, CatBoost, and a 61% win-rate vs fine-tuned TabForestPFN.

The model is available via the `TABPFNMIX` hyperparameters key, and is used in the new `experimental_quality` preset. We recommend using this model for datasets smaller than 50,000 training samples, ideally with a large time limit and 64+ GB of memory. This work is still in the early stages, and we appreciate any feedback from the community to help us iterate and improve for future releases. You can learn more by going to our HuggingFace model page for the model ([tabpfn-mix-1.0-classifier](https://huggingface.co/autogluon/tabpfn-mix-1.0-classifier), [tabpfn-mix-1.0-regressor](https://huggingface.co/autogluon/tabpfn-mix-1.0-regressor)). Give us a like on HuggingFace if you want to see more! A paper is planned in future to provide more details about the model.

#### fit_strategy="parallel"

AutoGluon's TabularPredictor now supports the new fit argument `fit_strategy` and the new `"parallel"` option, enabled by default in the new `experimental_quality` preset. For machines with 16 or more CPU cores, the parallel fit strategy offers a major speedup over the previous `"sequential"` strategy. We estimate with 64 CPU cores that most datasets will experience a 2-4x speedup, with the speedup getting larger as CPU cores increase.

### Chronos-Boltâš¡: a 250x faster, more accurate Chronos model

Chronos-Bolt is our latest foundation model for forecasting that has been integrated into AutoGluon. It is based on the T5 encoder-decoder architecture and has been trained on nearly 100 billion time series observations. It chunks the historical time series context into patches of multiple observations, which are then input into the encoder. The decoder then uses these representations to directly generate quantile forecasts across multiple future stepsâ€”_a method known as direct multi-step forecasting_. Chronos-Bolt models are up to 250 times faster and 20 times more memory-efficient than the original Chronos models of the same size.

The following plot compares the inference time of Chronos-Bolt against the original Chronos models for forecasting 1024 time series with a context length of 512 observations and a prediction horizon of 64 steps.

<center>
<img src="https://autogluon.s3.amazonaws.com/images/chronos_bolt_speed.svg" width="50%"/>
</center>

Chronos-Bolt models are not only significantly faster but also more accurate than the original Chronos models. The following plot reports the probabilistic and point forecasting performance of Chronos-Bolt in terms of the [Weighted Quantile Loss (WQL)](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-metrics.html#autogluon.timeseries.metrics.WQL) and the [Mean Absolute Scaled Error (MASE)](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-metrics.html#autogluon.timeseries.metrics.MASE), respectively, aggregated over 27 datasets (see the [Chronos paper](https://arxiv.org/abs/2403.07815) for details on this benchmark). Remarkably, despite having no prior exposure to these datasets during training, the zero-shot Chronos-Bolt models outperform commonly used statistical models and deep learning models that have been trained on these datasets (highlighted by *). Furthermore, they also perform better than other FMs, denoted by a +, which indicates that these models were pretrained on certain datasets in our benchmark and are not entirely zero-shot. Notably, Chronos-Bolt (Base) also surpasses the original Chronos (Large) model in terms of the forecasting accuracy while being over 600 times faster.

<center>
<img src="https://autogluon.s3.amazonaws.com/images/chronos_bolt_accuracy.svg" width="80%"/>
</center>

Chronos-Bolt models are now available through AutoGluon in four sizesâ€”Tiny (9M), Mini (21M), Small (48M), and Base (205M)â€”and can also be used on the CPU. With the addition of Chronos-Bolt models and other enhancements, **AutoGluon v1.2 achieves a 70%+ win rate against the previous release**!

In addition to the new Chronos-Bolt models, we have also added support for effortless fine-tuning of Chronos and Chronos-Bolt models. Check out the updated [Chronos tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-chronos.html) to learn how to use and fine-tune Chronos-Bolt models.

### Time Series Covariate Regressors

We have added support for covariate regressors for all forecasting models. Covariate regressors are tabular regression models that can be combined with univariate forecasting models to incorporate exogenous information. These are particularly useful for foundation models like Chronos-Bolt, which rely solely on the target time series' historical data and cannot directly use exogenous information (such as holidays or promotions). To improve the predictions of univariate models when covariates are available, a covariate regressor is first fit on the known covariates and static features to predict the target column at each time step. The predictions of the covariate regressor are then subtracted from the target column, and the univariate model then forecasts the residuals. The [Chronos tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-chronos.html) showcases how covariate regressors can be used with Chronos-Bolt.

## General

## Tabular

### Highlights

### New Features
- Parallel model fit support. @LennartPurucker @Innixma (#4606)

### Fixes and Improvements

## TimeSeries

### New Features
* Add fine-tuning support for Chronos and Chronos-Bolt models @abdulfatir (#4608, #4645, #4653, #4655, #4659, #4661, #4673, #4677)
* Add Chronos-Bolt @canerturkmen (#4625)
* `TimeSeriesPredictor.leaderboard` now can compute extra metrics and return hyperparameters for each model @shchur (#4481)
* Add `target_scaler` support for all forecasting models @shchur (#4460, #4644)
* Add `covariate_regressor` support for all forecasting models @shchur (#4566, #4641)
* Add method to convert a TimeSeriesDataFrame to a regular pd.DataFrame @shchur (#4415)
* [experimental] Add the weighted cumulative error forecasting metric @shchur (#4594)
* [experimental] Allow custom ensemble model types for time series @shchur (#4662)

### Fixes and Improvements
* Update presets @canerturkmen @shchur (#4656, #4658, #4666, #4672)
* Unify all Croston models into a single class @shchur (#4564)
* Bump `statsforecast` version to 1.7 @canerturkmen @shchur (#4194, #4357)
* Fix deep learning models failing if item_ids have StringDtype @rsj123 (#4539)
* Update logic for inferring the time series frequency @shchur (#4540)
* Speed up and reduce memory usage of the `TimeSeriesFeatureGenerator` preprocessing logic @shchur (#4557)
* Update to GluonTS v0.16.0 @shchur (#4628)
* Refactor GluonTS default parameter handling, update TiDE parameters @canerturkmen (#4640)
* Move covariate scaling logic into a separate class @shchur (#4634)
* Prune timeseries unit and smoke tests @canerturkmen (#4650)
* Minor fixes @abdulfatir @canerturkmen @shchur (#4259, #4299, #4395, #4386, #4409, #4533, #4565, #4633, #4647)


## Multimodal

### Fixes and Improvements
* Fix Missing Validation Metric While Resuming A Model Failed At Checkpoint Fusing Stage by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4449
* Add coco_root for better support for custom dataset in COCO format. by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/3809
* Add COCO Format Saving Support and Update Object Detection I/O Handling by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/3811
* Skip MMDet Config Files While Checking with bandit by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4630
* Fix Logloss Bug and Refine Compute Score Logics by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4629
* Fix Index Typo in Tutorial by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4642
* Fix Proba Metrics for Multiclass by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4643
* Support torch 2.4 by @tonyhoo in https://github.com/autogluon/autogluon/pull/4360
* Add Installation Guide for Object Detection in Tutorial by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4430
* Add Bandit Warning Mitigation for Internal `torch.save` and `torch.load` Usage by @tonyhoo in https://github.com/autogluon/autogluon/pull/4502
* update accelerate version range by @cheungdaven in https://github.com/autogluon/autogluon/pull/4596
* Bound nltk version to avoid verbose logging issue by @tonyhoo in https://github.com/autogluon/autogluon/pull/4604
* Upgrade TIMM by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4580
* Key dependency updates in _setup_utils.py for v1.2 release by @tonyhoo in https://github.com/autogluon/autogluon/pull/4612
* Configurable Number of Checkpoints to Keep per HPO Trial by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4615
* Refactor Metrics for Each Problem Type by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4616
* Fix Torch Version and Colab Installation for Object Detection by @FANGAreNotGnu in https://github.com/autogluon/autogluon/pull/4447

## Special Thanks

WIP: Come back in a few hours for the full release notes

* [Xiyuan Zhang](https://xiyuanzh.github.io/) for leading the development of TabPFNMix!
* The TabPFN author's [Noah Hollmann](https://twitter.com/noahholl), [Samuel Muller](https://twitter.com/SamuelMullr), [Katharina Eggensperger](https://twitter.com/KEggensperger), and [Frank Hutter](https://twitter.com/FrankRHutter) for unlocking the power of foundation models for tabular data, and the TabForestPFN author's [Felix den Breejen](https://github.com/FelixdenBreejen), [Sangmin Bae](https://scholar.google.com/citations?user=T5rHY14AAAAJ&hl=ko), [Stephen Cha](https://scholar.google.com/citations?user=jqLvFdIAAAAJ&hl=en), and [Se-Young Yun](https://fbsqkd.github.io/) for extending the idea to a more generic representation. Our TabPFNMix work builds upon the shoulders of giants.
* [Lennart Purucker](https://x.com/LennartPurucker) for leading development of the [parallel model fit functionality](https://github.com/autogluon/autogluon/pull/4606) and pushing AutoGluon to its limits in the 2024 Kaggle AutoML Grand Prix.
* [Robert Hatch](https://www.kaggle.com/roberthatch), [Tilii](https://www.kaggle.com/tilii7), [Optimistix](https://www.kaggle.com/optimistix), [Mart Preusse](https://www.kaggle.com/martinapreusse), [Ravi Ramakrishnan](https://www.kaggle.com/ravi20076), [Samvel Kocharyan](https://www.kaggle.com/samvelkoch), [Kirderf](https://www.kaggle.com/kirderf), [Carl McBride Ellis](https://www.kaggle.com/carlmcbrideellis), [Konstantin Dmitriev](https://www.kaggle.com/kdmitrie), and others for their insightful discussions and for championing AutoGluon on Kaggle!
* [Eddie Bergman](https://x.com/edberg_wardman) for his insightful surprise code review of the [tabular callback support](https://github.com/autogluon/autogluon/pull/4327) feature.

## New Contributors
* @nathanaelbosch made their first contribution in https://github.com/autogluon/autogluon/pull/4366
* @adibiasio made their first contribution in https://github.com/autogluon/autogluon/pull/4391
* @abdulfatir made their first contribution in https://github.com/autogluon/autogluon/pull/4608
* @echowve made their first contribution in https://github.com/autogluon/autogluon/pull/4667
* @abhishek-iitmadras made their first contribution in https://github.com/autogluon/autogluon/pull/4685
* @xiyuanzh made their first contribution in https://github.com/autogluon/autogluon/pull/4694

------
# REMOVE BEFORE MERGING - AUTOMATICALLY GENERATED RELEASE NOTES

## What's Changed
* [tabular] Fix LightGBM quantile predict_proba dtype by @Innixma in https://github.com/autogluon/autogluon/pull/4272
* [tabular] Fix RuntimeWarning in LinearModel by @Innixma in https://github.com/autogluon/autogluon/pull/4224
* [tabular] Add tutorial with a deep dive on how AutoGluon works by @rey-allan in https://github.com/autogluon/autogluon/pull/4284
* [tabular] Validate CPU/GPU settings by @Innixma in https://github.com/autogluon/autogluon/pull/4277
* [tabular] Improve hyperparameters logging by @Innixma in https://github.com/autogluon/autogluon/pull/4258
* [tabular] Add readable error message for invalid models in persist by @Innixma in https://github.com/autogluon/autogluon/pull/4285
* [tabular] Add roc_auc_ovo / ovr by @Innixma in https://github.com/autogluon/autogluon/pull/4248
* [tabular] Improve logging for invalid label by @Innixma in https://github.com/autogluon/autogluon/pull/4287
* [tabular] Fix Stacker max_models logic by @Innixma in https://github.com/autogluon/autogluon/pull/4290
* [Tabular] Avoid Edge Case Divison By Zero Error by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4317
* [tabular] Use ResourceManager for text_ngram.py by @Innixma in https://github.com/autogluon/autogluon/pull/4335
* [tabular] Remove sklearnex RF logic that raises exception by @Innixma in https://github.com/autogluon/autogluon/pull/4353
* [tabular] Fix file path for RF ONNX by @Innixma in https://github.com/autogluon/autogluon/pull/4352
* [tabular] Add `ag.compile` parameter to models by @Innixma in https://github.com/autogluon/autogluon/pull/4354
* [tabular] Fix exception when >20 configs present in medium quality preset by @Innixma in https://github.com/autogluon/autogluon/pull/4379
* [tabular] Fix exception in HPO when only specifying one of `num_cpus`/`num_gpus` by @Innixma in https://github.com/autogluon/autogluon/pull/4384
* [tabular] Add informative logging for NN_TORCH time exceeded by @Innixma in https://github.com/autogluon/autogluon/pull/4382
* [Tabular,Core] Fix Temperature Scaling by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4396
* [Tabular] Support for Raising an Error When No Models Were Trained Successfully During fit() by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4389
* [tabular] Add RF ONNX compilation unit test by @Innixma in https://github.com/autogluon/autogluon/pull/4398
* [tabular] Fix log_to_file docstring by @Innixma in https://github.com/autogluon/autogluon/pull/4399
* [tabular] raise_on_no_models_fitted=True by @Innixma in https://github.com/autogluon/autogluon/pull/4400
* [Tabular] Fix ROC AUC Average for Macro is Macro by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4407
* [tabular] Add `mcc` metric to eval_metric docstring by @Innixma in https://github.com/autogluon/autogluon/pull/4402
* [tabular] Fix feature pruning crash on Windows by @Innixma in https://github.com/autogluon/autogluon/pull/4405
* [tabular] Add initial callbacks support by @Innixma in https://github.com/autogluon/autogluon/pull/4327
* [tabular] Add `valid_stacker` and `use_orig_features` options by @Innixma in https://github.com/autogluon/autogluon/pull/4444
* [tabular] Fix incorrect return type in `predict_multi` for regression by @Innixma in https://github.com/autogluon/autogluon/pull/4450
* [tabular] Set num_bag_sets to 1 by default by @Innixma in https://github.com/autogluon/autogluon/pull/4446
* [tabular] Add AdaptiveES support to NN_TORCH by @Innixma in https://github.com/autogluon/autogluon/pull/4436
* [tabular] Fix refit crash by @Innixma in https://github.com/autogluon/autogluon/pull/4474
* [tabular] Minor logging improvement on verbosity=4 by @Innixma in https://github.com/autogluon/autogluon/pull/4498
* [tabular] Make refit_full respect user `num_cpus` and `num_gpus` by @Innixma in https://github.com/autogluon/autogluon/pull/4495
* [tabular] Doc cleanup, add positive_class init arg by @Innixma in https://github.com/autogluon/autogluon/pull/4445
* [tabular] Enhance predict_proba_multi by @Innixma in https://github.com/autogluon/autogluon/pull/4527
* [tabular] Speed up learning_curves tests by @Innixma in https://github.com/autogluon/autogluon/pull/4546
* [tabular] Speed up hpo tests by @Innixma in https://github.com/autogluon/autogluon/pull/4547
* [tabular] Disable AutoGluon-Lite CI test by @Innixma in https://github.com/autogluon/autogluon/pull/4549
* [tabular] Remove ensemble cascade support by @Innixma in https://github.com/autogluon/autogluon/pull/4548
* [tabular] Add support for controlling AutoGluon's repeated cross-validation behavior by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4552
* [tabular] Fix FASTAI edgecase crash with NaN by @Innixma in https://github.com/autogluon/autogluon/pull/4584
* [tabular] Set calibrate_decision_threshold="auto" by @Innixma in https://github.com/autogluon/autogluon/pull/4632
* [tabular] AutoGluon Distributed by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4606
* [tabular] Fix lightgbm import warning by @shchur in https://github.com/autogluon/autogluon/pull/4675
* [tabular] Fix weights_only=False torch warnings by @Innixma in https://github.com/autogluon/autogluon/pull/4686
* [tabular] Remove outdated macOS Python 3.11 CatBoost restriction for test_tabular.py by @abhishek-iitmadras in https://github.com/autogluon/autogluon/pull/4690
* Add TabPFNMix regression support by @xiyuanzh in https://github.com/autogluon/autogluon/pull/4694
* Disable callbacks for parallel fit_strategy by @Innixma in https://github.com/autogluon/autogluon/pull/4700
* Refactor TabularDataset by @Innixma in https://github.com/autogluon/autogluon/pull/4613
* Add TabPFNMix model by @Innixma in https://github.com/autogluon/autogluon/pull/4671

* bump lightgbm and skex versions by @Innixma in https://github.com/autogluon/autogluon/pull/4688
* remove private catboost call by @Innixma in https://github.com/autogluon/autogluon/pull/4687
* Fix Torch accidentally being imported immediately by @Innixma in https://github.com/autogluon/autogluon/pull/4635
* fix: Convert unique values to strings in `check_if_nlp_feature` by @rsj123 in https://github.com/autogluon/autogluon/pull/4682
* Add `compute_metric` by @Innixma in https://github.com/autogluon/autogluon/pull/4631

* Update to v1.1.2 by @Innixma in https://github.com/autogluon/autogluon/pull/4263
* [AWESOME] Add WiDS Competition Solution by @Innixma in https://github.com/autogluon/autogluon/pull/4265
* Add SECURITY.md for vulnerability reporting by @tonyhoo in https://github.com/autogluon/autogluon/pull/4298
* [CI] Disable package diff by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4279
* add link for conda release by @suzhoum in https://github.com/autogluon/autogluon/pull/4283
* Update infer_types.py to say the default handling is zero by @zkalson in https://github.com/autogluon/autogluon/pull/4311
* Ray version upgrade by @suzhoum in https://github.com/autogluon/autogluon/pull/4302
* add icml talk info by @suzhoum in https://github.com/autogluon/autogluon/pull/4336
* [Proposal] Add Support for Custom Memory (Soft) Limit by @LennartPurucker in https://github.com/autogluon/autogluon/pull/4333
* [common/features] line_length=119 by @Innixma in https://github.com/autogluon/autogluon/pull/4341
* Add __init__.py to all unit tests by @Innixma in https://github.com/autogluon/autogluon/pull/4340
* [core] Add `flake8` to the `[test]` requirements in `core/setup.py` by @nathanaelbosch in https://github.com/autogluon/autogluon/pull/4366
* Add Kaggle Grand Prix episode 3 and 4 results to AWESOME.md by @Innixma in https://github.com/autogluon/autogluon/pull/4380
* [core] Speed up `EnsembleSelection._fit` by @nathanaelbosch in https://github.com/autogluon/autogluon/pull/4367
* Addressed Unexpected Torch Seed Behavior with Dataloader by @adibiasio in https://github.com/autogluon/autogluon/pull/4391
* Added Copy Files s3 Util Function by @adibiasio in https://github.com/autogluon/autogluon/pull/4404
* Skip temperature scaling if negative temperature, increase learning rate by @Innixma in https://github.com/autogluon/autogluon/pull/4397
* [common] Add utility methods to FeatureMetadata by @Innixma in https://github.com/autogluon/autogluon/pull/4401
* Replace black and isort with ruff by @shchur in https://github.com/autogluon/autogluon/pull/4412
* Fix Source Install by @Innixma in https://github.com/autogluon/autogluon/pull/4425
* Added Learning Curve Generation Feature by @adibiasio in https://github.com/autogluon/autogluon/pull/4411
* Upgrade scikit-learn to 1.5.1 by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4420
* Add kaggle results up to Sept 1st 2024 by @Innixma in https://github.com/autogluon/autogluon/pull/4458
* [CI] Update Actions by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4462
* Updated the PAT secrets used for CICD by @tonyhoo in https://github.com/autogluon/autogluon/pull/4465
* [temp] Disable CI/CD for non-master branches by @tonyhoo in https://github.com/autogluon/autogluon/pull/4471
* Add Grand Prix result to AWESOME.md by @Innixma in https://github.com/autogluon/autogluon/pull/4472
* Fix Early Stopping Callback exception by @Innixma in https://github.com/autogluon/autogluon/pull/4473
* Revert "[temp] Disable CI/CD for non-master branches (#4471)" by @tonyhoo in https://github.com/autogluon/autogluon/pull/4479
* [core] Enhance generate_train_test_split by @Innixma in https://github.com/autogluon/autogluon/pull/4478
* Fix py38 import by @Innixma in https://github.com/autogluon/autogluon/pull/4485
* [CI] Update benchmark actions by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4504
* Add September Kaggle Competition Results by @Innixma in https://github.com/autogluon/autogluon/pull/4507
* Update Matplotlib range by @suzhoum in https://github.com/autogluon/autogluon/pull/4511
* [awesome.md] Add 2nd place Kaggle solution post to September comp by @Innixma in https://github.com/autogluon/autogluon/pull/4513
* Drop Python 3.8 Support by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4512
* [Master] Update installation instructions to use uv temporarily by @tonyhoo in https://github.com/autogluon/autogluon/pull/4516
* [Bug] Cap pyarrow to fix source installation issue by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4520
* [awesome.md] Add 17th place solution for S4E6 Kaggle Playground by @Innixma in https://github.com/autogluon/autogluon/pull/4531
* [features] Speed up DropDuplicatesFeatureGenerator by @shchur in https://github.com/autogluon/autogluon/pull/4543
* [CI] Fix failure in triggering CI by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4560
* add +cpu tag for cpu installation guide by @tonyhoo in https://github.com/autogluon/autogluon/pull/4554
* [Upgrade] Bulk package upgrade for v1.2 by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4570
* Version bump torchvision<0.21 by @Innixma in https://github.com/autogluon/autogluon/pull/4579
* Update install instructions by @Innixma in https://github.com/autogluon/autogluon/pull/4581
* Update full_install.sh to be simultaneous by @Innixma in https://github.com/autogluon/autogluon/pull/4582
* Fix edgecase label crash by @Innixma in https://github.com/autogluon/autogluon/pull/4583
* [install] Fix full_install.sh to be editable by @Innixma in https://github.com/autogluon/autogluon/pull/4587
* [CI] Fix container checkouts incorrect branch by @suzhoum in https://github.com/autogluon/autogluon/pull/4588
* fix platform tests by @suzhoum in https://github.com/autogluon/autogluon/pull/4463
* Fix uv source install by @Innixma in https://github.com/autogluon/autogluon/pull/4592
* Support python3.12 by @suzhoum in https://github.com/autogluon/autogluon/pull/4536
* [CI-Bench] Add AMLB changes by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4603
* [CI] Schedule benchmark everday by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4598
* [CI Benchmark] Add dependencies for AG Bench 0.4.4 by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4607
* Fix specifying None in upload_file prefix by @Innixma in https://github.com/autogluon/autogluon/pull/4609
* Add TODOs/FIXMEs by @Innixma in https://github.com/autogluon/autogluon/pull/4611
* Add AdamW support to NN_TORCH by @Innixma in https://github.com/autogluon/autogluon/pull/4610
* [Docker - v1.2] Update all images by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4614
* [Doc] Fixed broken links in the tutorial by @tonyhoo in https://github.com/autogluon/autogluon/pull/4621
* [Benchmark] Add PyArrow required by clean scripts by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4626
* Fix AutoGluon Dashboard by @prateekdesai04 in https://github.com/autogluon/autogluon/pull/4652
* add val operation when skip hpo by @echowve in https://github.com/autogluon/autogluon/pull/4667
* [Website] Add OpenGraph metadata for social media previews by @tonyhoo in https://github.com/autogluon/autogluon/pull/4665
* [Install] Update UV installation instructions and add dedicated UV tabs by @tonyhoo in https://github.com/autogluon/autogluon/pull/4618
* Upgrade to numpy 2.0 by @suzhoum in https://github.com/autogluon/autogluon/pull/4538
* [core] Bump accelerate version to >=0.34,<1.0 by @shchur in https://github.com/autogluon/autogluon/pull/4676

* fix: enable autogluon build on aarch64 platforms by @abhishek-iitmadras in https://github.com/autogluon/autogluon/pull/4663
* Remove unused experimental predictor by @Innixma in https://github.com/autogluon/autogluon/pull/4692
* Update to v1.2 by @Innixma in https://github.com/autogluon/autogluon/pull/4691
* [common] Update try_import.py by update CatBoost requirement by @abhishek-iitmadras in https://github.com/autogluon/autogluon/pull/4685

* bump ray to <2.40 by @Innixma in https://github.com/autogluon/autogluon/pull/4689
* [timeseries] Update Chronos and in-depth tutorials by @shchur in https://github.com/autogluon/autogluon/pull/4684
* [timeseries] deprecate Chronos optimization_strategy by @canerturkmen in https://github.com/autogluon/autogluon/pull/4696



**Full Changelog**: https://github.com/autogluon/autogluon/compare/v1.1.1...v1.2.0
