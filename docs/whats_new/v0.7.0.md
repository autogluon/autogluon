# Version 0.7.0

We're happy to announce the AutoGluon 0.7 release. This release contains a new module `autogluon.eda` for exploratory
data analysis. Meanwhile, 0.7 offers enhancements to Tabular, Multimodal, and Time Series
modules, along with many quality of life improvements and fixes.

As always, only load previously trained models using the same version of AutoGluon that they were originally trained on.
Loading models trained in different versions of AutoGluon is not supported.

This release contains [**170** commits from **21** contributors](https://github.com/autogluon/autogluon/graphs/contributors?from=2023-01-10&to=2023-02-16&type=c)!

See the full commit change-log here: https://github.com/autogluon/autogluon/compare/v0.6.2...v0.7.0

Special thanks to @MountPOTATO who is the first time contributors to AutoGluon this release!

Full Contributor List (ordered by # of commits):

@Innixma, @zhiqiangdon, @yinweisu, @gradientsky, @shchur, @sxjscience, @FANGAreNotGnu, @yongxinw, @cheungdaven,
@liangfu,
@tonyhoo, @bryanyzhu, @suzhoum, @canerturkmen, @giswqs, @gidler, @yzhliu, @lvwerra, @Raldir, @Linuxdex and @BingzhaoZhu

This version supports Python versions from 3.8 to 3.10 and dropped the support of Python 3.7.

# Changes

## AutoMM

AutoGluon Multimodal (a.k.a AutoMM) supports three new features: 1) document classification; 2) named entity recognition
for Chinese language; 3) few shot learning with SVM  

Meanwhile, we removed `autogluon.text` and `autogluon.vision` as these features are supported in `autogluon.multimodal`

### New features

- Document Classification
  - Add scanned document classification (experimental).
  - Customers can train models for scanned document classification in a few lines of codes
  - See [tutorials](https://auto.gluon.ai/stable/tutorials/multimodal/document/document_classification.html)
  - Contributors and commits: @cheungdaven (#2765, #2826, #2833, #2928)
- NER for Chinese Language
  - Support Chinese named entity recognition
  - See [tutorials](https://auto.gluon.ai/stable/tutorials/multimodal/document/document_classification.html)
  - Contributors and commits:  @cheungdaven (#2676, #2709)
- Few Shot Learning with SVM
  - Improved few shot learning by adding SVM support
  - See [tutorials](https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/few_shot_learning.html)
  - Contributors and commits: @yongxinw (#2850)

### Other Enhancements

- Add new loss function `FocalLoss`. @yongxinw (#2860)
- Add matcher realtime inference support. @zhiqiangdon (#2613)
- Add matcher HPO. @zhiqiangdon (#2619)
- Add YOLOX models (small, large, and x-large) and update presets for object detection. @FANGAreNotGnu (#2644, #2867, #2927, #2933)
- Add AutoMM presets @zhiqiangdon. (#2620, #2749, #2839)
- Add model dump for models from huggingface, timm and mmdet. @suzhoum @FANGAreNotGnu @liangfu (#2682, #2700, #2737, #2840)
- Bug fix / refactor for NER @cheungdaven (#2659, #2696, #2759, #2773)

### Deprecations

* `autogluon.vision` namespace is deprecated. @bryanyzhu (#2790, #2819, #2832)
* `autogluon.text` namespace is deprecated. @sxjscience Innixma (#2695, #2847)



## Tabular

1) TabularPredictor’s inference speed has been heavily optimized, with an average 250% speedup for real-time inference. This means that TabularPredictor can satisfy <10 ms end-to-end latency on many datasets when using `infer_limit`, and the `high_quality` preset can satisfy <100 ms end-to-end latency on many datasets by default.
2) TabularPredictor’s `"multimodal"` hyperparameter preset now leverages the full capabilities of MultimodalPredictor, resulting in stronger performance on datasets containing a mix of tabular, image, and text features.

### Performance Improvements

- Upgraded versions of all dependency packages to use the latest releases. @Innixma (#2823, #2829, #2834, #2887, #2915)
- Accelerated ensemble inference speed by 150% by removing TorchThreadManager context switching. @liangfu (#2472)
- Accelerated FastAI neural network inference speed by 100x+ and training speed by 10x on datasets with many features. @Innixma (#2909)
- (From 0.6.1) Avoid unnecessary DataFrame copies to accelerate feature preprocessing by 25%. @liangfu (#2532)
- (From 0.6.1) Refactor `NN_TORCH` model to be dataset iterable, leading to a 100% inference speedup. @liangfu (#2395)
- MultimodalPredictor is now used as a member of the ensemble when `TabularPredictor.fit` is passed `hyperparameters="multimodal"`. @Innixma (#2890)

### API Enhancements

- Added `predict_multi` and `predict_proba_multi` methods to `TabularPredictor` to efficiently get predictions from multiple models. @Innixma (#2727)
- Allow label column to not be present in `leaderboard` calls when scoring is disabled. @Innixma (#2912)

### Deprecations

- Added a deprecation warning when calling `predict_proba` with `problem_type="regression"` @Innixma (#2684)

### Bug Fixes / Doc Improvements

- Fixed incorrect time_limit estimation in `NN_TORCH` model. @Innixma (#2909)
- Fixed error when fitting with only text features. @Innixma (#2705)
- Fixed error when `calibrate=True, use_bag_holdout=True` in `TabularPredictor.fit`. @Innixma (#2715)
- Fixed error when tuning `n_estimators` with RandomForest / ExtraTrees models. @Innixma (#2735)
- Fixed missing onnxruntime dependency on Linux/MacOS when installing optional dependency `skl2onnx`. @liangfu (#2923)
- Fixed edge-case RandomForest error on Windows. @yinweisu (#2851)
- Added improved logging for `refit_full`. @Innixma (#2913)
- Added `compile_models` to the deployment tutorial. @liangfu (#2717)
- Various internal code refactoring. @Innixma (#2744, #2887)
- Various doc and logging improvements. @Innixma (#2668)

### Core Changes

- Removed `dask` and `distributed` dependencies. @Innixma (#2691)

## Time Series

### New features

- `TimeSeriesPredictor` now supports **past covariates** (a.k.a.dynamic features or related time series which is not known for time steps to be predicted). @shchur (#2680)
- 


### More tutorials and examples

Improved documentation and new tutorials:

- Updated [Quickstart tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-quickstart.html)
- New! [In-depth tutorial](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-indepth.html)
-

New! [Overview of available models and hyperparameters](https://auto.gluon.ai/stable/tutorials/timeseries/forecasting-model-zoo.html)

- Updated [API documentation](https://auto.gluon.ai/stable/api/autogluon.predictor.html#module-5)

@shchur (#2120, #2127, #2146, #2174, #2187, #2354)

### Miscellaneous

@shchur

- Deprecate passing quantile_levels to TimeSeriesPredictor.predict (#2277)
- Use static features in GluonTS forecasting models (#2238)
- Make sure that time series splitter doesn't trim training series shorter than prediction_length + 1 (#2099)
- Fix hyperparameter overloading in HPO for time series models (#2189)
- Clean up the TimeSeriesDataFrame public API (#2105)
- Fix item order in GluonTS models predictions (#2092)
- Implement hash_ts_dataframe_items (#2060)
- Speed up TimeSeriesDataFrame.slice_by_timestep (#2020)
- Speed up RandomForestQuantileRegressor and ExtraTreesQuantileRegressor (#2204)
- Various backend enhancements / refactoring / cleanup (#2314, #2294, #2292, #2278, #1985, #2398)

@canerturkmen

- Increase the number of samples used by DeepAR at prediction time (#2291)
- revise timeseries presets to minimum context length of 10 (#2065)
- Fix timeseries daily frequency inferred period (#2100)
- Various backend enhancements / refactoring / cleanup (#2286, #2302, #2240, #2093, #2098, #2044, #2385, #2355, #2405)
