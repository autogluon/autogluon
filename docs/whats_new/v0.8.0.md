# Version 0.8.0
We're happy to announce the AutoGluon 0.8 release. [Highlights of new features]

As always, only load previously trained models using the same version of AutoGluon that they were originally trained on. Loading models trained in different versions of AutoGluon is not supported.

This release contains XXX commits from XX contributors!

See the full commit change-log here: XXX

Full Contributor List (ordered by # of commits):

XXX

AutoGluon 0.8 supports Python versions 3.8, 3.9, and 3.10.

# Changes
XXX

## General
* General doc improvements @tonyhoo @Innixma @yinweisu @gidler @cnpgs @isunli @giswqs (#2940, #2953, #2963, #3007, #3027, #3059, #3068, #3083, #3128, #3129, #3130, #3147, #3174, #3187, #3256, #3258)
* General code fixes and improvements @yinweisu @Innixma (#2921, #3078, #3113, #3140, #3206)
* CI improvements @yinweisu @gidler @yzhliu @liangfu @gradientsky (#2965, #3008, #3013, #3020, #3046, #3053, #3108, #3135, #3159, #3283, #3185)
* New AutoGluon Webpage @gidler @shchur (#2924)
* Support sample_weight in RMSE @jjaeyeon (#3052)
* Move AG search space to common @yinweisu (#3192)
* Deprecation utils @yinweisu (#3206, #3209)
* Update namespace packages for PEP420 compatibility @gradientsky (#3228)


AutoMM

AutoGluon MultiModal (a.k.a AutoMM) supports two new features: 1) PDF document classification; 2) Open Vocabulary Object Detection. The object detection medium_quality , high_quality and best_quality presets have been upgraded, which bring significant improvements over the previous ones.

New Features

* PDF Document Classification @cheungdaven (#2864, #3043)
* Open Vocabulary Object Detection @FANGAreNotGnu (#3164)

Performance Improvements

* Upgrade the detection engine from mmdet 2.x to mmdet 3.x, and upgrade presets from medium_quality: yolo-s, high_quality: yolox-l, best_quality: yolox-x to medium_quality: yolox-l, high_quality: DINO-Res50, best_quality: DINO-Swin_l  @FANGAreNotGnu (#3262)
* Speedup fusion model training with deepspeed strategy @liangfu (#2932)
* Enable detection backbone freezing to boost finetuning speed and save GPU usage @FANGAreNotGnu (#3220)

Other Enhancements

* Support passing data path to the fit() API @zhiqiangdon (#3006)
* Upgrade TIMM to the latest v0.9.* @zhiqiangdon (#3282)
* Support xywh output for object detection @FANGAreNotGnu (#2948)
* Fusion model inference acceleration with TensorRT @liangfu (#2836, #2987)
* Support customizing image data augmentation @zhiqiangdon (#3022)
* Add yoloxm and yoloxtiny @FangAreNotGnu (#3038)
* Add MultiImageMix Dataset for Object Detection @FangAreNotGnu (#3094)
* Support loading specific checkpoints @zhiqiangdon (#3244)
* Support model parameter number statistics @zhiqiangdon (#3289)

Bug Fixes / Code and Doc Improvements

* General bug fixes and improvements @zhiqiangdon @liangfu @cheungdaven @xiaochenbin9527 @Innixma @FANGAreNotGnu @gradientsky @yinweisu @yongxinw (#2939, #2989,  #2983, #2998, #3001, #3004, #3006, #3025, #3026, #3048, #3055, #3064, #3070, #3081, #3090, #3103, #3106, #3119, #3155, #3158, #3167, #3180, #3188, #3222, #3261, #3266, #3277, #3279, #3261, #3267)
* General doc improvements @suzhoum (#3295, #3300)
* Remove clip from fusion models @liangfu (#2946)
* Refactor inferring problem type and output shape @zhiqiangdon (#3227)
* Log GPU info @zhiqaingdon (#3291)


## Tabular
XXX
### New Features
* Zero-shot config
* TabPFN model is now supported as an experimental model. TabPFN is a viable model option when inference speed is not a concern, and the number of rows of training data is less than 10,000. @Innixma (#3270)
* Backend support for distributed training, which will be available with the next Cloud module release. @yinweisu (#3054, #3110, #3115, #3131, #3142, #3179, #3216)
### Performance Improvements
* Accelerate boolean preprocessing @Innixma (#2944)
### Other Enhancements
* Add quantile regression support for CatBoost @shchur (#3165)
* Implement quantile regression for LGBModel @shchur (#3168)
* Log to file support @yinweisu (#3232)
* Add support for `included_model_types` @yinweisu (#3239)
* Add enable_categorical=True support to XGBoost @Innixma (#3286)
### Bug Fixes / Code and Doc Improvements
* General bug fixes and improvements @Innixma @cnpgs @shchur @yinweisu @gradientsky (#2865, #2936, #2990, #3045, #3060, #3069, #3148, #3182, #3199, #3226, #3257, #3259, #3268, #3269, #3287, #3288, #3285, #3293, #3294)
* Move interpretable logic to InterpretableTabularPredictor @Innixma (#2981)
* Enhance drop_duplicates, enable by default @Innixma (#3010)
* Refactor params_aux & memory checks @Innixma (#3033)
* Raise regression `pred_proba` @Innixma (#3240)


## Timeseries
XXX
### New Features
XXX
### Performance Improvements
* Speed up featurization for AutoGluonTabularModel @shchur (#2970, #2973)
* Implement prediction caching and refactor prediction logic in AbstractTimeSeriesTrainer @shchur (#3237)
### Other Enhancements
* Implement OOF prediction caching @shchur (#3062)
* Train multiple models for multi-window backtesting @shchur (#3080)
* `refit_full` is supported now for TimeSeriesPredictor @shchur (#3157)
* Implement recurrent forecasting model based on TabularPredictor and MLForecast @shchur (#3177, #3183)
### Deprecations
* Deprecate quantiles argument to TimeSeriesPredictor @shchur (#3193)
### Bug Fixes / Code and Doc Improvements
* General bug fixes and improvements @shchur (#2977, #3058, #3066, #3120, #3160, #3184, #3202, #3230, #3233, #3236, #3252, #3255, #3275, #3281, #3290)
* General doc improvements @shchur (#2960, #2964, #3296)
* Refactor local forecasting models @shchur (#3214)


## Exploratory Data Analysis (EDA) tools
In 0.8 we introduce a few new tools to help with data exploration and feature engineering:
* **Anomaly Detection** @gradientsky (#3124, #3137) - helps to identify unusual patterns or behaviors in data that deviate significantly from the norm.  It's best used when finding outliers, rare events, or suspicious activities that could indicate fraud, defects, or system failures. Check the [Anomaly Detection Tutorial](https://auto.gluon.ai/stable/tutorials/eda/eda-auto-anomaly-detection.html) to explore the functionality.
* **Partial Dependence Plots** @gradientsky (#3071, #3079) -  visualize the relationship between a feature and the model's output for each individual instance in the dataset. Two-way variant can visualize potential interactions between any two features. Please see this tutorial for more detail: [Using Interaction Charts To Learn Information About the Data](https://auto.gluon.ai/stable/tutorials/eda/eda-auto-analyze-interaction.html#using-interaction-charts-to-learn-information-about-the-data)
### Bug Fixes / Code and Doc Improvements
* Switch regression analysis in `quick_fit` to use residuals plot @gradientsky (#3039)
* Added `explain_rows` method to `autogluon.eda.auto` - Kernel SHAP visualization @gradientsky (#3014)
* General improvements and fixes @gradientsky (#2991, #3056, #3102, #3107, #3138)
