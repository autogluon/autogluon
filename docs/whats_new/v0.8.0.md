# Version 0.8.0
We're happy to announce the AutoGluon 0.8 release. [Highlights of new features]

As always, only load previously trained models using the same version of AutoGluon that they were originally trained on. Loading models trained in different versions of AutoGluon is not supported.

This release contains XXX commits from XX contributors!

See the full commit change-log here: XXX

Full Contributor List (ordered by # of commits):

XXX

AutoGluon 0.8 supports Python versions 3.8, 3.9, and 3.10.

# Changes

## General
* General doc improvements @tonyhoo @Innixma @yinweisu @gidler @cnpgs @isunli @giswqs (#2940, #2953, #2963, #3007, #3027, #3059, #3068, #3083, #3128, #3129, #3130, #3147, #3174, #3187, #3256, #3258, #3280, #3306, #3307, #3311, #3313)
* General code fixes and improvements @yinweisu @Innixma (#2921, #3078, #3113, #3140, #3206)
* CI improvements @yinweisu @gidler @yzhliu @liangfu @gradientsky (#2965, #3008, #3013, #3020, #3046, #3053, #3108, #3135, #3159, #3283, #3185)
* New AutoGluon Webpage @gidler @shchur (#2924)
* Support sample_weight in RMSE @jjaeyeon (#3052)
* Move AG search space to common @yinweisu (#3192)
* Deprecation utils @yinweisu (#3206, #3209)
* Update namespace packages for PEP420 compatibility @gradientsky (#3228)


## AutoMM

AutoGluon MultiModal (a.k.a AutoMM) supports two new features: 1) PDF document classification; 2) Open Vocabulary Object Detection. The object detection medium_quality , high_quality and best_quality presets have been upgraded, which bring significant improvements over the previous ones.

New Features

* PDF Document Classification @cheungdaven (#2864, #3043)
* Open Vocabulary Object Detection @FANGAreNotGnu (#3164)

Performance Improvements

* Upgrade the detection engine from mmdet 2.x to mmdet 3.x, and upgrade presets from medium_quality: yolo-s, high_quality: yolox-l, best_quality: yolox-x to medium_quality: yolox-l, high_quality: DINO-Res50, best_quality: DINO-Swin_l  @FANGAreNotGnu (#3262)
* Speedup fusion model training with deepspeed strategy @liangfu (#2932)
* Enable detection backbone freezing to boost finetuning speed and save GPU usage @FANGAreNotGnu (#3220)

Other Enhancements

* Support passing data path to the fit() API @zhiqiangdon (#3006)
* Upgrade TIMM to the latest v0.9.* @zhiqiangdon (#3282)
* Support xywh output for object detection @FANGAreNotGnu (#2948)
* Fusion model inference acceleration with TensorRT @liangfu (#2836, #2987)
* Support customizing image data augmentation @zhiqiangdon (#3022)
* Add yoloxm and yoloxtiny @FangAreNotGnu (#3038)
* Add MultiImageMix Dataset for Object Detection @FangAreNotGnu (#3094)
* Support loading specific checkpoints @zhiqiangdon (#3244)
* Support model parameter number statistics @zhiqiangdon (#3289)
* Support `predict_proba` for fewshot svm learner @yongxinw (#3267)

Bug Fixes / Code and Doc Improvements

* General bug fixes and improvements @zhiqiangdon @liangfu @cheungdaven @xiaochenbin9527 @Innixma @FANGAreNotGnu @gradientsky @yinweisu @yongxinw (#2939, #2989,  #2983, #2998, #3001, #3004, #3006, #3025, #3026, #3048, #3055, #3064, #3070, #3081, #3090, #3103, #3106, #3119, #3155, #3158, #3167, #3180, #3188, #3222, #3261, #3266, #3277, #3279, #3261, #3267)
* General doc improvements @suzhoum @FANGAreNotGnu @zhiqiangdon (#3295, #3300, #3305, #3314)
* Remove clip from fusion models @liangfu (#2946)
* Refactor inferring problem type and output shape @zhiqiangdon (#3227)
* Log GPU info @zhiqaingdon (#3291)


## Tabular
XXX
### New Features
* We've added an experimental Zero-shot config, which performs well on small datasets <5000 rows. To try it out, specify `preset="experimental_zeroshot_hpo"` when calling `fit()` @Innixma (#3312)
* TabPFN model is now supported as an experimental model. TabPFN is a viable model option when inference speed is not a concern, and the number of rows of training data is less than 10,000. @Innixma (#3270)
* Backend support for distributed training, which will be available with the next Cloud module release. @yinweisu (#3054, #3110, #3115, #3131, #3142, #3179, #3216)
### Performance Improvements
* Accelerate boolean preprocessing @Innixma (#2944)
### Other Enhancements
* Add quantile regression support for CatBoost @shchur (#3165)
* Implement quantile regression for LGBModel @shchur (#3168)
* Log to file support @yinweisu (#3232)
* Add support for `included_model_types` @yinweisu (#3239)
* Add enable_categorical=True support to XGBoost @Innixma (#3286)
* Add `calibrate_decision_threshold`, which allows to optimize a given metric's decision threshold for predictions to strongly enhance the metric score. @Innixma (#3298)
### Bug Fixes / Code and Doc Improvements
* General bug fixes and improvements @Innixma @cnpgs @shchur @yinweisu @gradientsky (#2865, #2936, #2990, #3045, #3060, #3069, #3148, #3182, #3199, #3226, #3257, #3259, #3268, #3269, #3287, #3288, #3285, #3293, #3294, #3302)
* Move interpretable logic to InterpretableTabularPredictor @Innixma (#2981)
* Enhance drop_duplicates, enable by default @Innixma (#3010)
* Refactor params_aux & memory checks @Innixma (#3033)
* Raise regression `pred_proba` @Innixma (#3240)


## TimeSeries
In v0.8 we introduce several major improvements to the Time Series module, including new models, upgraded presets that lead to better forecast accuracy, and optimizations that speed up training & inference.

### Highlights
- New models: `PatchTST` and `DLinear` from GluonTS, and `RecursiveTabular` based on integration with the [`mlforecast`](https://github.com/Nixtla/mlforecast) library @shchur (#3177, #3184, #3230)
- Improved accuracy and reduced overall training time thanks to updated presets @shchur (#3281, #3120)
- 3-6x faster training and inference for `AutoARIMA`, `AutoETS`, `Theta`, `DirectTabular`, `WeightedEnsemble` models @shchur (#3062, #3214, #3252)

### New Features
- Dramatically faster repeated calls to `predict()`, `leaderboard()` and `evaluate()` thanks to prediction caching @shchur (#3237)
- Reduce overfitting by using multiple validation windows with the `num_val_windows` argument to `fit()` @shchur (#3080)
- Exclude certain models from presets with the `excluded_model_types` argument to `fit()` @shchur (#3231)
- New method `refit_full()` that refits models on combined train and validation data @shchur (#3157)
- Train multiple configurations of the same model by providing lists in the `hyperparameters` argument @shchur (#3183)
- Time limit set by `time_limit` is now respected by all models @shchur (#3214)

### Enhancements
- Improvements to the `DirectTabular` model (previously called `AutoGluonTabular`): faster featurization, trained as a quantile regression model if `eval_metric` is set to `"mean_wQuantileLoss"` @shchur (#2973, #3211)
- Use correct seasonal period when computing the MASE metric @shchur (#2970)
- Check the AutoGluon version when loading `TimeSeriesPredictor` from disk @shchur (#3233)

### Minor Improvements / Documentation / Bug Fixes
* Update documentation and tutorials @shchur (#2960, #2964, #3296, #3297)
* General bug fixes and improvements @shchur (#2977, #3058, #3066, #3160, #3193, #3202, #3236, #3255, #3275, #3290)

## Exploratory Data Analysis (EDA) tools
In 0.8 we introduce a few new tools to help with data exploration and feature engineering:
* **Anomaly Detection** @gradientsky (#3124, #3137) - helps to identify unusual patterns or behaviors in data that deviate significantly from the norm.  It's best used when finding outliers, rare events, or suspicious activities that could indicate fraud, defects, or system failures. Check the [Anomaly Detection Tutorial](https://auto.gluon.ai/stable/tutorials/eda/eda-auto-anomaly-detection.html) to explore the functionality.
* **Partial Dependence Plots** @gradientsky (#3071, #3079) -  visualize the relationship between a feature and the model's output for each individual instance in the dataset. Two-way variant can visualize potential interactions between any two features. Please see this tutorial for more detail: [Using Interaction Charts To Learn Information About the Data](https://auto.gluon.ai/stable/tutorials/eda/eda-auto-analyze-interaction.html#using-interaction-charts-to-learn-information-about-the-data)
### Bug Fixes / Code and Doc Improvements
* Switch regression analysis in `quick_fit` to use residuals plot @gradientsky (#3039)
* Added `explain_rows` method to `autogluon.eda.auto` - Kernel SHAP visualization @gradientsky (#3014)
* General improvements and fixes @gradientsky (#2991, #3056, #3102, #3107, #3138)
