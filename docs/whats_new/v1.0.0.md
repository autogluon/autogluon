# Version 1.0.0

## General

### Highlights
* Python 3.11 Support @ddelange @yinweisu (#3190)

### Other Enhancements
* Added system info logging utility @Innixma (#3718)

### Dependency Updates
* Upgraded torch to `>=2.0,<2.2` @zhiqiangdon @yinweisu @shchur (#3404, #3587, #3588)
* Upgraded numpy to `>=1.21,<1.29` @prateekdesai04 (#3709)
* Upgraded Pandas to `>=2.0,<2.2` @yinweisu @tonyhoo @shchur (#3498)
* Upgraded scikit-learn to `>=1.3,<1.5` @yinweisu @tonyhoo @shchur (#3498)
* Upgraded Pillow to `>=10.0.1,<11` @jaheba (#3688)
* Upgraded scipy to `>=1.5.4,<1.13` @prateekdesai04 (#3709)
* Upgraded LightGBM to `>=3.3,<4.2` @mglowacki100 @prateekdesai04 @Innixma (#3427, #3709, #3733)
* Various minor dependency updates @jaheba (#3689)

## Tabular

### Highlights
AutoGluon v1.0 features major enhancements to predictive quality, establishing a new state-of-the-art in Tabular modeling. The enhancements come primarily from two features: Dynamic stacking to mitigate stacked overfitting, and a new learned model hyperparameters portfolio via Zeroshot-HPO, obtained via the newly released [TabRepo](https://github.com/autogluon/tabrepo) ensemble simulation library. Together, they lead to a **72% win-rate compared to v0.8.2 with faster inference speed, lower disk usage, and higher stability.**

### New Features
* Added `dynamic_stacking` predictor fit argument to mitigate stacked overfitting @LennartPurucker @Innixma (#3616)
* Added zeroshot-HPO learned portfolio as new hyperparameters for `best_quality` and `high_quality` presets. @Innixma @geoalgo (#3750)
* Added `predictor.model_failures()` @Innixma (#3421)
* Added enhanced FT-Transformer @taoyang1122 @Innixma (#3621, #3644, #3692)
* Added `predictor.simulation_artifact()` to support integration with [TabRepo](https://github.com/autogluon/tabrepo) @Innixma (#3555)

### Performance Improvements
* Enhanced FastAI model quality on regression via output clipping @LennartPurucker @Innixma (#3597)
* Added Skip-connection Weighted Ensemble @LennartPurucker (#3598)
* Fix memory leaks by using ray processes for sequential fitting @LennartPurucker (#3614)
* Added dynamic parallel folds support to better utilize compute in low memory scenarios @yinweisu @Innixma (#3511)
* Fixed linear model crashes during HPO and added search space for linear models @Innixma (#3571, #3720)

### Other Enhancements
* Multi-layer stacking now produces deterministic results @LennartPurucker (#3573)
* Various model dependency updates @mglowacki100 (#3373)
* Various code cleanup and logging improvements @Innixma (#3408, #3570, #3652, #3734)

### Bug Fixes / Code and Doc Improvements
* Fixed incorrect model memory usage calculation @Innixma (#3591)
* Fixed `infer_limit` being used incorrectly when bagging @Innixma (#3467)
* Fixed rare edge-case FastAI model crash @Innixma (#3416)
* Various minor bug fixes @Innixma (#3418, #3480)

## Deprecations

### General
* `autogluon.core.spaces` has been deprecated. Please use `autogluon.common.spaces` instead @Innixma (#3701)

### Tabular
@Innixma (#3701)
* `predictor.get_model_names()` -> `predictor.model_names()`
* `predictor.get_model_names_persisted()` -> `predictor.model_names(persisted=True)`
* `predictor.compile_models()` -> `predictor.compile()`
* `predictor.persist_models()` -> `predictor.persist()`
* `predictor.unpersist_models()` -> `predictor.unpersist()`
* `predictor.get_model_best()` -> `predictor.model_best`
* `predictor.get_pred_from_proba()` -> `predictor.predict_from_proba()`
* `predictor.get_oof_pred_proba()` -> `predictor.predict_proba_oof()`
* `predictor.get_oof_pred()` -> `predictor.predict_oof()`
* `predictor.get_model_full_dict()` -> `predictor.model_refit_map()`
* `predictor.get_size_disk()` -> `predictor.disk_usage()`
* `predictor.get_size_disk_per_file()` -> `predictor.disk_usage_per_file()`
* `predictor.leaderboard()` `silent` argument deprecated, replaced by `display`, defaults to False.
  * Same for `predictor.evaluate()` and `predictor.evaluate_predictions()`