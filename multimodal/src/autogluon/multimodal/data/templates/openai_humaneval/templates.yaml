dataset: openai_humaneval
templates:
  4a108b1c-7514-488f-99ed-3ca5da70e103: !Template
    answer_choices: null
    id: 4a108b1c-7514-488f-99ed-3ca5da70e103
    jinja: '{{ prompt }}

      Given the following docstring, what is the function body?

      |||

      {{ canonical_solution }}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Other
      original_task: true
    name: function body generation
    reference: ''
  9c85c898-70fe-4a51-be37-5111be357762: !Template
    answer_choices: null
    id: 9c85c898-70fe-4a51-be37-5111be357762
    jinja: "{% set ns = namespace(tests=[])%}\n{% set lines = test.split('\\n') %}\n\
      {% set test_ = \"\" %}\n{% set args = \"\" %}\n{% set return_val = \"\" %}\n\
      \n{% for line in lines %}\n    {% if line.strip().startswith('assert') and \"\
      ==\" in line.strip() %}\n        {% set ns.tests = ns.tests + [line.split('assert')[1]]\
      \ %}\n    {% endif %}\n{% endfor %}\n{% if (ns.tests | length) > 0 %}\n    {%\
      \ set test_ = ns.tests | choice  %}\n\n    {% set return_val = test_.split(\"\
      ==\")[1].split(\", \\\"\")[0].strip() %}\n    {% set args = (test_.split('(')[1:]\
      \ | join(\"\")).split(\"==\")[0].strip() %}\n    {{ prompt }}\n    {{ canonical_solution\
      \ }}\n    {{entry_point}}({{args}} =\n    |||\n    {{ return_val }}\n{% endif\
      \ %}\n"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Other
      original_task: false
    name: function call return value generation
    reference: ''
