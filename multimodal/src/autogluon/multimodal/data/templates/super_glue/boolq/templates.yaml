dataset: super_glue
subset: boolq
templates:
  3e386463-1715-4578-9cba-07d11a0d3b61: !Template
    answer_choices: False ||| True
    id: 3e386463-1715-4578-9cba-07d11a0d3b61
    jinja: 'Passage: {{passage}}


      After reading this passage, I have a question: {{question}}? True or False?
      |||

      {% if label != -1 %}

      {{answer_choices[label]}}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: after_reading
    reference: ''
  492f0f88-4370-46cd-839b-1de37a55aeda: !Template
    answer_choices: No ||| Yes
    id: 492f0f88-4370-46cd-839b-1de37a55aeda
    jinja: "{{ passage }} \nQuestion: {{ question }}\nAnswer: ||| \n{% if label !=\
      \ -1 %}\n{{ answer_choices[label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: GPT-3 Style
    reference: Same as Figure G29, p. 58 of the GPT-3 paper
  6cb6a026-c070-470a-b75d-bb8fdf424e35: !Template
    answer_choices: No ||| Yes
    id: 6cb6a026-c070-470a-b75d-bb8fdf424e35
    jinja: "{{ passage }} \n\nHaving read that, I wonder {{ question }}? |||\n{% if\
      \ label != -1 %}\n{{ answer_choices[label] }} \n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: "I wonder\u2026"
    reference: ''
  7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5: !Template
    answer_choices: No ||| Yes
    id: 7cf7acdf-e3a2-459f-a3e8-2e2d27dd6aa5
    jinja: 'Text: {{passage}}


      Answer the following yes/no question: {{question}}? Yes or no? |||

      {% if label != -1 %}

      {{answer_choices[label]}}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: yes_no_question
    reference: ''
  7d21d974-0624-4d4f-9e8c-644e2d009cb5: !Template
    answer_choices: No ||| Yes
    id: 7d21d974-0624-4d4f-9e8c-644e2d009cb5
    jinja: "{{ passage }} \n\nHaving read that, could you tell me {{ question }}?\
      \ ||| {% if label != -1 %}{{ answer_choices[label] }}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: "could you tell me\u2026"
    reference: ''
  922d3e87-ac58-4731-84d1-f0a40e47afb5: !Template
    answer_choices: No ||| Yes
    id: 922d3e87-ac58-4731-84d1-f0a40e47afb5
    jinja: "EXAM\n1. Answer by yes or no.\n\nDocument: {{passage}}\nQuestion: {{question}}?\
      \ ||| \n{% if label != -1 %}\n{{answer_choices[label]}}\n{% endif %}"
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: exam
    reference: ''
  9a1bf459-8047-437c-9def-f21e960429cc: !Template
    answer_choices: No ||| Yes
    id: 9a1bf459-8047-437c-9def-f21e960429cc
    jinja: 'Based on the following passage, {{ question }}? {{ passage }}


      |||

      {% if label != -1 %}

      {{ answer_choices[label] }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: based on the following passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  9f4c6b0a-437b-40c0-b467-db4b7218d38d: !Template
    answer_choices: False ||| True
    id: 9f4c6b0a-437b-40c0-b467-db4b7218d38d
    jinja: 'Exercise: read the text and answer the question by True or False.


      Text: {{passage}}

      Question: {{question}}? |||

      {% if label != -1 %}

      {{answer_choices[label]}}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: exercise
    reference: ''
  b2b3cb60-d6e3-491c-a09a-8201e13e417e: !Template
    answer_choices: No ||| Yes
    id: b2b3cb60-d6e3-491c-a09a-8201e13e417e
    jinja: '{{ passage }}

      Based on the previous passage, {{ question }}? ||| {% if label != -1 %}{{ answer_choices[label]
      }}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: false
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: based on the previous passage
    reference: "Adapted from Perez et al. 2021 and Schick & Sch\xFCtz 2021."
  eb78772c-e81e-4b8a-a77b-b75efd1c212a: !Template
    answer_choices: False ||| True
    id: eb78772c-e81e-4b8a-a77b-b75efd1c212a
    jinja: '{{passage}}


      Q: {{question}}? True or False? |||

      {% if label != -1 %}

      {{answer_choices[label]}}

      {% endif %}'
    metadata: !TemplateMetadata
      choices_in_prompt: true
      languages:
      - en
      metrics:
      - Accuracy
      original_task: true
    name: valid_binary
    reference: ''
