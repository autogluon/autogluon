optimization:
  optim_type: "adafactor"
  learning_rate: 1.0e-3
  weight_decay: 0.001
  scale_parameter: True
  relative_step: True
  warmup_init: False
  lr_choice: "layerwise_decay"
  lr_decay: 1.0
  lr_schedule: null
  max_epochs: 10
  max_steps: -1
  warmup_steps: 0.1
  end_lr: 0
  lr_mult: 1  # multiply lr for downstream heads
  patience: 10
  val_check_interval: 0.5
  top_k: 3
  top_k_average_method: 'greedy_soup'  # We support averaging method described in https://arxiv.org/pdf/2203.05482.pdf.
                                       # Currently support "union_soup", "greedy_soup", "best_soup".
