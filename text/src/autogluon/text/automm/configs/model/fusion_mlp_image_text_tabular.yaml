model:
  names:
    - "categorical_mlp"
    - "numerical_mlp"
    - "hf_text"
    - "timm_image"
    - "clip"
    - "fusion_mlp"
  categorical_mlp:
    hidden_size: 64
    activation: "leaky_relu"
    num_layers: 1
    drop_rate: 0.1
    normalization: "layer_norm"
    data_types:
      - "categorical"
  numerical_mlp:
    hidden_size: 128
    activation: "leaky_relu"
    num_layers: 1
    drop_rate: 0.1
    normalization: "layer_norm"
    data_types:
      - "numerical"
    merge: "concat"
  hf_text:
    checkpoint_name: "google/electra-base-discriminator"
    data_types:
      - "text"
    tokenizer_name: "hf_auto"
    max_text_len: 512  # If None or <=0, then use the max length of pretrained models.
    insert_sep: True
    text_segment_num: 2
    stochastic_chunk: False
  timm_image:
    checkpoint_name: "swin_base_patch4_window7_224"
    mix_choice: "all_logits"
    data_types:
      - "image"
    train_transform_types:
      - "resize_shorter_side"
      - "center_crop"
    val_transform_types:
      - "resize_shorter_side"
      - "center_crop"
    image_norm: "imagenet"
    image_size: 224
    max_img_num_per_col: 0
  clip:
    checkpoint_name: "openai/clip-vit-base-patch32"
    data_types:
      - "image"
      - "text"
    train_transform_types:
      - "resize_shorter_side"
      - "center_crop"
    val_transform_types:
      - "resize_shorter_side"
      - "center_crop"
    image_norm: "clip"
    image_size: 224
    max_img_num_per_col: 0
    tokenizer_name: "clip"
    max_text_len: 77  # The maximum possible length.
    insert_sep: False
    text_segment_num: 1
    stochastic_chunk: False
  fusion_mlp:
    weight: 0.1
    adapt_in_features: "max"
    hidden_sizes:
      - 128
    activation: "leaky_relu"
    drop_rate: 0.1
    normalization: "layer_norm"
    data_types:
